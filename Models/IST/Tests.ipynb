{"cells":[{"cell_type":"markdown","metadata":{"id":"cHy2H4YVh25D"},"source":["# Basic Setup and Functions"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"rXuB5FHah25G"},"outputs":[{"name":"stdout","output_type":"stream","text":["Note: you may need to restart the kernel to use updated packages.\n","Using mps device\n"]}],"source":["%pip install snntorch --quiet\n","\n","import librosa, random\n","import numpy as np\n","import pandas as pd\n","import os\n","import soundfile as sf\n","\n","from pandas import DataFrame as df\n","import torch\n","\n","from sklearn.metrics import confusion_matrix, roc_auc_score, precision_score, recall_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","\n","import snntorch as snn\n","from snntorch.functional.acc import _population_code, _prediction_check\n","\n","import torch.nn as nn\n","from torch import Tensor\n","from torch.utils.data import TensorDataset, DataLoader\n","from torch import optim\n","from torchvision import transforms\n","\n","from tqdm.notebook import tqdm\n","\n","import gc\n","\n","device = (\n","    \"cuda\"\n","    if torch.cuda.is_available()\n","    else \"mps\"\n","    if torch.backends.mps.is_available()\n","    else \"cpu\"\n",")\n","\n","print(f\"Using {device} device\")"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"3ae_oxqGh25H"},"outputs":[],"source":["def Triangle_Network(num_inputs, num_outputs, beta=0.90, time_dependent = False):\n","    try: dy_dx = int(4/(num_outputs - num_inputs))\n","    except: dy_dx = 0\n","    hidden1 = num_inputs + (dy_dx * 1)\n","    hidden2 = num_inputs + (dy_dx * 2)\n","    hidden3 = num_inputs + (dy_dx * 3)\n","\n","    if beta and time_dependent:\n","        class Net(nn.Module):\n","        # Initialise network with 2 forward connections (linear connections) and 2 leaky integrated fire layers (hidden and output)\n","            def __init__(self, *args, **kwargs) -> None:\n","                super().__init__(*args, **kwargs)\n","                self.fc1 = nn.Linear(num_inputs, hidden1)\n","                self.lif1 = snn.Leaky(beta=beta)\n","                self.fc2 = nn.Linear(hidden1, hidden2)\n","                self.lif2 = snn.Leaky(beta=beta)\n","                self.fc3 = nn.Linear(hidden3, hidden3)\n","                self.lif3 = snn.Leaky(beta=beta)\n","                self.fc4 = nn.Linear(hidden3, num_outputs)\n","                self.lif4 = snn.Leaky(beta=beta)\n","\n","            # Define a forward pass assuming x is normalised data (i.e. all values in [0,1])\n","            def forward(self, x):\n","                mem1 = self.lif1.init_leaky()\n","                mem2 = self.lif2.init_leaky()\n","                mem3 = self.lif3.init_leaky()\n","                mem4 = self.lif4.init_leaky()\n","\n","                spk_rec = []\n","                mem_rec = []\n","\n","                # Insert data in shape (time x batch x features)\n","                for step in range(x.size(0)):\n","                    cur1 = self.fc1(x[step])\n","                    spk1, mem1 = self.lif1(cur1, mem1)\n","                    cur2 = self.fc2(spk1)\n","                    spk2, mem2 = self.lif2(cur2, mem2)\n","                    cur3 = self.fc3(spk2)\n","                    spk3, mem3 = self.lif3(cur3, mem3)\n","                    cur4 = self.fc4(spk3)\n","                    spk4, mem4 = self.lif4(cur4, mem4)\n","\n","                    spk_rec.append(spk4)\n","                    mem_rec.append(mem4)\n","\n","                return torch.stack(spk_rec, dim=0), torch.stack(mem_rec, dim=0)\n","            \n","        return Net()\n","\n","\n","    elif beta and not time_dependent: return nn.Sequential(nn.Flatten(),\n","                    nn.Linear(num_inputs, hidden1),\n","                    snn.Leaky(beta=beta, init_hidden=True),\n","                    nn.Linear(hidden1, hidden2),\n","                    snn.Leaky(beta=beta, init_hidden=True),\n","                    nn.Linear(hidden2, hidden3),\n","                    snn.Leaky(beta=beta, init_hidden=True),\n","                    nn.Linear(hidden3, num_outputs),\n","                    snn.Leaky(beta=beta, init_hidden=True, output=True))\n","\n","    else: return nn.Sequential(nn.Flatten(),\n","                    nn.Linear(num_inputs, hidden1),\n","                    nn.ReLU(),\n","                    nn.Linear(hidden1, hidden2),\n","                    nn.ReLU(),\n","                    nn.Linear(hidden2, hidden3),\n","                    nn.ReLU(),\n","                    nn.Linear(hidden3, num_outputs))"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"_6kx2Evvh25I"},"outputs":[],"source":["def test_spiking_network(model, dataset, loss_fn, results: df, epoch, device, num_classes=False, printable=None, train_test = 'test'):\n","    dataloader = DataLoader(dataset, batch_size=100, num_workers=3, shuffle=False)\n","    model.eval()\n","    with torch.no_grad():\n","        test_loss = 0.0\n","        correct = 0\n","        total = 0\n","        total_spikes = 0\n","        all_labels = []\n","        all_predicted = []\n","        all_probs = []\n","\n","        for data, labels in dataloader:\n","            x, labels = data.transpose(0, 1).to(device), labels.to(device)\n","            spikes, _ = model(x)\n","            test_loss += loss_fn(spikes, labels).item()\n","            \n","            if num_classes: _, predicted = _population_code(spikes, num_classes=num_classes, num_outputs=spikes.size(-1)).max(1)\n","            else: _, predicted = spikes.sum(dim=1).max(1)\n","\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","            all_labels.extend(labels.cpu().numpy())\n","            all_predicted.extend(predicted.cpu().numpy())\n","\n","            if num_classes: num_spikes = _population_code(spikes, num_classes=num_classes, num_outputs=spikes.size(-1))\n","            else: num_spikes = spikes.sum(dim=1)\n","            \n","            softmax = torch.nn.Softmax(dim=1)\n","            probabilities = softmax(num_spikes)\n","            all_probs.extend(probabilities.cpu().numpy())\n","        \n","            total_spikes += spikes.size(1)\n","\n","        test_loss /= total_spikes\n","\n","    # Accuracy\n","    accuracy = 100 * correct / total\n","\n","    # Confusion Matrix\n","    cm = confusion_matrix(all_labels, all_predicted)\n","\n","    # Recall/Sensitivity -- avoiding div by 0\n","    recall = recall_score(all_labels, all_predicted, average='weighted', zero_division=0) * 100\n","\n","    # Precision\n","    precision = precision_score(all_labels, all_predicted, average='weighted', zero_division=0) * 100\n","\n","    # F1 Score\n","    f1_score = (2 * precision * recall) / (precision + recall)\n","\n","    # AUC-ROC\n","    auc_roc = 100 * roc_auc_score(all_labels, all_probs, multi_class='ovr')\n","    \n","    if printable: printable.set_description(\n","        f'Epoch [{epoch + 1}] {train_test} Loss: {test_loss / len(dataloader):.2f} '\n","        f'{train_test} Accuracy: {accuracy:.2f}% F1: {f1_score}% Recall: {recall:.2f}% Precision: {precision:.2f}% '\n","        f'AUC-ROC: {auc_roc:.4f}%'\n","    )\n","\n","    results = results._append({\n","            'Epoch': epoch + 1,\n","            'Accuracy': accuracy,\n","            'F1': f1_score,\n","            'Recall': recall,\n","            'Precision': precision,\n","            'Test Loss': test_loss / len(dataloader),\n","            'AUC-ROC': auc_roc,\n","            'Confusion Matrix': cm\n","        }, ignore_index=True)\n","\n","    del data\n","    del labels\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","\n","    return results"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def test_network(model, dataset, loss_fn, results: df, epoch, device, printable=None, train_test = 'test'):\n","    dataloader = DataLoader(dataset, batch_size=100, shuffle=False)\n","    model.eval()\n","    with torch.no_grad():\n","        test_loss = 0.0\n","        correct = 0\n","        total = 0\n","        all_labels = []\n","        all_predicted = []\n","        all_probs = []\n","\n","        for data, labels in dataloader:\n","            x, labels = data.to(device), labels.to(device)\n","            outputs = model(x)\n","            test_loss += loss_fn(outputs, labels).item()\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","            all_labels.extend(labels.cpu().numpy())\n","            all_predicted.extend(predicted.cpu().numpy())\n","\n","\n","            softmax = torch.nn.Softmax(dim=1)\n","            probabilities = softmax(outputs)\n","            all_probs.extend(probabilities.cpu().numpy())\n","\n","    # Accuracy\n","    accuracy = 100 * correct / total\n","\n","    # Confusion Matrix\n","    cm = confusion_matrix(all_labels, all_predicted)\n","\n","    # Recall/Sensitivity -- avoiding div by 0\n","    recall = recall_score(all_labels, all_predicted, average='weighted', zero_division=0)\n","\n","    # Precision\n","    precision = precision_score(all_labels, all_predicted, average='weighted', zero_division=0)\n","\n","    # F1 Score\n","    f1_score = (2 * precision * recall) / (precision + recall)\n","\n","    # AUC-ROC\n","    auc_roc = 100 * roc_auc_score(all_labels, all_probs, multi_class='ovr')\n","\n","    if printable: printable.set_description(\n","        f'Epoch [{epoch + 1}] {train_test} Loss: {test_loss / len(dataloader):.2f} '\n","        f'{train_test} Accuracy: {accuracy:.2f}% F1: {f1_score}% Recall: {recall:.2f}% Precision: {precision:.2f}% '\n","        f'AUC-ROC: {auc_roc:.4f}%'\n","    )\n","\n","    results = results._append({\n","            'Epoch': epoch + 1,\n","            'Accuracy': accuracy,\n","            'F1': f1_score,\n","            'Recall': recall,\n","            'Precision': precision,\n","            'Test Loss': test_loss / len(dataloader),\n","            'AUC-ROC': auc_roc,\n","            'Confusion Matrix': cm\n","        }, ignore_index=True)\n","\n","    del data\n","    del labels\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","\n","    return results"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["class PopulationCrossEntropyLoss():\n","    def __init__(self, num_classes=2):\n","        self.num_classes = num_classes\n","        self.__name__ = \"PopulationCrossEntropyLoss\"\n","\n","    def __call__(self, spk_out, targets):\n","        loss_fn = nn.CrossEntropyLoss()\n","        \n","        _, _, num_outputs = _prediction_check(spk_out)\n","\n","        spike_count = _population_code(\n","                spk_out, self.num_classes, num_outputs\n","            )\n","\n","        loss = loss_fn(spike_count, targets)\n","\n","        return loss\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"q93J30hEh25J"},"outputs":[],"source":["LABEL_MAPPINGS = {\n","    'westernart/classical': 'Classical',\n","    'indierock/pop': 'Rock',\n","    'pop/soul/electronica': 'Electronic',\n","    'electronica': 'Electronic',\n","    'jazz': 'Jazz',\n","    'pop/hiphop/rock': 'Pop',\n","    'rap/hiphop': 'Hiphop',\n","    'rock': 'Rock',\n","    'rock/folk': 'Rock',\n","    'westernart/baroque': 'Classical',\n","    'electronica/dance': 'Electronic',\n","    'westernart/romantic': 'Classical',\n","    'blues': 'Jazz',\n","    'pop/folk': 'Pop',\n","    'westernart/romantic/classical': 'Classical',\n","    'pop/electronica': 'Electronic',\n","    'latin': 'Jazz',\n","    'country/folk': 'Country',\n","    'indierock/folk/pop': 'Rock',\n","    'jazz/blues': 'Jazz',\n","    'pop/rap/rock/hiphop': 'Pop',\n","    'pop/experimental': 'Pop',\n","    'blues/rock/jazz': 'Jazz',\n","    'jazz/adventure': 'Jazz',\n","    'blues/electronica': 'Jazz',\n","    'jazz/pop/soul': 'Jazz',\n","    'funk/electronica': 'Electronic',\n","    'folk/pop': 'Folk',\n","    'indierock/rock': 'Rock',\n","    'jazz/electronica': 'Electronic',\n","    'hiphop': 'Hiphop',\n","    'funk/rnb/adventure': 'Soul',\n","    'pop': 'Pop',\n","    'hiphop/rap': 'Hiphop',\n","    'pop/gospel': 'Soul',\n","    'rap/metal/electronica': 'Electronic',\n","    'pop/rock/folk': 'Rock',\n","    'pop/electronica/hiphop': 'Pop',\n","    'metal/rap': 'Hiphop',\n","    'country': 'Country',\n","    'rap/metal': 'Hiphop',\n","    'country/pop': 'Country',\n","    'folk': 'Folk',\n","    'pop/rock/dance': 'Pop',\n","    'dance': 'Electronic',\n","    'pop/jazz/latin': 'Jazz',\n","    'pop/jazz': 'Jazz',\n","    'funk/rnb/electronica': 'Electronic',\n","    'funk/blues/jazz': 'Jazz',\n","    'pop/rock/soul': 'Pop',\n","    'pop/hiphop': 'Pop',\n","    'blues/funk': 'Jazz',\n","    'rap/metal/hiphop': 'Hiphop',\n","    'blues/jazz/adventure': 'Jazz',\n","    'folk/indierock': 'Folk',\n","    'adventure': 'Classical',\n","    'metal/rock': 'Rock',\n","    'blues/rock/country': 'Jazz',\n","    'pop/soul/rnb': 'Soul',\n","    'blues/rock': 'Jazz',\n","    'blues/rock/indierock': 'Jazz',\n","    'country/pop/folk': 'Country',\n","    'country/blues/rock': 'Country',\n","    'rock/funk/country': 'Rock',\n","    'pop/rock': 'Rock',\n","    'pop/blues': 'Rock',\n","    'blues/indierock': 'Rock',\n","    'blues/rock/rnb': 'Rock',\n","    'blues/pop/folk': 'Jazz',\n","    'pop/funk/adventure': 'Pop',\n","    'blues/rock/pop': 'Rock',\n","    'folk/pop/funk': 'Folk'\n","}\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"y5-_se-YiO7P"},"outputs":[{"name":"stdout","output_type":"stream","text":["{0: 'Classical', 1: 'Country', 2: 'Electronic', 3: 'Folk', 4: 'Hiphop', 5: 'Jazz', 6: 'Pop', 7: 'Rock', 8: 'Soul'}\n"]}],"source":["try:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    !rsync -av --exclude='mel_spectrograms' --exclude='cqt_spectrograms' /content/drive/MyDrive/spectrogram_tensors/ /content/spectrogram_tensors/ --quiet\n","    FILEPATH = '/content'\n","    CSV = 'sample_ISD.csv'\n","\n","    dataset = pd.read_csv(f'/content/drive/MyDrive/{CSV}', index_col=0)\n","\n","    \n","except:\n","    FILEPATH = \"../../Datasets/SmallDataset\"\n","    ORIGINAL_DIR = \"audio\"\n","    SAMPLE_DIR = \"audio uncompressed samples\"\n","    COMPRESSED_DIR = \"audio compressed\"\n","    CSV = 'sample_ISD.csv'\n","\n","    dataset = pd.read_csv(f'{FILEPATH}/{CSV}', index_col=0)\n","\n","X = dataset['filename'].tolist()\n","Y = dataset[dataset['supercategory']=='music']['category'].map(lambda x: LABEL_MAPPINGS[x]).tolist()\n","label_encoder = LabelEncoder()\n","Y_encoded = label_encoder.fit_transform(Y)\n","\n","label_mappings = {encoded_label: original_label for original_label, encoded_label in zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))}\n","print(label_mappings)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Garbage collection special commands\n","\n","gc.collect()\n","if device == \"cuda\":\n","    torch.cuda.empty_cache()\n","    torch.cuda.memory_summary(device=None, abbreviated=False)\n","elif device == \"mps\":\n","    torch.mps.empty_cache()\n","    print(f\"MPS occupied memory: {torch.mps.driver_allocated_memory()}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Very special command -- remove all variables\n","%reset"]},{"cell_type":"markdown","metadata":{"id":"JjzopoGZh25J"},"source":["# Audio Representation"]},{"cell_type":"markdown","metadata":{"id":"QrnOeGaHh25K"},"source":["## Sampling"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5qroeHpJh25L"},"outputs":[],"source":["def sample(audio_path, duration=5.0, sr=44100):\n","    original_path = audio_path\n","    for ext in [\".m4a\", \".wav\", \".ogg\", \".flac\", \".mp3\"]:\n","        if os.path.exists(audio_path + ext):\n","            audio_path += ext\n","\n","            total_duration = librosa.get_duration(path=audio_path)\n","            y, _ = librosa.load(audio_path, sr=sr, duration=total_duration)\n","\n","            if total_duration < duration:\n","                pad_length = int((duration - total_duration) * sr)\n","                y = np.pad(y, (0, pad_length), mode='constant')\n","\n","            start = random.uniform(0, max(0, total_duration - duration))\n","            y = y[int(start * sr):int((start + duration) * sr)]\n","\n","            sf.write(f\"{FILEPATH}/{SAMPLE_DIR}/{original_path.split('/')[-1]}.wav\", y, sr)\n","\n","            return y"]},{"cell_type":"markdown","metadata":{"id":"43m8jiuhh25L"},"source":["## Bitrate and Compression"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"74ui8zpqh25M"},"outputs":[],"source":["import os\n","from tqdm.notebook import tqdm\n","from concurrent.futures import ThreadPoolExecutor\n","\n","def convert_to_mp3(input_file, output_file, sample_rate=16000, bit_rate=\"8k\", channels=1):\n","    !ffmpeg -i \"$input_file\" -ar \"$sample_rate\" -b:a \"$bitrate\" -ac \"$channels\" \"$output_file\" -hide_banner -loglevel error\n","\n","\n","def convert_directory_to_mp3(input_dir, output_dir, sample_rate=16000, bit_rate=\"8k\"):\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    audio_files = [file for file in os.listdir(input_dir) if file.endswith((\".m4a\", \".wav\", \".ogg\", \".flac\", \".mp3\"))]\n","\n","    for file in tqdm(audio_files, desc=\"Converting\"):\n","            input_file_path = os.path.join(input_dir, file)\n","            output_file_path = os.path.join(output_dir, os.path.splitext(file)[0] + \".mp3\")\n","            convert_to_mp3(input_file_path, output_file_path, sample_rate, bit_rate)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IAUf5u8Yh25M"},"outputs":[],"source":["bitdepths = np.array([2,4,8,16,24])\n","samplerates = np.int32(np.array([8,16,22.05,32,44.1])*1000)\n","\n","with ThreadPoolExecutor() as executor:\n","    for bitdepth in bitdepths:\n","        for samplerate in samplerates:\n","            bitrate = (bitdepth * samplerate) / 1000\n","            print(f\"bitdepth: {bitdepth}, samplerate: {samplerate}\")\n","            print(f\"effective bitrate: {bitrate} kbps\")\n","\n","            executor.submit(convert_directory_to_mp3(f\"{FILEPATH}/{SAMPLE_DIR}\", f\"{FILEPATH}/{COMPRESSED_DIR}/{bitdepth}-{samplerate}\", sample_rate=samplerate, bit_rate=f\"{bitrate}k\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mEmydtY2h25M"},"outputs":[],"source":["# Assuming the directory contains all compressed files\n","!find . -mindepth 1 -maxdepth 1 -type d -exec sh -c 'find \"$1\" -type f -exec ls -l {} \\; | awk \"{sum += \\$5} END {print \\\"$1\\\", sum}\"' _ {} \\"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0K_lIJiLh25N"},"outputs":[],"source":["from mutagen.mp3 import MP3\n","\n","def get_unpacked_size(mp3_file):\n","    audio = MP3(mp3_file)\n","    duration = audio.info.length  # Duration of the audio in seconds\n","    bitrate = audio.info.bitrate  # Bitrate of the audio in bits per second\n","    # Calculate the unpacked size based on bitrate and duration\n","    unpacked_size = (duration * bitrate) / 8\n","    return unpacked_size\n","\n","\n","file_dirs = [d for d in os.listdir(f\"{FILEPATH}/{COMPRESSED_DIR}\") if os.path.isdir(f\"{FILEPATH}/{COMPRESSED_DIR}/{d}\")]\n","for bitrate in file_dirs:\n","    audio_files = [file for file in os.listdir(f\"{FILEPATH}/{COMPRESSED_DIR}/{bitrate}\") if file.endswith((\".mp3\"))]\n","    size = 0\n","    for file in audio_files:\n","        if os.path.exists(f\"{FILEPATH}/{COMPRESSED_DIR}/{bitrate}/{file}\"):\n","            size += get_unpacked_size(f\"{FILEPATH}/{COMPRESSED_DIR}/{bitrate}/{file}\")\n","    print(f\"{bitrate.split('/')[-1]}: {size} bytes\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BW6hyuwDh25N"},"outputs":[],"source":["from matplotlib import pyplot as plt\n","import tikzplotlib\n","\n","bit_two = np.array([[16,32,44.1,64,88.2],[1,3,4,5,5]]).T\n","bit_four = np.array([[32,64,88.2,128,176.4],[2,4,5,5,5]]).T\n","bit_eight = np.array([[64,128,176.4,256,352.8],[2,4,5,5,5]]).T\n","bit_sixteen = np.array([[128,256,352.8,512,705.6],[2,3,4,4,5]]).T\n","bit_twentyfour = np.array([[192,384,529.2,768,1058.4],[2,4,5,5,5]]).T\n","\n","plt.plot(bit_two[:,0], bit_two[:,1], label=\"2-bit\")\n","plt.plot(bit_four[:,0], bit_four[:,1], label=\"4-bit\")\n","plt.plot(bit_eight[:,0], bit_eight[:,1], label=\"8-bit\")\n","plt.plot(bit_sixteen[:,0], bit_sixteen[:,1], label=\"16-bit\")\n","plt.plot(bit_twentyfour[:,0], bit_twentyfour[:,1], label=\"24-bit\")\n","\n","plt.ylabel(\"Perceived Quality\")\n","plt.xlabel(\"Bitrate (kbps)\")\n","plt.xscale(\"log\")\n","plt.xlim(10,1100)\n","plt.ylim(0, 6)\n","plt.grid(True, which='both', axis='y')\n","#plt.legend()\n","\n","tikzplotlib.save(\"AudioRep/CompressionReception.tex\")"]},{"cell_type":"markdown","metadata":{"id":"st4_dGj4h25N"},"source":["## Spectrograms"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yE7h8re8h25O"},"outputs":[],"source":["import spectrograms\n","\n","AUDIO_DIR = \"compressed_audio\"\n","\n","X = dataset[dataset['supercategory']=='music']['filename'].tolist()\n","Y = dataset[dataset['supercategory']=='music']['category'].map(lambda x: LABEL_MAPPINGS[x]).tolist()\n","\n","label_encoder = LabelEncoder()\n","Y_encoded = label_encoder.fit_transform(Y)\n","\n","label_mappings = {encoded_label: original_label for original_label, encoded_label in zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))}\n","print(label_mappings)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, Y_encoded, test_size=0.2)\n","\n","waveforms_train = [spectrograms.load_from_path(f\"{FILEPATH}/{AUDIO_DIR}/{file}.mp3\") for file in X_train]\n","waveforms_test = [spectrograms.load_from_path(f\"{FILEPATH}/{AUDIO_DIR}/{file}.mp3\") for file in X_test]"]},{"cell_type":"markdown","metadata":{"id":"K_N2kwfnh25O"},"source":["### Standard Spectrogram"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vQQmRuouh25O"},"outputs":[],"source":["DIR = \"spectrogram_tensors\"\n","\n","\n","for n_fft in [512, 1024, 2048, 4096]:\n","    for win_length in [512, 1024, 2048, 4096]:\n","        if n_fft < win_length:\n","            continue\n","        else:\n","            os.makedirs(f\"{FILEPATH}/{DIR}/spectrograms/{n_fft}-{512}-{win_length}\", exist_ok=True)\n","            spectrogram_X_train = Tensor(np.array([x for x, _ in [spectrograms.spectrogram(sample, sr, hop=512, fft=n_fft, win=win_length) for sample, sr in waveforms_train]]))\n","            spectrogram_X_test = Tensor(np.array([x for x, _ in [spectrograms.spectrogram(sample, sr, hop=512, fft=n_fft, win=win_length) for sample, sr in waveforms_test]]))\n","            spectrogram_train = TensorDataset(spectrogram_X_train, torch.LongTensor(y_train))\n","            spectrogram_test = TensorDataset(spectrogram_X_test, torch.LongTensor(y_test))\n","            torch.save(spectrogram_train, f\"{FILEPATH}/{DIR}/spectrograms/{n_fft}-{512}-{win_length}/train.pt\")\n","            torch.save(spectrogram_test, f\"{FILEPATH}/{DIR}/spectrograms/{n_fft}-{512}-{win_length}/test.pt\")\n","\n","\n","for hop_length in [256, 1024, 2048]:\n","    os.makedirs(f\"{FILEPATH}/{DIR}/spectrograms/{2048}-{hop_length}-{2048}\", exist_ok=True)\n","    spectrogram_X_train = Tensor(np.array([x for x, _ in [spectrograms.spectrogram(sample, sr, hop=hop_length, fft=2048, win=2048) for sample, sr in waveforms_train]]))\n","    spectrogram_X_test = Tensor(np.array([x for x, _ in [spectrograms.spectrogram(sample, sr, hop=hop_length, fft=2048, win=2048) for sample, sr in waveforms_test]]))\n","    spectrogram_train = TensorDataset(spectrogram_X_train, torch.LongTensor(y_train))\n","    spectrogram_test = TensorDataset(spectrogram_X_test, torch.LongTensor(y_test))\n","    torch.save(spectrogram_train, f\"{FILEPATH}/{DIR}/spectrograms/{2048}-{hop_length}-{2048}/train.pt\")\n","    torch.save(spectrogram_test, f\"{FILEPATH}/{DIR}/spectrograms/{2048}-{hop_length}-{2048}/test.pt\")\n"]},{"cell_type":"markdown","metadata":{"id":"bgYyIxHJh25O"},"source":["### Mel Spectrogram"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ejZ5v5tBh25O"},"outputs":[],"source":["DIR = \"spectrogram_tensors\"\n","\n","\n","for n_fft in [512, 1024, 2048, 4096]:\n","    for win_length in [512, 1024, 2048, 4096]:\n","        if n_fft < win_length:\n","            continue\n","        else:\n","            os.makedirs(f\"{FILEPATH}/{DIR}/mel_spectrograms/{n_fft}-{512}-{win_length}-{128}\", exist_ok=True)\n","            spectrogram_X_train = Tensor(np.array([x for x, _ in [spectrograms.mel_spectrogram(sample, sr, fft=n_fft, win=win_length) for sample, sr in waveforms_train]]))\n","            spectrogram_X_test = Tensor(np.array([x for x, _ in [spectrograms.mel_spectrogram(sample, sr, fft=n_fft, win=win_length) for sample, sr in waveforms_test]]))\n","            spectrogram_train = TensorDataset(spectrogram_X_train, torch.LongTensor(y_train))\n","            spectrogram_test = TensorDataset(spectrogram_X_test, torch.LongTensor(y_test))\n","            torch.save(spectrogram_train, f\"{FILEPATH}/{DIR}/mel_spectrograms/{n_fft}-{512}-{win_length}-{128}/train.pt\")\n","            torch.save(spectrogram_test, f\"{FILEPATH}/{DIR}/mel_spectrograms/{n_fft}-{512}-{win_length}-{128}/test.pt\")\n","\n","\n","for hop_length in [256, 1024, 2048]:\n","    os.makedirs(f\"{FILEPATH}/{DIR}/mel_spectrograms/{2048}-{hop_length}-{2048}-{128}\", exist_ok=True)\n","    spectrogram_X_train = Tensor(np.array([x for x, _ in [spectrograms.mel_spectrogram(sample, sr, hop=hop_length, fft=2048, win=2048) for sample, sr in waveforms_train]]))\n","    spectrogram_X_test = Tensor(np.array([x for x, _ in [spectrograms.mel_spectrogram(sample, sr, hop=hop_length, fft=2048, win=2048) for sample, sr in waveforms_test]]))\n","    spectrogram_train = TensorDataset(spectrogram_X_train, torch.LongTensor(y_train))\n","    spectrogram_test = TensorDataset(spectrogram_X_test, torch.LongTensor(y_test))\n","    torch.save(spectrogram_train, f\"{FILEPATH}/{DIR}/mel_spectrograms/{2048}-{hop_length}-{2048}-{128}/train.pt\")\n","    torch.save(spectrogram_test, f\"{FILEPATH}/{DIR}/mel_spectrograms/{2048}-{hop_length}-{2048}-{128}/test.pt\")\n","\n","\n","for mel_features in [64, 128, 192, 256]:\n","    os.makedirs(f\"{FILEPATH}/{DIR}/mel_spectrograms/{2048}-{512}-{2048}-{mel_features}\", exist_ok=True)\n","    spectrogram_X_train = Tensor(np.array([x for x, _ in [spectrograms.mel_spectrogram(sample, sr, mel=mel_features) for sample, sr in waveforms_train]]))\n","    spectrogram_X_test = Tensor(np.array([x for x, _ in [spectrograms.mel_spectrogram(sample, sr, mel=mel_features) for sample, sr in waveforms_test]]))\n","    spectrogram_train = TensorDataset(spectrogram_X_train, torch.LongTensor(y_train))\n","    spectrogram_test = TensorDataset(spectrogram_X_test, torch.LongTensor(y_test))\n","    torch.save(spectrogram_train, f\"{FILEPATH}/{DIR}/mel_spectrograms/{2048}-{512}-{2048}-{mel_features}/train.pt\")\n","    torch.save(spectrogram_test, f\"{FILEPATH}/{DIR}/mel_spectrograms/{2048}-{512}-{2048}-{mel_features}/test.pt\")"]},{"cell_type":"markdown","metadata":{"id":"_VOfBuf6h25P"},"source":["### MFCCs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d1WeX2vLh25P"},"outputs":[],"source":["DIR = \"spectrogram_tensors\"\n","\n","for n_fft in [512, 1024, 2048, 4096]:\n","    for win_length in [512, 1024, 2048, 4096]:\n","        if n_fft < win_length:\n","            continue\n","        else:\n","            os.makedirs(f\"{FILEPATH}/{DIR}/mfcc_spectrograms/{n_fft}-{512}-{win_length}-{128}-{13}\", exist_ok=True)\n","            spectrogram_X_train = Tensor(np.array([x for x, _ in [spectrograms.mfcc_spectrogram(sample, sr, fft=n_fft, win=win_length) for sample, sr in waveforms_train]]))\n","            spectrogram_X_test = Tensor(np.array([x for x, _ in [spectrograms.mfcc_spectrogram(sample, sr, fft=n_fft, win=win_length) for sample, sr in waveforms_test]]))\n","            spectrogram_train = TensorDataset(spectrogram_X_train, torch.LongTensor(y_train))\n","            spectrogram_test = TensorDataset(spectrogram_X_test, torch.LongTensor(y_test))\n","            torch.save(spectrogram_train, f\"{FILEPATH}/{DIR}/mfcc_spectrograms/{n_fft}-{512}-{win_length}-{128}-{13}/train.pt\")\n","            torch.save(spectrogram_test, f\"{FILEPATH}/{DIR}/mfcc_spectrograms/{n_fft}-{512}-{win_length}-{128}-{13}/test.pt\")\n","\n","\n","for hop_length in [256, 1024, 2048]:\n","    os.makedirs(f\"{FILEPATH}/{DIR}/mfcc_spectrograms/{2048}-{hop_length}-{2048}-{128}-{13}\", exist_ok=True)\n","    spectrogram_X_train = Tensor(np.array([x for x, _ in [spectrograms.mfcc_spectrogram(sample, sr, hop=hop_length, fft=2048, win=2048) for sample, sr in waveforms_train]]))\n","    spectrogram_X_test = Tensor(np.array([x for x, _ in [spectrograms.mfcc_spectrogram(sample, sr, hop=hop_length, fft=2048, win=2048) for sample, sr in waveforms_test]]))\n","    spectrogram_train = TensorDataset(spectrogram_X_train, torch.LongTensor(y_train))\n","    spectrogram_test = TensorDataset(spectrogram_X_test, torch.LongTensor(y_test))\n","    torch.save(spectrogram_train, f\"{FILEPATH}/{DIR}/mfcc_spectrograms/{2048}-{hop_length}-{2048}-{128}-{13}/train.pt\")\n","    torch.save(spectrogram_test, f\"{FILEPATH}/{DIR}/mfcc_spectrograms/{2048}-{hop_length}-{2048}-{128}-{13}/test.pt\")\n","\n","\n","for mel_features in [64, 128, 192, 256]:\n","    os.makedirs(f\"{FILEPATH}/{DIR}/mfcc_spectrograms/{2048}-{512}-{2048}-{mel_features}-{13}\", exist_ok=True)\n","    spectrogram_X_train = Tensor(np.array([x for x, _ in [spectrograms.mfcc_spectrogram(sample, sr, mel=mel_features) for sample, sr in waveforms_train]]))\n","    spectrogram_X_test = Tensor(np.array([x for x, _ in [spectrograms.mfcc_spectrogram(sample, sr, mel=mel_features) for sample, sr in waveforms_test]]))\n","    spectrogram_train = TensorDataset(spectrogram_X_train, torch.LongTensor(y_train))\n","    spectrogram_test = TensorDataset(spectrogram_X_test, torch.LongTensor(y_test))\n","    torch.save(spectrogram_train, f\"{FILEPATH}/{DIR}/mfcc_spectrograms/{2048}-{512}-{2048}-{mel_features}-{13}/train.pt\")\n","    torch.save(spectrogram_test, f\"{FILEPATH}/{DIR}/mfcc_spectrograms/{2048}-{512}-{2048}-{mel_features}-{13}/test.pt\")\n","\n","for mfcc_components in [5, 9, 13, 20]:\n","    os.makedirs(f\"{FILEPATH}/{DIR}/mfcc_spectrograms/{2048}-{512}-{2048}-{128}-{mfcc_components}\", exist_ok=True)\n","    spectrogram_X_train = Tensor(np.array([x for x, _ in [spectrograms.mfcc_spectrogram(sample, sr, mfcc_bins=mfcc_components) for sample, sr in waveforms_train]]))\n","    spectrogram_X_test = Tensor(np.array([x for x, _ in [spectrograms.mfcc_spectrogram(sample, sr, mfcc_bins=mfcc_components) for sample, sr in waveforms_test]]))\n","    spectrogram_train = TensorDataset(spectrogram_X_train, torch.LongTensor(y_train))\n","    spectrogram_test = TensorDataset(spectrogram_X_test, torch.LongTensor(y_test))\n","    torch.save(spectrogram_train, f\"{FILEPATH}/{DIR}/mfcc_spectrograms/{2048}-{512}-{2048}-{128}-{mfcc_components}/train.pt\")\n","    torch.save(spectrogram_test, f\"{FILEPATH}/{DIR}/mfcc_spectrograms/{2048}-{512}-{2048}-{128}-{mfcc_components}/test.pt\")"]},{"cell_type":"markdown","metadata":{"id":"quC-qqvvh25P"},"source":["### CQT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dYLOq4ruh25P"},"outputs":[],"source":["for hop_length in [256, 512, 1024, 2048]:\n","    os.makedirs(f\"{FILEPATH}/{DIR}/cqt_spectrograms/{hop_length}\", exist_ok=True)\n","    spectrogram_X_train = Tensor(np.array([x for x, _ in [spectrograms.cqt_spectrogram(sample, sr, hop=hop_length) for sample, sr in waveforms_train]]))\n","    spectrogram_X_test = Tensor(np.array([x for x, _ in [spectrograms.cqt_spectrogram(sample, sr, hop=hop_length) for sample, sr in waveforms_test]]))\n","    spectrogram_train = TensorDataset(spectrogram_X_train, torch.LongTensor(y_train))\n","    spectrogram_test = TensorDataset(spectrogram_X_test, torch.LongTensor(y_test))\n","    torch.save(spectrogram_train, f\"{FILEPATH}/{DIR}/cqt_spectrograms/{hop_length}/train.pt\")\n","    torch.save(spectrogram_test, f\"{FILEPATH}/{DIR}/cqt_spectrograms/{hop_length}/test.pt\")"]},{"cell_type":"markdown","metadata":{"id":"v-ac1vMrh25P"},"source":["# ANN Baseline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xEiy6I9ph25P"},"outputs":[],"source":["def train(model, train_dataset, test_dataset, num_epochs, device):\n","    criterion = nn.CrossEntropyLoss()\n","    #optimizer = optim.SGD(model.parameters(), lr=0.01)\n","    optimizer = optim.Adam(model.parameters(), lr=0.0005)\n","\n","    batch_size = 32\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","    test_results = df()\n","    train_results = df()\n","\n","    epoch_progress_bar = tqdm(total=num_epochs, desc=\"Training Progress\", position=0)\n","\n","    for epoch in range(num_epochs):\n","        running_loss = 0.0\n","        model.train()\n","        for inputs, targets in train_loader:\n","            inputs, targets = inputs.to(device), targets.to(device)\n","\n","            outputs = model(inputs)\n","            loss = criterion(outputs, targets)\n","\n","            loss.backward()\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","            running_loss += loss.item()\n","\n","        epoch_progress_bar.update(1)\n","\n","        # Print average loss for the epoch\n","        test_results = test_network(model, test_dataset, criterion, test_results, epoch, device, printable=(epoch_progress_bar if ((epoch+1) % 15 == 0) else None), test_train = 'test')\n","        train_results = test_network(model, train_dataset, criterion, test_results, epoch, device, printable=(epoch_progress_bar if ((epoch+1) % 15 == 0) else None), test_train = 'train')\n","\n","    del model\n","    del inputs\n","    del targets\n","    del optimizer\n","    del criterion\n","    del loss\n","    gc.collect()\n","    if device == 'cuda': torch.cuda.empty_cache()\n","    elif device == 'mps': torch.mps.empty_cache()\n","\n","    print(\"Training finished!\")\n","    return test_results, train_results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ha95p49VjS-I"},"outputs":[],"source":["DIR = \"spectrogram_tensors\"\n","FILEPATH = \"/content\"\n","\n","X = dataset[dataset['supercategory']=='music']['filename'].tolist()\n","Y = dataset[dataset['supercategory']=='music']['category'].map(lambda x: LABEL_MAPPINGS[x]).tolist()\n","\n","label_encoder = LabelEncoder()\n","Y_encoded = label_encoder.fit_transform(Y)\n","\n","label_mappings = {encoded_label: original_label for original_label, encoded_label in zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))}\n","print(label_mappings)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0JoO1V9rh25P"},"outputs":[],"source":["for spectrogram_type in ['mfcc_spectrograms', 'cqt_spectrograms', 'mel_spectrograms', 'spectrograms']:\n","  for spectrogram_files in os.listdir(f\"{FILEPATH}/{DIR}/{spectrogram_type}\"):\n","    if not os.path.isfile(f\"{FILEPATH}/{DIR}/{spectrogram_type}/{spectrogram_files}/train.csv\") and os.path.isfile(f\"{FILEPATH}/{DIR}/{spectrogram_type}/{spectrogram_files}/train.pt\"):\n","      print(f\"{spectrogram_type}/{spectrogram_files}\")\n","      train_dataset = torch.load(f\"{FILEPATH}/{DIR}/{spectrogram_type}/{spectrogram_files}/train.pt\")\n","      test_dataset = torch.load(f\"{FILEPATH}/{DIR}/{spectrogram_type}/{spectrogram_files}/test.pt\")\n","\n","      x_shape = train_dataset[0][0].shape\n","      scale_factor = min(30000/(x_shape[0] * x_shape[1]), 1)\n","\n","      transform = transforms.Compose([\n","          transforms.ToTensor(),\n","          transforms.Resize(tuple(int(dim * scale_factor) for dim in x_shape), antialias=True)\n","      ])\n","\n","      train_dataset = [(transform(sample.numpy()), target) for sample, target in train_dataset]\n","      test_dataset = [(transform(sample.numpy()), target) for sample, target in test_dataset]\n","\n","      flattened_x_shape = int(x_shape[0]* scale_factor) * int(x_shape[1] * scale_factor)\n","\n","\n","      model = Triangle_Network(flattened_x_shape, len(label_encoder.classes_), beta=False).to(device)\n","      num_epochs = 120\n","\n","      criterion = nn.CrossEntropyLoss()\n","      #optimizer = optim.SGD(model.parameters(), lr=0.01)\n","      optimizer = optim.Adam(model.parameters(), lr=0.0005)\n","\n","      batch_size = 32\n","      train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","      test_results = df()\n","      train_results = df()\n","\n","      epoch_progress_bar = tqdm(total=num_epochs, desc=\"Training Progress\", position=0)\n","\n","      for epoch in range(num_epochs):\n","          running_loss = 0.0\n","          model.train()\n","          for inputs, targets in train_loader:\n","              inputs, targets = inputs.to(device), targets.to(device)\n","\n","              outputs = model(inputs)\n","              loss = criterion(outputs, targets)\n","\n","              loss.backward()\n","              optimizer.step()\n","              optimizer.zero_grad()\n","\n","              running_loss += loss.item()\n","\n","          epoch_progress_bar.update(1)\n","\n","          # Print average loss for the epoch\n","          test_results = test_network(model, test_dataset, criterion, test_results, epoch, device, printable=(epoch_progress_bar if ((epoch+1) % 15 == 0) else None), test_train = 'test')\n","          train_results = test_network(model, train_dataset, criterion, train_results, epoch, device, printable=(epoch_progress_bar if ((epoch+1) % 15 == 0) else None), test_train = 'train')\n","\n","      del model\n","      del inputs\n","      del targets\n","      del optimizer\n","      del criterion\n","      del loss\n","      gc.collect()\n","      if device == 'cuda': torch.cuda.empty_cache()\n","      elif device == 'mps': torch.mps.empty_cache()\n","\n","      test_results.to_csv(f\"/content/drive/MyDrive/spectrogram_tensors/{spectrogram_type}/{spectrogram_files}/test.csv\")\n","      train_results.to_csv(f\"/content/drive/MyDrive/spectrogram_tensors/{spectrogram_type}/{spectrogram_files}/train.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eLIP4saookhS"},"outputs":[],"source":["%reset"]},{"cell_type":"markdown","metadata":{},"source":["# Input Encodings"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["from snntorch import functional as SF\n","\n","FILEPATH = \"../\"\n","TEST_TYPE = \"IST non-JNB results/input_encoding\"\n","SPECTROGRAMS = ['mel_spectrograms','mfcc_spectrograms']"]},{"cell_type":"markdown","metadata":{},"source":["## Direct Encoding"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ENCODING_TYPE = \"direct_encoding\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for spectrogram_type in SPECTROGRAMS:\n","    if not os.path.isfile(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/train.csv\") and os.path.isfile(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/train.pt\"):\n","        print(f\"{spectrogram_type}\")\n","        train_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/train.pt\")\n","        test_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/test.pt\")\n","\n","        # Get the shape of the first sample (train_dataset[0]) of data (x) within the dataset\n","        x_shape = train_dataset[0][0].shape\n","\n","        # Assuming the shape is t x f\n","        features_shape = x_shape[1]\n","        POP_ENCODING = 10\n","        classes = len(label_encoder.classes_)\n","        output_shape = classes * POP_ENCODING\n","\n","\n","        model = Triangle_Network(features_shape, output_shape, beta=0.9, time_dependent=True).to(device)\n","        num_epochs = 100\n","\n","        criterion = criterion = PopulationCrossEntropyLoss(num_classes=classes)\n","\n","        optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","        batch_size = 125\n","        train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=10, shuffle=True)\n","\n","        test_results = df()\n","        train_results = df()\n","\n","        epoch_progress_bar = tqdm(total=num_epochs, desc=\"Training Progress\", position=0)\n","    \n","        for epoch in range(num_epochs):\n","            running_loss = 0.0\n","            acc = 0\n","            total = 0\n","            model.train()\n","            for inputs, targets in train_loader:\n","                inputs, targets = inputs.transpose(0, 1).to(device), targets.to(device)\n","\n","                spikes, _ = model(inputs)\n","\n","                loss = criterion(spikes, targets)\n","\n","                loss.backward()\n","                optimizer.step()\n","                optimizer.zero_grad()\n","\n","                running_loss += loss.item()\n","                total += spikes.size(1)\n","\n","            epoch_progress_bar.update(1)\n","\n","            print(f\"Epoch {epoch+1} Running loss: {running_loss/total}\")\n","            \n","            # Print average loss for the epoch\n","            if ((epoch+1) % 5 == 0):\n","                to_print = (epoch_progress_bar if ((epoch+1) % 15 == 0) else None)\n","                test_results = test_spiking_network(model, test_dataset, criterion, test_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'test')\n","                train_results = test_spiking_network(model, train_dataset, criterion, train_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'train')\n","\n","        del model\n","        del inputs\n","        del targets\n","        del optimizer\n","        del criterion\n","        del loss\n","        gc.collect()\n","        if device == 'cuda': torch.cuda.empty_cache()\n","        elif device == 'mps': torch.mps.empty_cache()\n","\n","        test_results.to_csv(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/test.csv\")\n","        train_results.to_csv(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/train.csv\")"]},{"cell_type":"markdown","metadata":{},"source":["## Time Contrast Imports"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from delta import delta"]},{"cell_type":"markdown","metadata":{},"source":["## Direct Time Contrast"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["NON_ENCODED = \"direct_encoding\"\n","ENCODING_TYPE = \"direct_TC_encoding\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for spectrogram_type in ['mfcc_spectrograms', 'mel_spectrograms']:\n","    original_test_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{NON_ENCODED}/{spectrogram_type}/test.pt\")\n","    original_train_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{NON_ENCODED}/{spectrogram_type}/train.pt\")\n","\n","    direct_TC_test = delta(original_test_dataset, padding = True)\n","    direct_TC_train = delta(original_train_dataset, padding = True)\n","\n","    torch.save(direct_TC_test, f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/test.pt\")\n","    torch.save(direct_TC_train, f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/train.pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for spectrogram_type in SPECTROGRAMS:\n","    if not os.path.isfile(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/train.csv\") and os.path.isfile(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/train.pt\"):\n","        print(f\"{spectrogram_type}\")\n","        train_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/train.pt\")\n","        test_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/test.pt\")\n","\n","        # Get the shape of the first sample (train_dataset[0]) of data (x) within the dataset\n","        x_shape = train_dataset[0][0].shape\n","\n","        # Assuming the shape is t x f\n","        features_shape = x_shape[1]\n","        POP_ENCODING = 10\n","        classes = len(label_encoder.classes_)\n","        output_shape = classes * POP_ENCODING\n","\n","\n","        model = Triangle_Network(features_shape, output_shape, beta=0.9, time_dependent=True).to(device)\n","        num_epochs = 100\n","\n","        criterion = PopulationCrossEntropyLoss(num_classes=classes)\n","\n","        optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","        batch_size = 125\n","        train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=10, shuffle=True)\n","\n","        test_results = df()\n","        train_results = df()\n","\n","        epoch_progress_bar = tqdm(total=num_epochs, desc=\"Training Progress\", position=0)\n","    \n","        for epoch in range(num_epochs):\n","            running_loss = 0.0\n","            acc = 0\n","            total = 0\n","            model.train()\n","            for inputs, targets in train_loader:\n","                # inputs in form of (time, batch, features)\n","                inputs, targets = inputs.transpose(0, 1).to(device), targets.to(device)\n","\n","                spikes, _ = model(inputs)\n","\n","                loss = criterion(spikes, targets)\n","\n","                loss.backward()\n","                optimizer.step()\n","                optimizer.zero_grad()\n","\n","                running_loss += loss.item()\n","                total += spikes.size(0)\n","\n","            epoch_progress_bar.update(1)\n","\n","            print(f\"Epoch {epoch+1} Running loss: {running_loss/total}\")\n","            \n","            # Print average loss for the epoch\n","            if ((epoch+1) % 5 == 0):\n","                to_print = (epoch_progress_bar if ((epoch+1) % 15 == 0) else None)\n","                test_results = test_spiking_network(model, test_dataset, criterion, test_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'test')\n","                train_results = test_spiking_network(model, train_dataset, criterion, train_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'train')\n","\n","        del model\n","        del inputs\n","        del targets\n","        del optimizer\n","        del criterion\n","        del loss\n","        gc.collect()\n","        if device == 'cuda': torch.cuda.empty_cache()\n","        elif device == 'mps': torch.mps.empty_cache()\n","\n","        test_results.to_csv(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/test.csv\")\n","        train_results.to_csv(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/train.csv\")"]},{"cell_type":"markdown","metadata":{},"source":["## Time Contrast or Threshold Based"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from delta import delta\n","\n","NON_ENCODED = \"direct_encoding\"\n","ENCODING_TYPE = \"time_contrast\"\n","\n","THRESHOLDS = [0.01, 0.025, 0.05, 0.10, 0.20, 0.50]\n","OFF_SPIKES = [True, False]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for spectrogram_type in SPECTROGRAMS:\n","    for threshold in THRESHOLDS:\n","        for off_spike in OFF_SPIKES:\n","            original_test_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{NON_ENCODED}/{spectrogram_type}/test.pt\")\n","            original_train_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{NON_ENCODED}/{spectrogram_type}/train.pt\")\n","\n","            TC_test = delta(original_test_dataset, padding = True, threshold=threshold, off_spike=off_spike, threshold_as_percentage=True)\n","            TC_train = delta(original_train_dataset, padding = True, threshold=threshold, off_spike=off_spike, threshold_as_percentage=True)\n","\n","            os.makedirs(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{threshold}_{off_spike}/{spectrogram_type}\", exist_ok=True)\n","\n","            torch.save(TC_test, f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{threshold}_{off_spike}/{spectrogram_type}/test.pt\")\n","            torch.save(TC_train, f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{threshold}_{off_spike}/{spectrogram_type}/train.pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for spectrogram_type in SPECTROGRAMS:\n","    for threshold in THRESHOLDS:\n","        for off_spike in OFF_SPIKES:\n","            if not os.path.isfile(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{threshold}_{off_spike}/{spectrogram_type}/train.csv\") and os.path.isfile(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{threshold}_{off_spike}/{spectrogram_type}/train.pt\"):\n","                print(f\"{threshold}_{off_spike}_{spectrogram_type}\")\n","                train_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{threshold}_{off_spike}/{spectrogram_type}/train.pt\")\n","                test_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{threshold}_{off_spike}/{spectrogram_type}/test.pt\")\n","\n","                # Get the shape of the first sample (train_dataset[0]) of data (x) within the dataset\n","                x_shape = train_dataset[0][0].shape\n","\n","                # Assuming the shape is t x f\n","                features_shape = x_shape[1]\n","                POP_ENCODING = 10\n","                classes = len(label_encoder.classes_)\n","                output_shape = classes * POP_ENCODING\n","\n","\n","                model = Triangle_Network(features_shape, output_shape, beta=0.9, time_dependent=True).to(device)\n","                num_epochs = 100\n","\n","                criterion = PopulationCrossEntropyLoss(num_classes=classes)\n","\n","                optimizer = optim.Adam(model.parameters(), lr=0.005)\n","\n","                batch_size = 120\n","                train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=10, shuffle=True)\n","\n","                test_results = df()\n","                train_results = df()\n","\n","                epoch_progress_bar = tqdm(total=num_epochs, desc=\"Training Progress\", position=0)\n","\n","                for epoch in range(num_epochs):\n","                    running_loss = 0.0\n","                    total = 0\n","                    model.train()\n","                    for inputs, targets in train_loader:\n","                        # inputs in form of (time, batch, features)\n","                        inputs, targets = inputs.transpose(0, 1).to(device), targets.to(device)\n","\n","                        spikes, _ = model(inputs)\n","\n","                        loss = criterion(spikes, targets)\n","\n","                        loss.backward()\n","                        optimizer.step()\n","                        optimizer.zero_grad()\n","\n","                        running_loss += loss.item()\n","                        total += spikes.size(0)\n","\n","                    epoch_progress_bar.update(1)\n","\n","                    print(f\"Epoch {epoch+1} Running loss: {running_loss/total}\")\n","                    \n","                    # Print average loss for the epoch\n","                    if ((epoch+1) % 5 == 0):\n","                        test_results = test_spiking_network(model, test_dataset, criterion, test_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'test')\n","                        train_results = test_spiking_network(model, train_dataset, criterion, train_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'train')\n","\n","                del model\n","                del inputs\n","                del targets\n","                del optimizer\n","                del criterion\n","                del loss\n","                gc.collect()\n","                if device == 'cuda': torch.cuda.empty_cache()\n","                elif device == 'mps': torch.mps.empty_cache()\n","\n","                test_results.to_csv(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{threshold}_{off_spike}/{spectrogram_type}/test.csv\")\n","                train_results.to_csv(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{threshold}_{off_spike}/{spectrogram_type}/train.csv\")"]},{"cell_type":"markdown","metadata":{},"source":["## Cumulative Time Contrast (SF)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from delta import delta\n","\n","NON_ENCODED = \"direct_encoding\"\n","ENCODING_TYPE = \"step_forward\"\n","\n","THRESHOLDS = [0.01, 0.025, 0.05, 0.10, 0.20, 0.50]\n","OFF_SPIKES = [True, False]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for spectrogram_type in SPECTROGRAMS:\n","    for threshold in THRESHOLDS:\n","        for off_spike in OFF_SPIKES:\n","            original_test_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{NON_ENCODED}/{spectrogram_type}/test.pt\")\n","            original_train_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{NON_ENCODED}/{spectrogram_type}/train.pt\")\n","\n","            TC_test = delta(original_test_dataset, padding = True, threshold=threshold, off_spike=off_spike, threshold_as_percentage=True, cumulative=True)\n","            TC_train = delta(original_train_dataset, padding = True, threshold=threshold, off_spike=off_spike, threshold_as_percentage=True, cumulative=True)\n","\n","            os.makedirs(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{threshold}_{off_spike}/{spectrogram_type}\", exist_ok=True)\n","\n","            torch.save(TC_test, f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{threshold}_{off_spike}/{spectrogram_type}/test.pt\")\n","            torch.save(TC_train, f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{threshold}_{off_spike}/{spectrogram_type}/train.pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for spectrogram_type in SPECTROGRAMS:\n","    for threshold in THRESHOLDS:\n","        for off_spike in OFF_SPIKES:\n","            if not os.path.isfile(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{threshold}_{off_spike}/{spectrogram_type}/train.csv\") and os.path.isfile(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{threshold}_{off_spike}/{spectrogram_type}/train.pt\"):\n","                print(f\"{threshold}_{off_spike}_{spectrogram_type}\")\n","                train_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{threshold}_{off_spike}/{spectrogram_type}/train.pt\")\n","                test_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{threshold}_{off_spike}/{spectrogram_type}/test.pt\")\n","\n","                # Get the shape of the first sample (train_dataset[0]) of data (x) within the dataset\n","                x_shape = train_dataset[0][0].shape\n","\n","                # Assuming the shape is t x f\n","                features_shape = x_shape[1]\n","                POP_ENCODING = 10\n","                classes = len(label_encoder.classes_)\n","                output_shape = classes * POP_ENCODING\n","\n","\n","                model = Triangle_Network(features_shape, output_shape, beta=0.9, time_dependent=True).to(device)\n","                num_epochs = 100\n","\n","                criterion = PopulationCrossEntropyLoss(num_classes=classes)\n","\n","                optimizer = optim.Adam(model.parameters(), lr=0.005)\n","\n","                batch_size = 120\n","                train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=10, shuffle=True)\n","\n","                test_results = df()\n","                train_results = df()\n","\n","                epoch_progress_bar = tqdm(total=num_epochs, desc=\"Training Progress\", position=0)\n","\n","                for epoch in range(num_epochs):\n","                    running_loss = 0.0\n","                    total = 0\n","                    model.train()\n","                    for inputs, targets in train_loader:\n","                        # inputs in form of (time, batch, features)\n","                        inputs, targets = inputs.transpose(0, 1).to(device), targets.to(device)\n","\n","                        spikes, _ = model(inputs)\n","\n","                        loss = criterion(spikes, targets)\n","\n","                        loss.backward()\n","                        optimizer.step()\n","                        optimizer.zero_grad()\n","\n","                        running_loss += loss.item()\n","                        total += spikes.size(0)\n","\n","                    epoch_progress_bar.update(1)\n","\n","                    print(f\"Epoch {epoch+1} Running loss: {running_loss/total}\")\n","                    \n","                    # Print average loss for the epoch\n","                    if ((epoch+1) % 5 == 0):\n","                        test_results = test_spiking_network(model, test_dataset, criterion, test_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'test')\n","                        train_results = test_spiking_network(model, train_dataset, criterion, train_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'train')\n","\n","                del model\n","                del inputs\n","                del targets\n","                del optimizer\n","                del criterion\n","                del loss\n","                gc.collect()\n","                if device == 'cuda': torch.cuda.empty_cache()\n","                elif device == 'mps': torch.mps.empty_cache()\n","\n","                test_results.to_csv(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{threshold}_{off_spike}/{spectrogram_type}/test.csv\")\n","                train_results.to_csv(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{threshold}_{off_spike}/{spectrogram_type}/train.csv\")"]},{"cell_type":"markdown","metadata":{},"source":["## Rate Encoding Imports"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["from rate import rate, count"]},{"cell_type":"markdown","metadata":{},"source":["## Count Encoding (Whole Spectrogram)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["NON_ENCODED = \"direct_encoding\"\n","ENCODING_TYPE = \"count_encoding\"\n","SUB = \"whole\"\n","\n","for spectrogram_type in SPECTROGRAMS:\n","    for n_count in [5,7,10,15]:\n","        original_test_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{NON_ENCODED}/{spectrogram_type}/test.pt\")\n","        original_train_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{NON_ENCODED}/{spectrogram_type}/train.pt\")\n","\n","        poisson_test = count(original_test_dataset, max_spikes=n_count)\n","        poisson_train = count(original_train_dataset, max_spikes=n_count)\n","\n","        os.makedirs(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{SUB}/{n_count}/{spectrogram_type}\", exist_ok=True)\n","\n","        torch.save(poisson_test, f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{SUB}/{n_count}/{spectrogram_type}/test.pt\")\n","        torch.save(poisson_train, f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{SUB}/{n_count}/{spectrogram_type}/train.pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for spectrogram_type in SPECTROGRAMS:\n","    for n_count in [5,7,10,15]:\n","        if not os.path.isfile(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{SUB}/{n_count}/{spectrogram_type}/train.csv\") and os.path.isfile(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{SUB}/{n_count}/{spectrogram_type}/train.pt\"):\n","            print(f\"{spectrogram_type}\")\n","            train_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{SUB}/{n_count}/{spectrogram_type}/train.pt\")\n","            test_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{SUB}/{n_count}/{spectrogram_type}/test.pt\")\n","\n","            x_shape = train_dataset[0][0].shape\n","            scale_factor = min(30000/(x_shape[0] * x_shape[1]), 1)\n","\n","            transform = transforms.Compose([\n","                transforms.ToTensor(),\n","                transforms.Resize((n_count, int(x_shape[1]*scale_factor)), antialias=True)\n","            ])\n","\n","            train_dataset = [(transform(sample.numpy()).squeeze(), target) for sample, target in train_dataset]\n","            test_dataset = [(transform(sample.numpy()).squeeze(), target) for sample, target in test_dataset]\n","\n","            flattened_x_shape = int(x_shape[1]*scale_factor)\n","\n","            features_shape = flattened_x_shape\n","            POP_ENCODING = 10\n","            classes = len(label_encoder.classes_)\n","            output_shape = classes * POP_ENCODING\n","\n","\n","\n","            model = Triangle_Network(features_shape, output_shape, beta=0.9, time_dependent=True).to(device)\n","            num_epochs = 100\n","\n","            criterion = PopulationCrossEntropyLoss(num_classes=classes)\n","\n","            optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","            batch_size = 120\n","            train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=10, shuffle=True)\n","\n","            test_results = df()\n","            train_results = df()\n","\n","            epoch_progress_bar = tqdm(total=num_epochs, desc=\"Training Progress\", position=0)\n","\n","            for epoch in range(num_epochs):\n","                running_loss = 0.0\n","                total = 0\n","                model.train()\n","                for inputs, targets in train_loader:\n","                    # inputs in form of (time, batch, features)\n","                    inputs, targets = inputs.transpose(0, 1).to(device), targets.to(device)\n","\n","                    spikes, _ = model(inputs)\n","\n","                    loss = criterion(spikes, targets)\n","\n","                    loss.backward()\n","                    optimizer.step()\n","                    optimizer.zero_grad()\n","\n","                    running_loss += loss.item()\n","                    total += spikes.size(0)\n","\n","                epoch_progress_bar.update(1)\n","\n","                print(f\"Epoch {epoch+1} Running loss: {running_loss/total}\")\n","                \n","                # Print average loss for the epoch\n","                if ((epoch+1) % 5 == 0):\n","                    test_results = test_spiking_network(model, test_dataset, criterion, test_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'test')\n","                    train_results = test_spiking_network(model, train_dataset, criterion, train_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'train')\n","\n","            del model\n","            del inputs\n","            del targets\n","            del optimizer\n","            del criterion\n","            del loss\n","            gc.collect()\n","            if device == 'cuda': torch.cuda.empty_cache()\n","            elif device == 'mps': torch.mps.empty_cache()\n","\n","            test_results.to_csv(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{SUB}/{n_count}/{spectrogram_type}/test.csv\")\n","            train_results.to_csv(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{SUB}/{n_count}/{spectrogram_type}/train.csv\")"]},{"cell_type":"markdown","metadata":{},"source":["## Count Encoding (Extending Dims)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["NON_ENCODED = \"direct_encoding\"\n","ENCODING_TYPE = \"count_encoding\"\n","SUB = \"extend\"\n","\n","for spectrogram_type in SPECTROGRAMS:\n","    for n_count in [5,7,10,15]:\n","        original_test_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{NON_ENCODED}/{spectrogram_type}/test.pt\")\n","        original_train_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{NON_ENCODED}/{spectrogram_type}/train.pt\")\n","\n","        poisson_test = count(original_test_dataset, max_spikes=n_count, time_varying=True)\n","        poisson_train = count(original_train_dataset, max_spikes=n_count, time_varying=True)\n","\n","        os.makedirs(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{SUB}/{n_count}/{spectrogram_type}\", exist_ok=True)\n","\n","        torch.save(poisson_test, f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{SUB}/{n_count}/{spectrogram_type}/test.pt\")\n","        torch.save(poisson_train, f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{SUB}/{n_count}/{spectrogram_type}/train.pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for spectrogram_type in SPECTROGRAMS:\n","    for n_count in [5,7,10,15]:\n","        if not os.path.isfile(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{SUB}/{n_count}/{spectrogram_type}/train.csv\") and os.path.isfile(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{SUB}/{n_count}/{spectrogram_type}/train.pt\"):\n","            print(f\"{spectrogram_type}\")\n","            train_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{SUB}/{n_count}/{spectrogram_type}/train.pt\")\n","            test_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{SUB}/{n_count}/{spectrogram_type}/test.pt\")\n","\n","            # Get the shape of the first sample (train_dataset[0]) of data (x) within the dataset\n","            x_shape = train_dataset[0][0].shape\n","\n","            # Assuming the shape is t x f\n","            features_shape = x_shape[1]\n","            POP_ENCODING = 10\n","            classes = len(label_encoder.classes_)\n","            output_shape = classes * POP_ENCODING\n","\n","\n","            model = Triangle_Network(features_shape, output_shape, beta=0.9, time_dependent=True).to(device)\n","            num_epochs = 120\n","\n","            criterion = PopulationCrossEntropyLoss(num_classes=classes)\n","\n","            optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","            batch_size = 120\n","            train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=10, shuffle=True)\n","\n","            test_results = df()\n","            train_results = df()\n","\n","            epoch_progress_bar = tqdm(total=num_epochs, desc=\"Training Progress\", position=0)\n","\n","            for epoch in range(num_epochs):\n","                running_loss = 0.0\n","                total = 0\n","                model.train()\n","                for inputs, targets in train_loader:\n","                    # inputs in form of (time, batch, features)\n","                    inputs, targets = inputs.transpose(0, 1).to(device), targets.to(device)\n","\n","                    spikes, _ = model(inputs)\n","\n","                    loss = criterion(spikes, targets)\n","\n","                    loss.backward()\n","                    optimizer.step()\n","                    optimizer.zero_grad()\n","\n","                    running_loss += loss.item()\n","                    total += spikes.size(0)\n","\n","                epoch_progress_bar.update(1)\n","\n","                print(f\"Epoch {epoch+1} Running loss: {running_loss/total}\")\n","                \n","                # Print average loss for the epoch\n","                if ((epoch+1) % 5 == 0):\n","                    test_results = test_spiking_network(model, test_dataset, criterion, test_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'test')\n","                    train_results = test_spiking_network(model, train_dataset, criterion, train_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'train')\n","\n","            del model\n","            del inputs\n","            del targets\n","            del optimizer\n","            del criterion\n","            del loss\n","            gc.collect()\n","            if device == 'cuda': torch.cuda.empty_cache()\n","            elif device == 'mps': torch.mps.empty_cache()\n","\n","            test_results.to_csv(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{SUB}/{n_count}/{spectrogram_type}/test.csv\")\n","            train_results.to_csv(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{SUB}/{n_count}/{spectrogram_type}/train.csv\")"]},{"cell_type":"markdown","metadata":{},"source":["## Poisson Encoding (Whole Spectrogram)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["NON_ENCODED = \"direct_encoding\"\n","ENCODING_TYPE = \"poisson_whole\""]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([361, 5, 40064])\n","torch.Size([361, 7, 40064])\n","torch.Size([361, 10, 40064])\n","torch.Size([361, 15, 40064])\n","torch.Size([361, 5, 4069])\n","torch.Size([361, 7, 4069])\n","torch.Size([361, 10, 4069])\n","torch.Size([361, 15, 4069])\n"]}],"source":["for spectrogram_type in SPECTROGRAMS:\n","    for n_count in [5,7,10,15]:\n","        original_test_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{NON_ENCODED}/{spectrogram_type}/test.pt\")\n","        original_train_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{NON_ENCODED}/{spectrogram_type}/train.pt\")\n","\n","        poisson_test = rate(original_test_dataset, extend=False, num_steps=n_count)\n","        poisson_train = rate(original_train_dataset, extend=False, num_steps=n_count)\n","\n","        print(poisson_train.tensors[0].shape)\n","\n","        os.makedirs(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{n_count}/{spectrogram_type}\", exist_ok=True)\n","\n","        torch.save(poisson_test, f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{n_count}/{spectrogram_type}/test.pt\")\n","        torch.save(poisson_train, f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{n_count}/{spectrogram_type}/train.pt\")"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["mel_spectrograms\n"]},{"ename":"RuntimeError","evalue":"Invalid buffer size: 5.98 GB","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(label_encoder\u001b[38;5;241m.\u001b[39mclasses_)\n\u001b[1;32m     14\u001b[0m output_shape \u001b[38;5;241m=\u001b[39m classes \u001b[38;5;241m*\u001b[39m POP_ENCODING\n\u001b[0;32m---> 17\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mTriangle_Network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_dependent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m     20\u001b[0m criterion \u001b[38;5;241m=\u001b[39m PopulationCrossEntropyLoss(num_classes\u001b[38;5;241m=\u001b[39mclasses)\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1152\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:825\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 825\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    826\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1150\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mRuntimeError\u001b[0m: Invalid buffer size: 5.98 GB"]}],"source":["for spectrogram_type in SPECTROGRAMS:\n","    for n_count in [5,7,10,15]:\n","        if not os.path.isfile(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{n_count}/{spectrogram_type}/train.csv\") and os.path.isfile(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{n_count}/{spectrogram_type}/train.pt\"):\n","            print(f\"{spectrogram_type}\")\n","            train_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{n_count}/{spectrogram_type}/train.pt\")\n","            test_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{n_count}/{spectrogram_type}/test.pt\")\n","\n","            x_shape = train_dataset[0][0].shape\n","            scale_factor = min(30000/(x_shape[0] * x_shape[1]), 1)\n","\n","            transform = transforms.Compose([\n","                transforms.ToTensor(),\n","                transforms.Resize((n_count, int(x_shape[1]*scale_factor)), antialias=True)\n","            ])\n","\n","            train_dataset = [(transform(sample.numpy()).squeeze(), target) for sample, target in train_dataset]\n","            test_dataset = [(transform(sample.numpy()).squeeze(), target) for sample, target in test_dataset]\n","\n","            flattened_x_shape = int(x_shape[1]*scale_factor)\n","\n","            features_shape = flattened_x_shape\n","            POP_ENCODING = 10\n","            classes = len(label_encoder.classes_)\n","            output_shape = classes * POP_ENCODING\n","\n","\n","            model = Triangle_Network(features_shape, output_shape, beta=0.9, time_dependent=True).to(device)\n","            num_epochs = 100\n","\n","            criterion = PopulationCrossEntropyLoss(num_classes=classes)\n","\n","            optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","            batch_size = 120\n","            train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=10, shuffle=True)\n","\n","            test_results = df()\n","            train_results = df()\n","\n","            epoch_progress_bar = tqdm(total=num_epochs, desc=\"Training Progress\", position=0)\n","\n","            for epoch in range(num_epochs):\n","                running_loss = 0.0\n","                total = 0\n","                model.train()\n","                for inputs, targets in train_loader:\n","                    # inputs in form of (time, batch, features)\n","                    inputs, targets = inputs.transpose(0, 1).to(device), targets.to(device)\n","                    print(inputs.shape)\n","\n","                    spikes, _ = model(inputs)\n","                    print(spikes.shape)\n","\n","                    loss = criterion(spikes, targets)\n","\n","                    loss.backward()\n","                    optimizer.step()\n","                    optimizer.zero_grad()\n","\n","                    running_loss += loss.item()\n","                    total += spikes.size(0)\n","\n","                epoch_progress_bar.update(1)\n","\n","                print(f\"Epoch {epoch+1} Running loss: {running_loss/total}\")\n","\n","                # Print average loss for the epoch\n","                if ((epoch+1) % 5 == 0):\n","                    test_results = test_spiking_network(model, test_dataset, criterion, test_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'test')\n","                    train_results = test_spiking_network(model, train_dataset, criterion, train_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'train')\n","\n","            del model\n","            del inputs\n","            del targets\n","            del optimizer\n","            del criterion\n","            del loss\n","            gc.collect()\n","            if device == 'cuda': torch.cuda.empty_cache()\n","            elif device == 'mps': torch.mps.empty_cache()\n","\n","            test_results.to_csv(f\"{FILEPATH}/{ENCODING_TYPE}/{n_count}/{spectrogram_type}/test.csv\")\n","            train_results.to_csv(f\"{FILEPATH}/{ENCODING_TYPE}/{n_count}/{spectrogram_type}/train.csv\")"]},{"cell_type":"markdown","metadata":{},"source":["## Poisson Encoding (Keeping Dimensions)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["NON_ENCODED = \"direct_encoding\"\n","ENCODING_TYPE = \"poisson_dims\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for spectrogram_type in SPECTROGRAMS:\n","    original_test_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{NON_ENCODED}/{spectrogram_type}/test.pt\")\n","    original_train_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{NON_ENCODED}/{spectrogram_type}/train.pt\")\n","\n","    poisson_test = rate(original_test_dataset)\n","    poisson_train = rate(original_train_dataset)\n","\n","    os.makedirs(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}\", exist_ok=True)\n","\n","    torch.save(poisson_test, f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/test.pt\")\n","    torch.save(poisson_train, f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/train.pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for spectrogram_type in SPECTROGRAMS:\n","    if not os.path.isfile(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/train.csv\") and os.path.isfile(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/train.pt\"):\n","        print(f\"{spectrogram_type}\")\n","        train_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/train.pt\")\n","        test_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/test.pt\")\n","\n","        # Get the shape of the first sample (train_dataset[0]) of data (x) within the dataset\n","        x_shape = train_dataset[0][0].shape\n","\n","        # Assuming the shape is t x f\n","        features_shape = x_shape[1]\n","        POP_ENCODING = 10\n","        classes = len(label_encoder.classes_)\n","        output_shape = classes * POP_ENCODING\n","\n","\n","        model = Triangle_Network(features_shape, output_shape, beta=0.9, time_dependent=True).to(device)\n","        num_epochs = 100\n","\n","        criterion = PopulationCrossEntropyLoss(num_classes=classes)\n","\n","        optimizer = optim.Adam(model.parameters(), lr=0.005)\n","\n","        batch_size = 100\n","        train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=10, shuffle=True)\n","\n","        test_results = df()\n","        test_results = df()\n","\n","        epoch_progress_bar = tqdm(total=num_epochs, desc=\"Training Progress\", position=0)\n","\n","        for epoch in range(num_epochs):\n","            running_loss = 0.0\n","            total = 0\n","            model.train()\n","            for inputs, targets in train_loader:\n","                # inputs in form of (time, batch, features)\n","                inputs, targets = inputs.transpose(0, 1).to(device), targets.to(device)\n","\n","                spikes, _ = model(inputs)\n","\n","                loss = criterion(spikes, targets)\n","\n","                loss.backward()\n","                optimizer.step()\n","                optimizer.zero_grad()\n","\n","                running_loss += loss.item()\n","                total += spikes.size(0)\n","\n","            epoch_progress_bar.update(1)\n","\n","            print(f\"Epoch {epoch+1} Running loss: {running_loss/total}\")\n","            \n","            # Print average loss for the epoch\n","            if ((epoch+1) % 5 == 0):\n","                test_results = test_spiking_network(model, test_dataset, criterion, test_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'test')\n","                train_results = test_spiking_network(model, train_dataset, criterion, train_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'train')\n","\n","        del model\n","        del inputs\n","        del targets\n","        del optimizer\n","        del criterion\n","        del loss\n","        gc.collect()\n","        if device == 'cuda': torch.cuda.empty_cache()\n","        elif device == 'mps': torch.mps.empty_cache()\n","\n","        test_results.to_csv(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/test.csv\")\n","        train_results.to_csv(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/train.csv\")"]},{"cell_type":"markdown","metadata":{},"source":["## Poisson Encoding (Extending Dims)"]},{"cell_type":"markdown","metadata":{},"source":["### Note that this took too long for Count Encoding (Extending Dims) --- i.e. it takes upwards of 50hrs to train Count_n=15"]},{"cell_type":"markdown","metadata":{},"source":["## Autoencoder"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from snntorch import utils\n","\n","FILEPATH = \"../\"\n","TEST_TYPE = \"IST non-JNB results/input_encoding\"\n","DATA_ENCODING = \"direct_encoding\"\n","ENCODING_TYPE = \"autoencoder\"\n","\n","SPECTROGRAMS = [\"mfcc_spectrograms\", \"mel_spectrograms\"]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class AutoEncoder(nn.Module):\n","    def __init__(self, features_shape, coding_size):\n","        super().__init__()\n","\n","        # Encoder and Decoder is not time dependent within themselves. Time is handled by the Autoencoder\n","\n","        # Encoder\n","        self.encoder = Triangle_Network(features_shape, coding_size, beta=0.9, time_dependent=False)\n","\n","        # Decoder\n","        self.decoder = Triangle_Network(coding_size, features_shape, beta=0.9, time_dependent=False)\n","\n","    def forward(self, x):\n","        utils.reset(self.encoder)\n","        utils.reset(self.decoder)\n","\n","        # Assume the data is in the form [time x batch x features]\n","        num_steps = x.size(0)\n","\n","        spk_mem2=[]\n","        spk_rec=[]\n","        \n","        # Over the time dimension\n","        for step in range(num_steps):\n","            # Encode\n","            spk_x, _ = self.encoder(x[step])\n","            spk_rec.append(spk_x)\n","            \n","            # Decode\n","            _, x_mem_recon = self.decoder(spk_x)\n","            spk_mem2.append(x_mem_recon)\n","\n","\n","        # Same Dimensions as input: [time x batch x features]\n","        spk_rec = torch.stack(spk_rec,dim=0)\n","        spk_mem2 = torch.stack(spk_mem2,dim=0)\n","\n","        return spk_mem2\n","    \n","    def encode(self,x):\n","        utils.reset(self.encoder)\n","        num_steps = x.size(0)\n","        spk_rec = []\n","        spk_mem = []\n","        for step in range(num_steps):\n","            spk_x, mem_x = self.encoder(x[step])\n","            spk_rec.append(spk_x)\n","            spk_mem.append(mem_x)\n","        spk_rec = torch.stack(spk_rec,dim=0)\n","        spk_mem = torch.stack(spk_mem,dim=0)\n","        return spk_rec, spk_mem\n","\n","    def decode(self,x):\n","        utils.reset(self.decoder)\n","        num_steps = x.size(0)\n","        spk_rec = []\n","        spk_mem = []\n","        for step in range(num_steps):\n","            spk_x, mem_x = self.decoder(x[step])\n","            spk_rec.append(spk_x)\n","            spk_mem.append(mem_x)\n","        spk_rec = torch.stack(spk_rec,dim=0)\n","        spk_mem = torch.stack(spk_mem,dim=0)\n","        return spk_rec, spk_mem\n","    \n","    def to(self, device):\n","        super().to(device)\n","        self.encoder = self.encoder.to(device)\n","        self.decoder = self.decoder.to(device)\n","        return self\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["TOLERANCE = 0.05 #dB\n","\n","def check_accuracy(model, test_dataset: TensorDataset, train_dataset: TensorDataset):\n","    model.eval()\n","    test_x, _ = test_dataset.tensors\n","    train_x, _ = train_dataset.tensors\n","    data = torch.cat((test_x, train_x), dim=0).to(device)\n","\n","    mem = model(data).detach().cpu().numpy()\n","\n","    # Check predictions against tolerance\n","    within_tolerance = np.abs(data.detach().cpu().numpy() - mem) <= TOLERANCE\n","\n","    # Calculate accuracy\n","    accuracy = np.mean(within_tolerance) * 100\n","\n","    return accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Set upper and lower bound percentages of the encoded layer\n","upper_bound = 1.0\n","lower_bound = 0.5\n","MAX_MODELS = 4\n","\n","input_dir = f\"{FILEPATH}IST non-JNB results/input_encoding/autoencoder\"\n","output_dir = f\"{FILEPATH}IST non-JNB results/input_encoding/autoencoder\"\n","\n","for spectrogram_type in SPECTROGRAMS:\n","    i = 0; upper_bound = 1.0; lower_bound = 0.5\n","    while i < MAX_MODELS:\n","        mid_bound = (upper_bound + lower_bound) / 2\n","        if os.path.isfile(f\"{FILEPATH}/{TEST_TYPE}/{DATA_ENCODING}/{spectrogram_type}/train.pt\") and not os.path.isfile(f\"{input_dir}/{mid_bound}/{spectrogram_type}/model.pt\"):\n","            print(f\"{i+1}. {spectrogram_type} {mid_bound}\")\n","            train_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{DATA_ENCODING}/{spectrogram_type}/train.pt\")\n","            test_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{DATA_ENCODING}/{spectrogram_type}/test.pt\")\n","\n","            # Get the shape of the first sample (train_dataset[0]) of data (x) within the dataset\n","            x_shape = train_dataset[0][0].shape\n","\n","            # Assuming the shape is t x f\n","            features_shape = x_shape[1]\n","\n","            model = AutoEncoder(features_shape, round(features_shape * mid_bound)).to(device)\n","            num_epochs = 75\n","\n","            criterion = nn.L1Loss()\n","\n","            optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","            # Higher batch size for quicker training and a more general model\n","            batch_size = 175\n","            train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=3, shuffle=True)\n","\n","            results = df()\n","\n","            epoch_progress_bar = tqdm(total=num_epochs, desc=\"Training Progress\", position=0)\n","\n","            for epoch in range(num_epochs):\n","                running_loss = 0.0\n","                total = 0\n","                model.train()\n","                for inputs, _ in train_loader:\n","                    # inputs in form of (time, batch, features)\n","                    inputs = inputs.transpose(0, 1).to(device)\n","\n","                    mem = model(inputs)\n","\n","                    loss = criterion(mem, inputs)\n","\n","                    loss.backward()\n","                    optimizer.step()\n","                    optimizer.zero_grad()\n","\n","                    running_loss += loss.item()\n","                    total += mem.size(0)\n","\n","\n","                epoch_progress_bar.update(1)\n","                \n","\n","                accuracy = check_accuracy(model, test_dataset, train_dataset)\n","                epoch_progress_bar.set_description(f\"Epoch {epoch+1} Running loss: {running_loss/total} Accuracy (within 5dB): {accuracy}\")\n","                results = results._append({'Epoch': epoch+1, 'Loss': running_loss/total, 'Accuracy (within 5dB)': accuracy}, ignore_index=True)\n","\n","\n","                # Decrease upper bound on success -- save models\n","                if accuracy >= 90:\n","                    success = True\n","                    if accuracy == 100:\n","                        i = MAX_MODELS\n","                        print(\"100% Accuracy -- breaking\")\n","                    print(\"Within 90% -- trying towards lower bound\")\n","\n","                    upper_bound = mid_bound; i += 1\n","\n","                    os.makedirs(f\"{FILEPATH}{TEST_TYPE}/autoencoder/{mid_bound}/{spectrogram_type}\", exist_ok=True)\n","                    torch.save(model, f\"{FILEPATH}{TEST_TYPE}/autoencoder/{mid_bound}/{spectrogram_type}/model.pt\")\n","                    results.to_csv(f\"{FILEPATH}{TEST_TYPE}/autoencoder/{mid_bound}/{spectrogram_type}/model.csv\")\n","                    break\n","            \n","            # Raise lower bound on fail\n","            os.makedirs(f\"{FILEPATH}{TEST_TYPE}/autoencoder/{mid_bound}/{spectrogram_type}\", exist_ok=True)\n","            torch.save(model.state_dict(), f\"{FILEPATH}{TEST_TYPE}/autoencoder/{mid_bound}/{spectrogram_type}/model.pt\")\n","            results.to_csv(f\"{FILEPATH}{TEST_TYPE}/autoencoder/{mid_bound}/{spectrogram_type}/model.csv\")\n","\n","\n","            model.eval()\n","\n","            inputs, targets = train_dataset.tensors\n","            inputs = inputs.transpose(0, 1).to(device)\n","            num_steps = inputs.size(0)\n","            \n","            spikes, _ = model.encode(inputs)\n","            spikes = spikes.transpose(0, 1)\n","\n","            train_encode = TensorDataset(spikes.detach().cpu(), targets)\n","            torch.save(train_encode, f\"{output_dir}/{mid_bound}/{spectrogram_type}/train.pt\")\n","\n","\n","            inputs, targets = test_dataset.tensors\n","            inputs = inputs.transpose(0, 1).to(device)\n","            \n","            spikes, _ = model.encode(inputs)\n","            spikes = spikes.transpose(0, 1)\n","\n","            test_encode = TensorDataset(spikes.detach().cpu(), targets)\n","            torch.save(test_encode, f\"{output_dir}/{mid_bound}/{spectrogram_type}/test.pt\")\n","\n","\n","            del model\n","            del inputs\n","            del optimizer\n","            del criterion\n","            del loss\n","            gc.collect()\n","            if device == 'cuda': torch.cuda.empty_cache()\n","            elif device == 'mps': torch.mps.empty_cache()\n","\n","        lower_bound = mid_bound; i += 1\n","                \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for spectrogram_type in SPECTROGRAMS:\n","    for autoencoder in [0.75, 0.875, 0.9375, 0.96875]:\n","        input_dir = f\"{FILEPATH}/IST non-JNB results/input_encoding/autoencoder/{autoencoder}/{spectrogram_type}\"\n","        output_dir = f\"{FILEPATH}/IST non-JNB results/input_encoding/autoencoder/{autoencoder}/{spectrogram_type}\"\n","        if os.path.isfile(f\"{input_dir}/train.pt\") and not os.path.isfile(f\"{output_dir}/train.csv\"):\n","            print(f\"{spectrogram_type} {autoencoder}\")\n","            train_dataset = torch.load(f\"{input_dir}/train.pt\"); train_x, train_y = train_dataset.tensors; train_dataset = TensorDataset(Tensor(train_x.detach().cpu().numpy()), Tensor(train_y.detach().cpu().numpy()))\n","            test_dataset = torch.load(f\"{input_dir}/test.pt\"); test_x, test_y = test_dataset.tensors; test_dataset = TensorDataset(Tensor(test_x.detach().cpu().numpy()), Tensor(test_y.detach().cpu().numpy()))\n","\n","\n","            # Get the shape of the first sample (train_dataset[0]) of data (x) within the dataset\n","            x_shape = train_dataset[0][0].shape\n","\n","            # Assuming the shape is t x f\n","            features_shape = x_shape[1]\n","            POP_ENCODING = 10\n","            classes = len(label_encoder.classes_)\n","            output_shape = classes * POP_ENCODING\n","\n","\n","            model = Triangle_Network(features_shape, output_shape, beta=0.9, time_dependent=True).to(device)\n","            num_epochs = 100\n","\n","            criterion = PopulationCrossEntropyLoss(num_classes=classes)\n","\n","            optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","            batch_size = 120\n","            train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=10, shuffle=True)\n","\n","            test_results = df()\n","            train_results = df()\n","\n","            epoch_progress_bar = tqdm(total=num_epochs, desc=\"Training Progress\", position=0)\n","\n","            for epoch in range(num_epochs):\n","                running_loss = 0.0\n","                total = 0\n","                model.train()\n","                for inputs, targets in train_loader:\n","                    # inputs in form of (time, batch, features)\n","                    inputs, targets = inputs.transpose(0, 1).to(device), targets.to(device)\n","\n","                    spikes, _ = model(inputs)\n","\n","                    loss = criterion(spikes, targets)\n","\n","                    loss.backward()\n","                    optimizer.step()\n","                    optimizer.zero_grad()\n","\n","                    running_loss += loss.item()\n","                    total += spikes.size(0)\n","\n","                epoch_progress_bar.update(1)\n","\n","                print(f\"Epoch {epoch+1} Running loss: {running_loss/total}\")\n","                \n","                # Print average loss for the epoch\n","                if ((epoch+1) % 5 == 0):\n","                    test_results = test_spiking_network(model, test_dataset, criterion, test_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'test')\n","                    train_results = test_spiking_network(model, train_dataset, criterion, train_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'train')\n","\n","            del model\n","            del inputs\n","            del targets\n","            del optimizer\n","            del criterion\n","            del loss\n","            gc.collect()\n","            if device == 'cuda': torch.cuda.empty_cache()\n","            elif device == 'mps': torch.mps.empty_cache()\n","\n","            os.makedirs(f\"{output_dir}\", exist_ok=True)\n","            test_results.to_csv(f\"{output_dir}/test.csv\")\n","            train_results.to_csv(f\"{output_dir}/train.csv\")"]},{"cell_type":"markdown","metadata":{},"source":["# Architectures & Action Potentials"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["FILEPATH = \"../\"\n","TEST_TYPE = \"IST non-JNB results/architectures\"\n","ENCODING = \"time_contrast/0.1_True/mel_spectrograms\""]},{"cell_type":"markdown","metadata":{},"source":["## MLP (Triangle)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Ignore beta = 0.90 as this has been worked out before depending on the input dataset\n","BETAS = [0.70, 0.80, 0.95]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for beta in BETAS:\n","    input_dir = f\"{FILEPATH}/IST non-JNB results/input_encoding/{ENCODING}\"\n","    output_dir = f\"{FILEPATH}/{TEST_TYPE}/MLP/{beta}\"\n","    if  os.path.isfile(f\"{input_dir}/train.pt\") and not os.path.isfile(f\"{output_dir}/train.csv\"):\n","        print(f\"{beta}\")\n","        train_dataset = torch.load(f\"{input_dir}/train.pt\")\n","        test_dataset = torch.load(f\"{input_dir}/test.pt\")\n","\n","        # Get the shape of the first sample (train_dataset[0]) of data (x) within the dataset\n","        x_shape = train_dataset[0][0].shape\n","\n","        # Assuming the shape is t x f\n","        features_shape = x_shape[1]\n","        POP_ENCODING = 10\n","        classes = len(label_encoder.classes_)\n","        output_shape = classes * POP_ENCODING\n","\n","\n","        model = Triangle_Network(features_shape, output_shape, beta=0.9, time_dependent=True).to(device)\n","        num_epochs = 100\n","\n","        criterion = PopulationCrossEntropyLoss(num_classes=classes)\n","\n","        optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","        batch_size = 120\n","        train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=10, shuffle=True)\n","\n","        test_results = df()\n","        train_results = df()\n","\n","        epoch_progress_bar = tqdm(total=num_epochs, desc=\"Training Progress\", position=0)\n","\n","        for epoch in range(num_epochs):\n","            running_loss = 0.0\n","            total = 0\n","            model.train()\n","            for inputs, targets in train_loader:\n","                # inputs in form of (time, batch, features)\n","                inputs, targets = inputs.transpose(0, 1).to(device), targets.to(device)\n","\n","                spikes, _ = model(inputs)\n","\n","                loss = criterion(spikes, targets)\n","\n","                loss.backward()\n","                optimizer.step()\n","                optimizer.zero_grad()\n","\n","                running_loss += loss.item()\n","                total += spikes.size(0)\n","\n","            epoch_progress_bar.update(1)\n","\n","            print(f\"Epoch {epoch+1} Running loss: {running_loss/total}\")\n","            \n","            # Print average loss for the epoch\n","            if ((epoch+1) % 5 == 0):\n","                test_results = test_spiking_network(model, test_dataset, criterion, test_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'test')\n","                train_results = test_spiking_network(model, train_dataset, criterion, train_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'train')\n","\n","        del model\n","        del inputs\n","        del targets\n","        del optimizer\n","        del criterion\n","        del loss\n","        gc.collect()\n","        if device == 'cuda': torch.cuda.empty_cache()\n","        elif device == 'mps': torch.mps.empty_cache()\n","\n","        os.makedirs(f\"{output_dir}\", exist_ok=True)\n","        test_results.to_csv(f\"{output_dir}/test.csv\")\n","        train_results.to_csv(f\"{output_dir}/train.csv\")"]},{"cell_type":"markdown","metadata":{},"source":["## Convolutional Neural Network"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch.nn.functional as F"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class CNN(nn.Module):\n","    def __init__(self, num_outputs, beta):\n","        super().__init__()\n","\n","        # Initialize layers\n","        self.conv1 = nn.Conv1d(1, 12, kernel_size=5)\n","        self.lif1 = snn.Leaky(beta=beta)\n","        self.conv2 = nn.Conv1d(12, 64, kernel_size=5)\n","        self.lif2 = snn.Leaky(beta=beta)\n","        self.fc1 = nn.Linear(64*29, num_outputs)\n","        self.lif3 = snn.Leaky(beta=beta)\n","\n","    def forward(self, x):\n","\n","        # Initialize hidden states and outputs at t=0\n","        mem1 = self.lif1.init_leaky()\n","        mem2 = self.lif2.init_leaky()\n","        mem3 = self.lif3.init_leaky()\n","\n","        spk_rec = []; mem_rec = []\n","\n","        # Add Channel so in form (time, batch, channel, features)\n","        x = x.unsqueeze(2)\n","\n","        for step in range(x.size(0)):\n","            cur1 = F.max_pool1d(self.conv1(x[step]), 2)\n","            spk1, mem1 = self.lif1(cur1, mem1)\n","\n","            cur2 = F.max_pool1d(self.conv2(spk1), 2)\n","            spk2, mem2 = self.lif2(cur2, mem2)\n","\n","            cur3 = self.fc1(spk2.view(spk2.size(0), -1))\n","\n","            spk3, mem3 = self.lif3(cur3, mem3)\n","\n","            spk_rec.append(spk3)\n","            mem_rec.append(mem3)\n","\n","\n","        return torch.stack(spk_rec, dim=0), torch.stack(mem_rec, dim=0)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["BETAS = [0.70, 0.80, 0.90, 0.95]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for beta in BETAS:\n","    input_dir = f\"{FILEPATH}/IST non-JNB results/input_encoding/{ENCODING}\"\n","    output_dir = f\"{FILEPATH}/{TEST_TYPE}/CNN/{beta}\"\n","    if not os.path.isfile(f\"{output_dir}/train.csv\") and os.path.isfile(f\"{input_dir}/train.pt\"):\n","        print(f\"{beta}\")\n","        train_dataset = torch.load(f\"{input_dir}/train.pt\")\n","        test_dataset = torch.load(f\"{input_dir}/test.pt\")\n","\n","        # Get the shape of the first sample (train_dataset[0]) of data (x) within the dataset\n","        x_shape = train_dataset[0][0].shape\n","\n","        # Assuming the shape is t x f\n","        features_shape = x_shape[1]\n","        POP_ENCODING = 10\n","        classes = len(label_encoder.classes_)\n","        output_shape = classes * POP_ENCODING\n","\n","\n","        model = CNN(output_shape, beta=0.9).to(device)\n","        num_epochs = 100\n","\n","        criterion = PopulationCrossEntropyLoss(num_classes=classes)\n","\n","        optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","        batch_size = 120\n","        train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=10, shuffle=True)\n","\n","        test_results = df()\n","        train_results = df()\n","\n","        epoch_progress_bar = tqdm(total=num_epochs, desc=\"Training Progress\", position=0)\n","\n","        for epoch in range(num_epochs):\n","            running_loss = 0.0\n","            total = 0\n","            model.train()\n","            for inputs, targets in train_loader:\n","                # inputs in form of (time, batch, features)\n","                inputs, targets = inputs.transpose(0, 1).to(device), targets.to(device)\n","\n","                spikes, _ = model(inputs)\n","\n","                loss = criterion(spikes, targets)\n","\n","                loss.backward()\n","                optimizer.step()\n","                optimizer.zero_grad()\n","\n","                running_loss += loss.item()\n","                total += spikes.size(0)\n","\n","            epoch_progress_bar.update(1)\n","\n","            print(f\"Epoch {epoch+1} Running loss: {running_loss/total}\")\n","            \n","            # Print average loss for the epoch\n","            if ((epoch+1) % 5 == 0):\n","                test_results = test_spiking_network(model, test_dataset, criterion, test_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'test')\n","                train_results = test_spiking_network(model, train_dataset, criterion, train_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'train')\n","\n","        del model\n","        del inputs\n","        del targets\n","        del optimizer\n","        del criterion\n","        del loss\n","        gc.collect()\n","        if device == 'cuda': torch.cuda.empty_cache()\n","        elif device == 'mps': torch.mps.empty_cache()\n","\n","        os.makedirs(f\"{output_dir}\", exist_ok=True)\n","        test_results.to_csv(f\"{output_dir}/test.csv\")\n","        train_results.to_csv(f\"{output_dir}/train.csv\")"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["QrnOeGaHh25K","43m8jiuhh25L","st4_dGj4h25N"],"gpuType":"A100","private_outputs":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":0}
