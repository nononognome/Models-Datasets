{"cells":[{"cell_type":"markdown","metadata":{"id":"cHy2H4YVh25D"},"source":["# Basic Setup and Functions"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"rXuB5FHah25G"},"outputs":[{"name":"stdout","output_type":"stream","text":["Note: you may need to restart the kernel to use updated packages.\n","Using mps device\n"]}],"source":["%pip install snntorch --quiet\n","\n","import librosa, random\n","import numpy as np\n","import pandas as pd\n","import os\n","import soundfile as sf\n","\n","from pandas import DataFrame as df\n","import torch\n","\n","from sklearn.metrics import confusion_matrix, roc_auc_score, precision_score, recall_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","\n","import snntorch as snn\n","from snntorch.functional.acc import _population_code, _prediction_check\n","\n","import torch.nn as nn\n","from torch import Tensor\n","from torch.utils.data import TensorDataset, DataLoader\n","from torch import optim\n","from torchvision import transforms\n","\n","from tqdm.notebook import tqdm\n","\n","import gc\n","\n","device = (\n","    \"cuda\"\n","    if torch.cuda.is_available()\n","    else \"mps\"\n","    if torch.backends.mps.is_available()\n","    else \"cpu\"\n",")\n","\n","print(f\"Using {device} device\")"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"3ae_oxqGh25H"},"outputs":[],"source":["def Triangle_Network(num_inputs, num_outputs, beta=0.90, time_dependent = False):\n","    dy_dx = int(4/(num_outputs - num_inputs))\n","    hidden1 = num_inputs + (dy_dx * 1)\n","    hidden2 = num_inputs + (dy_dx * 2)\n","    hidden3 = num_inputs + (dy_dx * 3)\n","\n","    if beta and time_dependent:\n","        class Net(nn.Module):\n","        # Initialise network with 2 forward connections (linear connections) and 2 leaky integrated fire layers (hidden and output)\n","            def __init__(self, *args, **kwargs) -> None:\n","                super().__init__(*args, **kwargs)\n","                self.fc1 = nn.Linear(num_inputs, hidden1)\n","                self.lif1 = snn.Leaky(beta=beta)\n","                self.fc2 = nn.Linear(hidden1, hidden2)\n","                self.lif2 = snn.Leaky(beta=beta)\n","                self.fc3 = nn.Linear(hidden3, hidden3)\n","                self.lif3 = snn.Leaky(beta=beta)\n","                self.fc4 = nn.Linear(hidden3, num_outputs)\n","                self.lif4 = snn.Leaky(beta=beta)\n","\n","            # Define a forward pass assuming x is normalised data (i.e. all values in [0,1])\n","            def forward(self, x):\n","                mem1 = self.lif1.init_leaky()\n","                mem2 = self.lif2.init_leaky()\n","                mem3 = self.lif3.init_leaky()\n","                mem4 = self.lif4.init_leaky()\n","\n","                spk_rec = []\n","                mem_rec = []\n","\n","                # Insert data in shape (time x batch x features)\n","                for step in range(x.size(0)):\n","                    cur1 = self.fc1(x[step])\n","                    spk1, mem1 = self.lif1(cur1, mem1)\n","                    cur2 = self.fc2(spk1)\n","                    spk2, mem2 = self.lif2(cur2, mem2)\n","                    cur3 = self.fc3(spk2)\n","                    spk3, mem3 = self.lif3(cur3, mem3)\n","                    cur4 = self.fc4(spk3)\n","                    spk4, mem4 = self.lif4(cur4, mem4)\n","\n","                    spk_rec.append(spk4)\n","                    mem_rec.append(mem4)\n","\n","                return torch.stack(spk_rec, dim=0), torch.stack(mem_rec, dim=0)\n","            \n","        return Net()\n","\n","\n","    elif beta and not time_dependent: return nn.Sequential(nn.Flatten(),\n","                    nn.Linear(num_inputs, hidden1),\n","                    snn.Leaky(beta=beta, init_hidden=True),\n","                    nn.Linear(hidden1, hidden2),\n","                    snn.Leaky(beta=beta, init_hidden=True),\n","                    nn.Linear(hidden2, hidden3),\n","                    snn.Leaky(beta=beta, init_hidden=True),\n","                    nn.Linear(hidden3, num_outputs),\n","                    snn.Leaky(beta=beta, init_hidden=True, output=True))\n","\n","    else: return nn.Sequential(nn.Flatten(),\n","                    nn.Linear(num_inputs, hidden1),\n","                    nn.ReLU(),\n","                    nn.Linear(hidden1, hidden2),\n","                    nn.ReLU(),\n","                    nn.Linear(hidden2, hidden3),\n","                    nn.ReLU(),\n","                    nn.Linear(hidden3, num_outputs))"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"_6kx2Evvh25I"},"outputs":[],"source":["def test_spiking_network(model, dataset, loss_fn, results: df, epoch, device, num_classes=False, printable=None, train_test = 'test'):\n","    dataloader = DataLoader(dataset, batch_size=100, num_workers=3, shuffle=False)\n","    model.eval()\n","    with torch.no_grad():\n","        test_loss = 0.0\n","        correct = 0\n","        total = 0\n","        total_spikes = 0\n","        all_labels = []\n","        all_predicted = []\n","        all_probs = []\n","\n","        for data, labels in dataloader:\n","            x, labels = data.transpose(0, 1).to(device), labels.to(device)\n","            spikes, _ = model(x)\n","            test_loss += loss_fn(spikes, labels).item()\n","            \n","            if num_classes: _, predicted = _population_code(spikes, num_classes=num_classes, num_outputs=spikes.size(-1)).max(1)\n","            else: _, predicted = spikes.sum(dim=1).max(1)\n","\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","            all_labels.extend(labels.cpu().numpy())\n","            all_predicted.extend(predicted.cpu().numpy())\n","\n","            if num_classes: num_spikes = _population_code(spikes, num_classes=num_classes, num_outputs=spikes.size(-1))\n","            else: num_spikes = spikes.sum(dim=1)\n","            \n","            softmax = torch.nn.Softmax(dim=1)\n","            probabilities = softmax(num_spikes)\n","            all_probs.extend(probabilities.cpu().numpy())\n","        \n","            total_spikes += spikes.size(1)\n","\n","        test_loss /= total_spikes\n","\n","    # Accuracy\n","    accuracy = 100 * correct / total\n","\n","    # Confusion Matrix\n","    cm = confusion_matrix(all_labels, all_predicted)\n","\n","    # Recall/Sensitivity -- avoiding div by 0\n","    recall = recall_score(all_labels, all_predicted, average='weighted', zero_division=0) * 100\n","\n","    # Precision\n","    precision = precision_score(all_labels, all_predicted, average='weighted', zero_division=0) * 100\n","\n","    # F1 Score\n","    f1_score = (2 * precision * recall) / (precision + recall)\n","\n","    # AUC-ROC\n","    auc_roc = 100 * roc_auc_score(all_labels, all_probs, multi_class='ovr')\n","    \n","    if printable: printable.set_description(\n","        f'Epoch [{epoch + 1}] {train_test} Loss: {test_loss / len(dataloader):.2f} '\n","        f'{train_test} Accuracy: {accuracy:.2f}% F1: {f1_score}% Recall: {recall:.2f}% Precision: {precision:.2f}% '\n","        f'AUC-ROC: {auc_roc:.4f}%'\n","    )\n","\n","    results = results._append({\n","            'Epoch': epoch + 1,\n","            'Accuracy': accuracy,\n","            'F1': f1_score,\n","            'Recall': recall,\n","            'Precision': precision,\n","            'Test Loss': test_loss / len(dataloader),\n","            'AUC-ROC': auc_roc,\n","            'Confusion Matrix': cm\n","        }, ignore_index=True)\n","\n","    del data\n","    del labels\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","\n","    return results"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["class PopulationCrossEntropyLoss():\n","    def __init__(self, num_classes=2):\n","        self.num_classes = num_classes\n","        self.__name__ = \"PopulationCrossEntropyLoss\"\n","\n","    def __call__(self, spk_out, targets):\n","        loss_fn = nn.CrossEntropyLoss()\n","        \n","        _, _, num_outputs = _prediction_check(spk_out)\n","\n","        spike_count = _population_code(\n","                spk_out, self.num_classes, num_outputs\n","            )\n","\n","        loss = loss_fn(spike_count, targets)\n","\n","        return loss\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"q93J30hEh25J"},"outputs":[],"source":["LABEL_MAPPINGS = {\n","    'westernart/classical': 'Classical',\n","    'indierock/pop': 'Rock',\n","    'pop/soul/electronica': 'Electronic',\n","    'electronica': 'Electronic',\n","    'jazz': 'Jazz',\n","    'pop/hiphop/rock': 'Pop',\n","    'rap/hiphop': 'Hiphop',\n","    'rock': 'Rock',\n","    'rock/folk': 'Rock',\n","    'westernart/baroque': 'Classical',\n","    'electronica/dance': 'Electronic',\n","    'westernart/romantic': 'Classical',\n","    'blues': 'Jazz',\n","    'pop/folk': 'Pop',\n","    'westernart/romantic/classical': 'Classical',\n","    'pop/electronica': 'Electronic',\n","    'latin': 'Jazz',\n","    'country/folk': 'Country',\n","    'indierock/folk/pop': 'Rock',\n","    'jazz/blues': 'Jazz',\n","    'pop/rap/rock/hiphop': 'Pop',\n","    'pop/experimental': 'Pop',\n","    'blues/rock/jazz': 'Jazz',\n","    'jazz/adventure': 'Jazz',\n","    'blues/electronica': 'Jazz',\n","    'jazz/pop/soul': 'Jazz',\n","    'funk/electronica': 'Electronic',\n","    'folk/pop': 'Folk',\n","    'indierock/rock': 'Rock',\n","    'jazz/electronica': 'Electronic',\n","    'hiphop': 'Hiphop',\n","    'funk/rnb/adventure': 'Soul',\n","    'pop': 'Pop',\n","    'hiphop/rap': 'Hiphop',\n","    'pop/gospel': 'Soul',\n","    'rap/metal/electronica': 'Electronic',\n","    'pop/rock/folk': 'Rock',\n","    'pop/electronica/hiphop': 'Pop',\n","    'metal/rap': 'Hiphop',\n","    'country': 'Country',\n","    'rap/metal': 'Hiphop',\n","    'country/pop': 'Country',\n","    'folk': 'Folk',\n","    'pop/rock/dance': 'Pop',\n","    'dance': 'Electronic',\n","    'pop/jazz/latin': 'Jazz',\n","    'pop/jazz': 'Jazz',\n","    'funk/rnb/electronica': 'Electronic',\n","    'funk/blues/jazz': 'Jazz',\n","    'pop/rock/soul': 'Pop',\n","    'pop/hiphop': 'Pop',\n","    'blues/funk': 'Jazz',\n","    'rap/metal/hiphop': 'Hiphop',\n","    'blues/jazz/adventure': 'Jazz',\n","    'folk/indierock': 'Folk',\n","    'adventure': 'Classical',\n","    'metal/rock': 'Rock',\n","    'blues/rock/country': 'Jazz',\n","    'pop/soul/rnb': 'Soul',\n","    'blues/rock': 'Jazz',\n","    'blues/rock/indierock': 'Jazz',\n","    'country/pop/folk': 'Country',\n","    'country/blues/rock': 'Country',\n","    'rock/funk/country': 'Rock',\n","    'pop/rock': 'Rock',\n","    'pop/blues': 'Rock',\n","    'blues/indierock': 'Rock',\n","    'blues/rock/rnb': 'Rock',\n","    'blues/pop/folk': 'Jazz',\n","    'pop/funk/adventure': 'Pop',\n","    'blues/rock/pop': 'Rock',\n","    'folk/pop/funk': 'Folk'\n","}\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"y5-_se-YiO7P"},"outputs":[{"name":"stdout","output_type":"stream","text":["{0: 'Classical', 1: 'Country', 2: 'Electronic', 3: 'Folk', 4: 'Hiphop', 5: 'Jazz', 6: 'Pop', 7: 'Rock', 8: 'Soul'}\n"]}],"source":["try:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    !rsync -av --exclude='mel_spectrograms' --exclude='cqt_spectrograms' /content/drive/MyDrive/spectrogram_tensors/ /content/spectrogram_tensors/ --quiet\n","    FILEPATH = '/content'\n","    CSV = 'sample_ISD.csv'\n","\n","    dataset = pd.read_csv(f'/content/drive/MyDrive/{CSV}', index_col=0)\n","\n","    \n","except:\n","    FILEPATH = \"../../Datasets/SmallDataset\"\n","    ORIGINAL_DIR = \"audio\"\n","    SAMPLE_DIR = \"audio uncompressed samples\"\n","    COMPRESSED_DIR = \"audio compressed\"\n","    CSV = 'sample_ISD.csv'\n","\n","    dataset = pd.read_csv(f'{FILEPATH}/{CSV}', index_col=0)\n","\n","X = dataset['filename'].tolist()\n","Y = dataset[dataset['supercategory']=='music']['category'].map(lambda x: LABEL_MAPPINGS[x]).tolist()\n","label_encoder = LabelEncoder()\n","Y_encoded = label_encoder.fit_transform(Y)\n","\n","label_mappings = {encoded_label: original_label for original_label, encoded_label in zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))}\n","print(label_mappings)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Garbage collection special commands\n","\n","gc.collect()\n","if device == \"cuda\":\n","    torch.cuda.empty_cache()\n","    torch.cuda.memory_summary(device=None, abbreviated=False)\n","elif device == \"mps\":\n","    torch.mps.empty_cache()\n","    print(f\"MPS occupied memory: {torch.mps.driver_allocated_memory()}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Very special command -- remove all variables\n","%reset"]},{"cell_type":"markdown","metadata":{"id":"JjzopoGZh25J"},"source":["# Audio Representation"]},{"cell_type":"markdown","metadata":{"id":"QrnOeGaHh25K"},"source":["## Sampling"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5qroeHpJh25L"},"outputs":[],"source":["def sample(audio_path, duration=5.0, sr=44100):\n","    original_path = audio_path\n","    for ext in [\".m4a\", \".wav\", \".ogg\", \".flac\", \".mp3\"]:\n","        if os.path.exists(audio_path + ext):\n","            audio_path += ext\n","\n","            total_duration = librosa.get_duration(path=audio_path)\n","            y, _ = librosa.load(audio_path, sr=sr, duration=total_duration)\n","\n","            if total_duration < duration:\n","                pad_length = int((duration - total_duration) * sr)\n","                y = np.pad(y, (0, pad_length), mode='constant')\n","\n","            start = random.uniform(0, max(0, total_duration - duration))\n","            y = y[int(start * sr):int((start + duration) * sr)]\n","\n","            sf.write(f\"{FILEPATH}/{SAMPLE_DIR}/{original_path.split('/')[-1]}.wav\", y, sr)\n","\n","            return y"]},{"cell_type":"markdown","metadata":{"id":"43m8jiuhh25L"},"source":["## Bitrate and Compression"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"74ui8zpqh25M"},"outputs":[],"source":["import os\n","from tqdm.notebook import tqdm\n","from concurrent.futures import ThreadPoolExecutor\n","\n","def convert_to_mp3(input_file, output_file, sample_rate=16000, bit_rate=\"8k\", channels=1):\n","    !ffmpeg -i \"$input_file\" -ar \"$sample_rate\" -b:a \"$bitrate\" -ac \"$channels\" \"$output_file\" -hide_banner -loglevel error\n","\n","def convert_directory_to_mp3(input_dir, output_dir, sample_rate=16000, bit_rate=\"8k\"):\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    audio_files = [file for file in os.listdir(input_dir) if file.endswith((\".m4a\", \".wav\", \".ogg\", \".flac\", \".mp3\"))]\n","\n","    for file in tqdm(audio_files, desc=\"Converting\"):\n","            input_file_path = os.path.join(input_dir, file)\n","            output_file_path = os.path.join(output_dir, os.path.splitext(file)[0] + \".mp3\")\n","            convert_to_mp3(input_file_path, output_file_path, sample_rate, bit_rate)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IAUf5u8Yh25M"},"outputs":[],"source":["bitdepths = np.array([2,4,8,16,24])\n","samplerates = np.int32(np.array([8,16,22.05,32,44.1])*1000)\n","\n","with ThreadPoolExecutor() as executor:\n","    for bitdepth in bitdepths:\n","        for samplerate in samplerates:\n","            bitrate = (bitdepth * samplerate) / 1000\n","            print(f\"bitdepth: {bitdepth}, samplerate: {samplerate}\")\n","            print(f\"effective bitrate: {bitrate} kbps\")\n","\n","            executor.submit(convert_directory_to_mp3(f\"{FILEPATH}/{SAMPLE_DIR}\", f\"{FILEPATH}/{COMPRESSED_DIR}/{bitdepth}-{samplerate}\", sample_rate=samplerate, bit_rate=f\"{bitrate}k\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mEmydtY2h25M"},"outputs":[],"source":["# Assuming the directory contains all compressed files\n","!find . -mindepth 1 -maxdepth 1 -type d -exec sh -c 'find \"$1\" -type f -exec ls -l {} \\; | awk \"{sum += \\$5} END {print \\\"$1\\\", sum}\"' _ {} \\"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0K_lIJiLh25N"},"outputs":[],"source":["from mutagen.mp3 import MP3\n","\n","def get_unpacked_size(mp3_file):\n","    audio = MP3(mp3_file)\n","    duration = audio.info.length  # Duration of the audio in seconds\n","    bitrate = audio.info.bitrate  # Bitrate of the audio in bits per second\n","    # Calculate the unpacked size based on bitrate and duration\n","    unpacked_size = (duration * bitrate) / 8\n","    return unpacked_size\n","\n","\n","file_dirs = [d for d in os.listdir(f\"{FILEPATH}/{COMPRESSED_DIR}\") if os.path.isdir(f\"{FILEPATH}/{COMPRESSED_DIR}/{d}\")]\n","for bitrate in file_dirs:\n","    audio_files = [file for file in os.listdir(f\"{FILEPATH}/{COMPRESSED_DIR}/{bitrate}\") if file.endswith((\".mp3\"))]\n","    size = 0\n","    for file in audio_files:\n","        if os.path.exists(f\"{FILEPATH}/{COMPRESSED_DIR}/{bitrate}/{file}\"):\n","            size += get_unpacked_size(f\"{FILEPATH}/{COMPRESSED_DIR}/{bitrate}/{file}\")\n","    print(f\"{bitrate.split('/')[-1]}: {size} bytes\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BW6hyuwDh25N"},"outputs":[],"source":["from matplotlib import pyplot as plt\n","import tikzplotlib\n","\n","bit_two = np.array([[16,32,44.1,64,88.2],[1,3,4,5,5]]).T\n","bit_four = np.array([[32,64,88.2,128,176.4],[2,4,5,5,5]]).T\n","bit_eight = np.array([[64,128,176.4,256,352.8],[2,4,5,5,5]]).T\n","bit_sixteen = np.array([[128,256,352.8,512,705.6],[2,3,4,4,5]]).T\n","bit_twentyfour = np.array([[192,384,529.2,768,1058.4],[2,4,5,5,5]]).T\n","\n","plt.plot(bit_two[:,0], bit_two[:,1], label=\"2-bit\")\n","plt.plot(bit_four[:,0], bit_four[:,1], label=\"4-bit\")\n","plt.plot(bit_eight[:,0], bit_eight[:,1], label=\"8-bit\")\n","plt.plot(bit_sixteen[:,0], bit_sixteen[:,1], label=\"16-bit\")\n","plt.plot(bit_twentyfour[:,0], bit_twentyfour[:,1], label=\"24-bit\")\n","\n","plt.ylabel(\"Perceived Quality\")\n","plt.xlabel(\"Bitrate (kbps)\")\n","plt.xscale(\"log\")\n","plt.xlim(10,1100)\n","plt.ylim(0, 6)\n","plt.grid(True, which='both', axis='y')\n","#plt.legend()\n","\n","tikzplotlib.save(\"AudioRep/CompressionReception.tex\")"]},{"cell_type":"markdown","metadata":{"id":"st4_dGj4h25N"},"source":["## Spectrograms"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yE7h8re8h25O"},"outputs":[],"source":["import spectrograms\n","\n","AUDIO_DIR = \"compressed_audio\"\n","\n","X = dataset[dataset['supercategory']=='music']['filename'].tolist()\n","Y = dataset[dataset['supercategory']=='music']['category'].map(lambda x: LABEL_MAPPINGS[x]).tolist()\n","\n","label_encoder = LabelEncoder()\n","Y_encoded = label_encoder.fit_transform(Y)\n","\n","label_mappings = {encoded_label: original_label for original_label, encoded_label in zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))}\n","print(label_mappings)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, Y_encoded, test_size=0.2)\n","\n","waveforms_train = [spectrograms.load_from_path(f\"{FILEPATH}/{AUDIO_DIR}/{file}.mp3\") for file in X_train]\n","waveforms_test = [spectrograms.load_from_path(f\"{FILEPATH}/{AUDIO_DIR}/{file}.mp3\") for file in X_test]"]},{"cell_type":"markdown","metadata":{"id":"K_N2kwfnh25O"},"source":["### Standard Spectrogram"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vQQmRuouh25O"},"outputs":[],"source":["DIR = \"spectrogram_tensors\"\n","\n","\n","for n_fft in [512, 1024, 2048, 4096]:\n","    for win_length in [512, 1024, 2048, 4096]:\n","        if n_fft < win_length:\n","            continue\n","        else:\n","            os.makedirs(f\"{FILEPATH}/{DIR}/spectrograms/{n_fft}-{512}-{win_length}\", exist_ok=True)\n","            spectrogram_X_train = Tensor(np.array([x for x, _ in [spectrograms.spectrogram(sample, sr, hop=512, fft=n_fft, win=win_length) for sample, sr in waveforms_train]]))\n","            spectrogram_X_test = Tensor(np.array([x for x, _ in [spectrograms.spectrogram(sample, sr, hop=512, fft=n_fft, win=win_length) for sample, sr in waveforms_test]]))\n","            spectrogram_train = TensorDataset(spectrogram_X_train, torch.LongTensor(y_train))\n","            spectrogram_test = TensorDataset(spectrogram_X_test, torch.LongTensor(y_test))\n","            torch.save(spectrogram_train, f\"{FILEPATH}/{DIR}/spectrograms/{n_fft}-{512}-{win_length}/train.pt\")\n","            torch.save(spectrogram_test, f\"{FILEPATH}/{DIR}/spectrograms/{n_fft}-{512}-{win_length}/test.pt\")\n","\n","\n","for hop_length in [256, 1024, 2048]:\n","    os.makedirs(f\"{FILEPATH}/{DIR}/spectrograms/{2048}-{hop_length}-{2048}\", exist_ok=True)\n","    spectrogram_X_train = Tensor(np.array([x for x, _ in [spectrograms.spectrogram(sample, sr, hop=hop_length, fft=2048, win=2048) for sample, sr in waveforms_train]]))\n","    spectrogram_X_test = Tensor(np.array([x for x, _ in [spectrograms.spectrogram(sample, sr, hop=hop_length, fft=2048, win=2048) for sample, sr in waveforms_test]]))\n","    spectrogram_train = TensorDataset(spectrogram_X_train, torch.LongTensor(y_train))\n","    spectrogram_test = TensorDataset(spectrogram_X_test, torch.LongTensor(y_test))\n","    torch.save(spectrogram_train, f\"{FILEPATH}/{DIR}/spectrograms/{2048}-{hop_length}-{2048}/train.pt\")\n","    torch.save(spectrogram_test, f\"{FILEPATH}/{DIR}/spectrograms/{2048}-{hop_length}-{2048}/test.pt\")\n"]},{"cell_type":"markdown","metadata":{"id":"bgYyIxHJh25O"},"source":["### Mel Spectrogram"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ejZ5v5tBh25O"},"outputs":[],"source":["DIR = \"spectrogram_tensors\"\n","\n","\n","for n_fft in [512, 1024, 2048, 4096]:\n","    for win_length in [512, 1024, 2048, 4096]:\n","        if n_fft < win_length:\n","            continue\n","        else:\n","            os.makedirs(f\"{FILEPATH}/{DIR}/mel_spectrograms/{n_fft}-{512}-{win_length}-{128}\", exist_ok=True)\n","            spectrogram_X_train = Tensor(np.array([x for x, _ in [spectrograms.mel_spectrogram(sample, sr, fft=n_fft, win=win_length) for sample, sr in waveforms_train]]))\n","            spectrogram_X_test = Tensor(np.array([x for x, _ in [spectrograms.mel_spectrogram(sample, sr, fft=n_fft, win=win_length) for sample, sr in waveforms_test]]))\n","            spectrogram_train = TensorDataset(spectrogram_X_train, torch.LongTensor(y_train))\n","            spectrogram_test = TensorDataset(spectrogram_X_test, torch.LongTensor(y_test))\n","            torch.save(spectrogram_train, f\"{FILEPATH}/{DIR}/mel_spectrograms/{n_fft}-{512}-{win_length}-{128}/train.pt\")\n","            torch.save(spectrogram_test, f\"{FILEPATH}/{DIR}/mel_spectrograms/{n_fft}-{512}-{win_length}-{128}/test.pt\")\n","\n","\n","for hop_length in [256, 1024, 2048]:\n","    os.makedirs(f\"{FILEPATH}/{DIR}/mel_spectrograms/{2048}-{hop_length}-{2048}-{128}\", exist_ok=True)\n","    spectrogram_X_train = Tensor(np.array([x for x, _ in [spectrograms.mel_spectrogram(sample, sr, hop=hop_length, fft=2048, win=2048) for sample, sr in waveforms_train]]))\n","    spectrogram_X_test = Tensor(np.array([x for x, _ in [spectrograms.mel_spectrogram(sample, sr, hop=hop_length, fft=2048, win=2048) for sample, sr in waveforms_test]]))\n","    spectrogram_train = TensorDataset(spectrogram_X_train, torch.LongTensor(y_train))\n","    spectrogram_test = TensorDataset(spectrogram_X_test, torch.LongTensor(y_test))\n","    torch.save(spectrogram_train, f\"{FILEPATH}/{DIR}/mel_spectrograms/{2048}-{hop_length}-{2048}-{128}/train.pt\")\n","    torch.save(spectrogram_test, f\"{FILEPATH}/{DIR}/mel_spectrograms/{2048}-{hop_length}-{2048}-{128}/test.pt\")\n","\n","\n","for mel_features in [64, 128, 192, 256]:\n","    os.makedirs(f\"{FILEPATH}/{DIR}/mel_spectrograms/{2048}-{512}-{2048}-{mel_features}\", exist_ok=True)\n","    spectrogram_X_train = Tensor(np.array([x for x, _ in [spectrograms.mel_spectrogram(sample, sr, mel=mel_features) for sample, sr in waveforms_train]]))\n","    spectrogram_X_test = Tensor(np.array([x for x, _ in [spectrograms.mel_spectrogram(sample, sr, mel=mel_features) for sample, sr in waveforms_test]]))\n","    spectrogram_train = TensorDataset(spectrogram_X_train, torch.LongTensor(y_train))\n","    spectrogram_test = TensorDataset(spectrogram_X_test, torch.LongTensor(y_test))\n","    torch.save(spectrogram_train, f\"{FILEPATH}/{DIR}/mel_spectrograms/{2048}-{512}-{2048}-{mel_features}/train.pt\")\n","    torch.save(spectrogram_test, f\"{FILEPATH}/{DIR}/mel_spectrograms/{2048}-{512}-{2048}-{mel_features}/test.pt\")"]},{"cell_type":"markdown","metadata":{"id":"_VOfBuf6h25P"},"source":["### MFCCs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d1WeX2vLh25P"},"outputs":[],"source":["DIR = \"spectrogram_tensors\"\n","\n","for n_fft in [512, 1024, 2048, 4096]:\n","    for win_length in [512, 1024, 2048, 4096]:\n","        if n_fft < win_length:\n","            continue\n","        else:\n","            os.makedirs(f\"{FILEPATH}/{DIR}/mfcc_spectrograms/{n_fft}-{512}-{win_length}-{128}-{13}\", exist_ok=True)\n","            spectrogram_X_train = Tensor(np.array([x for x, _ in [spectrograms.mfcc_spectrogram(sample, sr, fft=n_fft, win=win_length) for sample, sr in waveforms_train]]))\n","            spectrogram_X_test = Tensor(np.array([x for x, _ in [spectrograms.mfcc_spectrogram(sample, sr, fft=n_fft, win=win_length) for sample, sr in waveforms_test]]))\n","            spectrogram_train = TensorDataset(spectrogram_X_train, torch.LongTensor(y_train))\n","            spectrogram_test = TensorDataset(spectrogram_X_test, torch.LongTensor(y_test))\n","            torch.save(spectrogram_train, f\"{FILEPATH}/{DIR}/mfcc_spectrograms/{n_fft}-{512}-{win_length}-{128}-{13}/train.pt\")\n","            torch.save(spectrogram_test, f\"{FILEPATH}/{DIR}/mfcc_spectrograms/{n_fft}-{512}-{win_length}-{128}-{13}/test.pt\")\n","\n","\n","for hop_length in [256, 1024, 2048]:\n","    os.makedirs(f\"{FILEPATH}/{DIR}/mfcc_spectrograms/{2048}-{hop_length}-{2048}-{128}-{13}\", exist_ok=True)\n","    spectrogram_X_train = Tensor(np.array([x for x, _ in [spectrograms.mfcc_spectrogram(sample, sr, hop=hop_length, fft=2048, win=2048) for sample, sr in waveforms_train]]))\n","    spectrogram_X_test = Tensor(np.array([x for x, _ in [spectrograms.mfcc_spectrogram(sample, sr, hop=hop_length, fft=2048, win=2048) for sample, sr in waveforms_test]]))\n","    spectrogram_train = TensorDataset(spectrogram_X_train, torch.LongTensor(y_train))\n","    spectrogram_test = TensorDataset(spectrogram_X_test, torch.LongTensor(y_test))\n","    torch.save(spectrogram_train, f\"{FILEPATH}/{DIR}/mfcc_spectrograms/{2048}-{hop_length}-{2048}-{128}-{13}/train.pt\")\n","    torch.save(spectrogram_test, f\"{FILEPATH}/{DIR}/mfcc_spectrograms/{2048}-{hop_length}-{2048}-{128}-{13}/test.pt\")\n","\n","\n","for mel_features in [64, 128, 192, 256]:\n","    os.makedirs(f\"{FILEPATH}/{DIR}/mfcc_spectrograms/{2048}-{512}-{2048}-{mel_features}-{13}\", exist_ok=True)\n","    spectrogram_X_train = Tensor(np.array([x for x, _ in [spectrograms.mfcc_spectrogram(sample, sr, mel=mel_features) for sample, sr in waveforms_train]]))\n","    spectrogram_X_test = Tensor(np.array([x for x, _ in [spectrograms.mfcc_spectrogram(sample, sr, mel=mel_features) for sample, sr in waveforms_test]]))\n","    spectrogram_train = TensorDataset(spectrogram_X_train, torch.LongTensor(y_train))\n","    spectrogram_test = TensorDataset(spectrogram_X_test, torch.LongTensor(y_test))\n","    torch.save(spectrogram_train, f\"{FILEPATH}/{DIR}/mfcc_spectrograms/{2048}-{512}-{2048}-{mel_features}-{13}/train.pt\")\n","    torch.save(spectrogram_test, f\"{FILEPATH}/{DIR}/mfcc_spectrograms/{2048}-{512}-{2048}-{mel_features}-{13}/test.pt\")\n","\n","for mfcc_components in [5, 9, 13, 20]:\n","    os.makedirs(f\"{FILEPATH}/{DIR}/mfcc_spectrograms/{2048}-{512}-{2048}-{128}-{mfcc_components}\", exist_ok=True)\n","    spectrogram_X_train = Tensor(np.array([x for x, _ in [spectrograms.mfcc_spectrogram(sample, sr, mfcc_bins=mfcc_components) for sample, sr in waveforms_train]]))\n","    spectrogram_X_test = Tensor(np.array([x for x, _ in [spectrograms.mfcc_spectrogram(sample, sr, mfcc_bins=mfcc_components) for sample, sr in waveforms_test]]))\n","    spectrogram_train = TensorDataset(spectrogram_X_train, torch.LongTensor(y_train))\n","    spectrogram_test = TensorDataset(spectrogram_X_test, torch.LongTensor(y_test))\n","    torch.save(spectrogram_train, f\"{FILEPATH}/{DIR}/mfcc_spectrograms/{2048}-{512}-{2048}-{128}-{mfcc_components}/train.pt\")\n","    torch.save(spectrogram_test, f\"{FILEPATH}/{DIR}/mfcc_spectrograms/{2048}-{512}-{2048}-{128}-{mfcc_components}/test.pt\")"]},{"cell_type":"markdown","metadata":{"id":"quC-qqvvh25P"},"source":["### CQT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dYLOq4ruh25P"},"outputs":[],"source":["for hop_length in [256, 512, 1024, 2048]:\n","    os.makedirs(f\"{FILEPATH}/{DIR}/cqt_spectrograms/{hop_length}\", exist_ok=True)\n","    spectrogram_X_train = Tensor(np.array([x for x, _ in [spectrograms.cqt_spectrogram(sample, sr, hop=hop_length) for sample, sr in waveforms_train]]))\n","    spectrogram_X_test = Tensor(np.array([x for x, _ in [spectrograms.cqt_spectrogram(sample, sr, hop=hop_length) for sample, sr in waveforms_test]]))\n","    spectrogram_train = TensorDataset(spectrogram_X_train, torch.LongTensor(y_train))\n","    spectrogram_test = TensorDataset(spectrogram_X_test, torch.LongTensor(y_test))\n","    torch.save(spectrogram_train, f\"{FILEPATH}/{DIR}/cqt_spectrograms/{hop_length}/train.pt\")\n","    torch.save(spectrogram_test, f\"{FILEPATH}/{DIR}/cqt_spectrograms/{hop_length}/test.pt\")"]},{"cell_type":"markdown","metadata":{"id":"v-ac1vMrh25P"},"source":["# ANN Baseline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xEiy6I9ph25P"},"outputs":[],"source":["def train(model, train_dataset, test_dataset, num_epochs, device):\n","    criterion = nn.CrossEntropyLoss()\n","    #optimizer = optim.SGD(model.parameters(), lr=0.01)\n","    optimizer = optim.Adam(model.parameters(), lr=0.0005)\n","\n","    batch_size = 32\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","    test_results = df()\n","    train_results = df()\n","\n","    epoch_progress_bar = tqdm(total=num_epochs, desc=\"Training Progress\", position=0)\n","\n","    for epoch in range(num_epochs):\n","        running_loss = 0.0\n","        model.train()\n","        for inputs, targets in train_loader:\n","            inputs, targets = inputs.to(device), targets.to(device)\n","\n","            outputs = model(inputs)\n","            loss = criterion(outputs, targets)\n","\n","            loss.backward()\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","            running_loss += loss.item()\n","\n","        epoch_progress_bar.update(1)\n","\n","        # Print average loss for the epoch\n","        test_results = test_network(model, test_dataset, criterion, test_results, epoch, device, printable=(epoch_progress_bar if ((epoch+1) % 15 == 0) else None), test_train = 'test')\n","        train_results = test_network(model, train_dataset, criterion, test_results, epoch, device, printable=(epoch_progress_bar if ((epoch+1) % 15 == 0) else None), test_train = 'train')\n","\n","    del model\n","    del inputs\n","    del targets\n","    del optimizer\n","    del criterion\n","    del loss\n","    gc.collect()\n","    if device == 'cuda': torch.cuda.empty_cache()\n","    elif device == 'mps': torch.mps.empty_cache()\n","\n","    print(\"Training finished!\")\n","    return test_results, train_results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ha95p49VjS-I"},"outputs":[],"source":["DIR = \"spectrogram_tensors\"\n","FILEPATH = \"/content\"\n","\n","X = dataset[dataset['supercategory']=='music']['filename'].tolist()\n","Y = dataset[dataset['supercategory']=='music']['category'].map(lambda x: LABEL_MAPPINGS[x]).tolist()\n","\n","label_encoder = LabelEncoder()\n","Y_encoded = label_encoder.fit_transform(Y)\n","\n","label_mappings = {encoded_label: original_label for original_label, encoded_label in zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))}\n","print(label_mappings)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0JoO1V9rh25P"},"outputs":[],"source":["for spectrogram_type in ['mfcc_spectrograms', 'cqt_spectrograms', 'mel_spectrograms', 'spectrograms']:\n","  for spectrogram_files in os.listdir(f\"{FILEPATH}/{DIR}/{spectrogram_type}\"):\n","    if not os.path.isfile(f\"{FILEPATH}/{DIR}/{spectrogram_type}/{spectrogram_files}/train.csv\") and os.path.isfile(f\"{FILEPATH}/{DIR}/{spectrogram_type}/{spectrogram_files}/train.pt\"):\n","      print(f\"{spectrogram_type}/{spectrogram_files}\")\n","      train_dataset = torch.load(f\"{FILEPATH}/{DIR}/{spectrogram_type}/{spectrogram_files}/train.pt\")\n","      test_dataset = torch.load(f\"{FILEPATH}/{DIR}/{spectrogram_type}/{spectrogram_files}/test.pt\")\n","\n","      x_shape = train_dataset[0][0].shape\n","      scale_factor = min(30000/(x_shape[0] * x_shape[1]), 1)\n","\n","      transform = transforms.Compose([\n","          transforms.ToTensor(),\n","          transforms.Resize(tuple(int(dim * scale_factor) for dim in x_shape), antialias=True)\n","      ])\n","\n","      train_dataset = [(transform(sample.numpy()), target) for sample, target in train_dataset]\n","      test_dataset = [(transform(sample.numpy()), target) for sample, target in test_dataset]\n","\n","      flattened_x_shape = int(x_shape[0]* scale_factor) * int(x_shape[1] * scale_factor)\n","\n","\n","      model = Triangle_Network(flattened_x_shape, len(label_encoder.classes_), beta=False).to(device)\n","      num_epochs = 120\n","\n","      criterion = nn.CrossEntropyLoss()\n","      #optimizer = optim.SGD(model.parameters(), lr=0.01)\n","      optimizer = optim.Adam(model.parameters(), lr=0.0005)\n","\n","      batch_size = 32\n","      train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","      test_results = df()\n","      train_results = df()\n","\n","      epoch_progress_bar = tqdm(total=num_epochs, desc=\"Training Progress\", position=0)\n","\n","      for epoch in range(num_epochs):\n","          running_loss = 0.0\n","          model.train()\n","          for inputs, targets in train_loader:\n","              inputs, targets = inputs.to(device), targets.to(device)\n","\n","              outputs = model(inputs)\n","              loss = criterion(outputs, targets)\n","\n","              loss.backward()\n","              optimizer.step()\n","              optimizer.zero_grad()\n","\n","              running_loss += loss.item()\n","\n","          epoch_progress_bar.update(1)\n","\n","          # Print average loss for the epoch\n","          test_results = test_network(model, test_dataset, criterion, test_results, epoch, device, printable=(epoch_progress_bar if ((epoch+1) % 15 == 0) else None), test_train = 'test')\n","          train_results = test_network(model, train_dataset, criterion, train_results, epoch, device, printable=(epoch_progress_bar if ((epoch+1) % 15 == 0) else None), test_train = 'train')\n","\n","      del model\n","      del inputs\n","      del targets\n","      del optimizer\n","      del criterion\n","      del loss\n","      gc.collect()\n","      if device == 'cuda': torch.cuda.empty_cache()\n","      elif device == 'mps': torch.mps.empty_cache()\n","\n","      test_results.to_csv(f\"/content/drive/MyDrive/spectrogram_tensors/{spectrogram_type}/{spectrogram_files}/test.csv\")\n","      train_results.to_csv(f\"/content/drive/MyDrive/spectrogram_tensors/{spectrogram_type}/{spectrogram_files}/train.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eLIP4saookhS"},"outputs":[],"source":["%reset"]},{"cell_type":"markdown","metadata":{},"source":["# Input Encodings"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["from snntorch import functional as SF\n","\n","FILEPATH = \"../\"\n","TEST_TYPE = \"IST non-JNB results/input_encoding\"\n","SPECTROGRAMS = ['mel_spectrograms']"]},{"cell_type":"markdown","metadata":{},"source":["## Direct Encoding"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ENCODING_TYPE = \"direct_encoding\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for spectrogram_type in SPECTROGRAMS:\n","    if not os.path.isfile(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/train.csv\") and os.path.isfile(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/train.pt\"):\n","        print(f\"{spectrogram_type}\")\n","        train_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/train.pt\")\n","        test_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/test.pt\")\n","\n","        # Get the shape of the first sample (train_dataset[0]) of data (x) within the dataset\n","        x_shape = train_dataset[0][0].shape\n","\n","        # Assuming the shape is t x f\n","        features_shape = x_shape[1]\n","        POP_ENCODING = 10\n","        classes = len(label_encoder.classes_)\n","        output_shape = classes * POP_ENCODING\n","\n","\n","        model = Triangle_Network(features_shape, output_shape, beta=0.9, time_dependent=True).to(device)\n","        num_epochs = 100\n","\n","        criterion = criterion = PopulationCrossEntropyLoss(num_classes=classes)\n","\n","        optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","        batch_size = 125\n","        train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=10, shuffle=True)\n","\n","        test_results = df()\n","        train_results = df()\n","\n","        epoch_progress_bar = tqdm(total=num_epochs, desc=\"Training Progress\", position=0)\n","    \n","        for epoch in range(num_epochs):\n","            running_loss = 0.0\n","            acc = 0\n","            total = 0\n","            model.train()\n","            for inputs, targets in train_loader:\n","                inputs, targets = inputs.transpose(0, 1).to(device), targets.to(device)\n","\n","                spikes, _ = model(inputs)\n","\n","                loss = criterion(spikes, targets)\n","\n","                loss.backward()\n","                optimizer.step()\n","                optimizer.zero_grad()\n","\n","                running_loss += loss.item()\n","                total += spikes.size(1)\n","\n","            epoch_progress_bar.update(1)\n","\n","            print(f\"Epoch {epoch+1} Running loss: {running_loss/total}\")\n","            \n","            # Print average loss for the epoch\n","            if ((epoch+1) % 5 == 0):\n","                to_print = (epoch_progress_bar if ((epoch+1) % 15 == 0) else None)\n","                test_results = test_spiking_network(model, test_dataset, criterion, test_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'test')\n","                train_results = test_spiking_network(model, train_dataset, criterion, train_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'train')\n","\n","        del model\n","        del inputs\n","        del targets\n","        del optimizer\n","        del criterion\n","        del loss\n","        gc.collect()\n","        if device == 'cuda': torch.cuda.empty_cache()\n","        elif device == 'mps': torch.mps.empty_cache()\n","\n","        test_results.to_csv(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/test.csv\")\n","        train_results.to_csv(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/train.csv\")"]},{"cell_type":"markdown","metadata":{},"source":["## Time Contrast Imports"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from delta import delta"]},{"cell_type":"markdown","metadata":{},"source":["## Direct Time Contrast"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["NON_ENCODED = \"direct_encoding\"\n","ENCODING_TYPE = \"direct_TC_encoding\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for spectrogram_type in ['mfcc_spectrograms', 'mel_spectrograms']:\n","    original_test_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{NON_ENCODED}/{spectrogram_type}/test.pt\")\n","    original_train_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{NON_ENCODED}/{spectrogram_type}/train.pt\")\n","\n","    direct_TC_test = delta(original_test_dataset, padding = True)\n","    direct_TC_train = delta(original_train_dataset, padding = True)\n","\n","    torch.save(direct_TC_test, f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/test.pt\")\n","    torch.save(direct_TC_train, f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/train.pt\")"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["for spectrogram_type in SPECTROGRAMS:\n","    if not os.path.isfile(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/train.csv\") and os.path.isfile(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/train.pt\"):\n","        print(f\"{spectrogram_type}\")\n","        train_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/train.pt\")\n","        test_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/test.pt\")\n","\n","        # Get the shape of the first sample (train_dataset[0]) of data (x) within the dataset\n","        x_shape = train_dataset[0][0].shape\n","\n","        # Assuming the shape is t x f\n","        features_shape = x_shape[1]\n","        POP_ENCODING = 10\n","        classes = len(label_encoder.classes_)\n","        output_shape = classes * POP_ENCODING\n","\n","\n","        model = Triangle_Network(features_shape, output_shape, beta=0.9, time_dependent=True).to(device)\n","        num_epochs = 100\n","\n","        criterion = PopulationCrossEntropyLoss(num_classes=classes)\n","\n","        optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","        batch_size = 125\n","        train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=10, shuffle=True)\n","\n","        test_results = df()\n","        train_results = df()\n","\n","        epoch_progress_bar = tqdm(total=num_epochs, desc=\"Training Progress\", position=0)\n","    \n","        for epoch in range(num_epochs):\n","            running_loss = 0.0\n","            acc = 0\n","            total = 0\n","            model.train()\n","            for inputs, targets in train_loader:\n","                # inputs in form of (time, batch, features)\n","                inputs, targets = inputs.transpose(0, 1).to(device), targets.to(device)\n","\n","                spikes, _ = model(inputs)\n","\n","                loss = criterion(spikes, targets)\n","\n","                loss.backward()\n","                optimizer.step()\n","                optimizer.zero_grad()\n","\n","                running_loss += loss.item()\n","                total += spikes.size(0)\n","\n","            epoch_progress_bar.update(1)\n","\n","            print(f\"Epoch {epoch+1} Running loss: {running_loss/total}\")\n","            \n","            # Print average loss for the epoch\n","            if ((epoch+1) % 5 == 0):\n","                to_print = (epoch_progress_bar if ((epoch+1) % 15 == 0) else None)\n","                test_results = test_spiking_network(model, test_dataset, criterion, test_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'test')\n","                train_results = test_spiking_network(model, train_dataset, criterion, train_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'train')\n","\n","        del model\n","        del inputs\n","        del targets\n","        del optimizer\n","        del criterion\n","        del loss\n","        gc.collect()\n","        if device == 'cuda': torch.cuda.empty_cache()\n","        elif device == 'mps': torch.mps.empty_cache()\n","\n","        test_results.to_csv(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/test.csv\")\n","        train_results.to_csv(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/train.csv\")"]},{"cell_type":"markdown","metadata":{},"source":["## Time Contrast or Threshold Based"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["from delta import delta\n","\n","NON_ENCODED = \"direct_encoding\"\n","ENCODING_TYPE = \"time_contrast\"\n","\n","THRESHOLDS = [0.01, 0.025, 0.05, 0.10, 0.20, 0.50]\n","OFF_SPIKES = [True, False]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for spectrogram_type in SPECTROGRAMS:\n","    for threshold in THRESHOLDS:\n","        for off_spike in OFF_SPIKES:\n","            original_test_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{NON_ENCODED}/{spectrogram_type}/test.pt\")\n","            original_train_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{NON_ENCODED}/{spectrogram_type}/train.pt\")\n","\n","            TC_test = delta(original_test_dataset, padding = True, threshold=threshold, off_spike=off_spike, threshold_as_percentage=True)\n","            TC_train = delta(original_train_dataset, padding = True, threshold=threshold, off_spike=off_spike, threshold_as_percentage=True)\n","\n","            os.makedirs(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{threshold}_{off_spike}/{spectrogram_type}\", exist_ok=True)\n","\n","            torch.save(TC_test, f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{threshold}_{off_spike}/{spectrogram_type}/test.pt\")\n","            torch.save(TC_train, f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{threshold}_{off_spike}/{spectrogram_type}/train.pt\")"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.01_False_mel_spectrograms\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2d828d86067a41e89dabf52a99145afb","version_major":2,"version_minor":0},"text/plain":["Training Progress:   0%|          | 0/100 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1 Running loss: 0.005943875628919266\n","Epoch 2 Running loss: 0.013992645298711028\n","Epoch 3 Running loss: 0.007349659840519817\n","Epoch 4 Running loss: 0.01143346236536678\n","Epoch 5 Running loss: 0.012316375875625367\n","Epoch 6 Running loss: 0.007428885077516111\n","Epoch 7 Running loss: 0.015742759354198322\n","Epoch 8 Running loss: 0.0071166763290429645\n","Epoch 9 Running loss: 0.01823962744051656\n","Epoch 10 Running loss: 0.012717686712551421\n","Epoch 11 Running loss: 0.01248092982715692\n","Epoch 12 Running loss: 0.01169699668503417\n","Epoch 13 Running loss: 0.009319805775206691\n","Epoch 14 Running loss: 0.010526078196760184\n","Epoch 15 Running loss: 0.008577991407900191\n","Epoch 16 Running loss: 0.009495405914684453\n","Epoch 17 Running loss: 0.007213335912734175\n","Epoch 18 Running loss: 0.009542768850874976\n","Epoch 19 Running loss: 0.012386565772108376\n","Epoch 20 Running loss: 0.009672898073165943\n","Epoch 21 Running loss: 0.009695520606665566\n","Epoch 22 Running loss: 0.01136774186509105\n","Epoch 23 Running loss: 0.01239093862021693\n","Epoch 24 Running loss: 0.012432149661996494\n","Epoch 25 Running loss: 0.01280065694936929\n","Epoch 26 Running loss: 0.00871124892189099\n","Epoch 27 Running loss: 0.010051645886022063\n","Epoch 28 Running loss: 0.009259075116806518\n","Epoch 29 Running loss: 0.010673630923127975\n","Epoch 30 Running loss: 0.018994161686577356\n","Epoch 31 Running loss: 0.009933446590511943\n","Epoch 32 Running loss: 0.009940822474872723\n","Epoch 33 Running loss: 0.00829145540825475\n","Epoch 34 Running loss: 0.009653258818787888\n","Epoch 35 Running loss: 0.01593834161758423\n","Epoch 36 Running loss: 0.013412654209441651\n","Epoch 37 Running loss: 0.009435335001625572\n","Epoch 38 Running loss: 0.012757133752012406\n","Epoch 39 Running loss: 0.013129383230361695\n","Epoch 40 Running loss: 0.008149728797876035\n","Epoch 41 Running loss: 0.009258814370289397\n","Epoch 42 Running loss: 0.008870863114683011\n","Epoch 43 Running loss: 0.008659872193686878\n","Epoch 44 Running loss: 0.00860328577197017\n","Epoch 45 Running loss: 0.008870441692705733\n","Epoch 46 Running loss: 0.007965867892621804\n","Epoch 47 Running loss: 0.0070902938469530295\n","Epoch 48 Running loss: 0.008084657283636708\n","Epoch 49 Running loss: 0.007605548959951431\n","Epoch 50 Running loss: 0.01129899162073105\n","Epoch 51 Running loss: 0.007803674513539567\n","Epoch 52 Running loss: 0.008972701173240004\n","Epoch 53 Running loss: 0.009788998018819304\n","Epoch 54 Running loss: 0.0085219320016928\n","Epoch 55 Running loss: 0.0100517172021226\n","Epoch 56 Running loss: 0.01044310662693109\n","Epoch 57 Running loss: 0.01202613267654809\n","Epoch 58 Running loss: 0.01664449041262983\n","Epoch 59 Running loss: 0.011034191226045164\n","Epoch 60 Running loss: 0.014458060455017577\n","Epoch 61 Running loss: 0.0112916981450285\n","Epoch 62 Running loss: 0.01316545946529498\n","Epoch 63 Running loss: 0.007963532968736685\n","Epoch 64 Running loss: 0.009609476445962826\n","Epoch 65 Running loss: 0.007824303052676753\n","Epoch 66 Running loss: 0.007169869951546764\n","Epoch 67 Running loss: 0.00791879679067447\n","Epoch 68 Running loss: 0.007070738381851976\n","Epoch 69 Running loss: 0.005891782978472237\n","Epoch 70 Running loss: 0.006302492591900567\n","Epoch 71 Running loss: 0.006833017729341793\n","Epoch 72 Running loss: 0.006433279845661249\n","Epoch 73 Running loss: 0.009264229585568363\n","Epoch 74 Running loss: 0.00932841464734306\n","Epoch 75 Running loss: 0.007690154135036773\n","Epoch 76 Running loss: 0.00948883340762446\n","Epoch 77 Running loss: 0.00903391438170363\n","Epoch 78 Running loss: 0.007880318802766526\n","Epoch 79 Running loss: 0.008487657236215024\n","Epoch 80 Running loss: 0.0066049607179035396\n","Epoch 81 Running loss: 0.008042124418404918\n","Epoch 82 Running loss: 0.007465497611429744\n","Epoch 83 Running loss: 0.006776591364187174\n","Epoch 84 Running loss: 0.007618042893303088\n","Epoch 85 Running loss: 0.01400695879238482\n","Epoch 86 Running loss: 0.020897501573775904\n","Epoch 87 Running loss: 0.009629021818264605\n","Epoch 88 Running loss: 0.007313743757363707\n","Epoch 89 Running loss: 0.00892878549929244\n","Epoch 90 Running loss: 0.008733035466922359\n","Epoch 91 Running loss: 0.006066128968621214\n","Epoch 92 Running loss: 0.006565607774659795\n","Epoch 93 Running loss: 0.00849233439174323\n","Epoch 94 Running loss: 0.00628513726182639\n","Epoch 95 Running loss: 0.006748207365742887\n","Epoch 96 Running loss: 0.00795840331540702\n","Epoch 97 Running loss: 0.005594078612070495\n","Epoch 98 Running loss: 0.006368311782614491\n","Epoch 99 Running loss: 0.007843786154311305\n","Epoch 100 Running loss: 0.008759232565236929\n","0.025_True_mel_spectrograms\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"64a239512bb64ef4a57c730c5638be09","version_major":2,"version_minor":0},"text/plain":["Training Progress:   0%|          | 0/100 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1 Running loss: 0.007385018629768786\n","Epoch 2 Running loss: 0.013115036220977101\n","Epoch 3 Running loss: 0.014358925362364553\n","Epoch 4 Running loss: 0.029461962536881908\n","Epoch 5 Running loss: 0.020085144157226856\n","Epoch 6 Running loss: 0.02028375692641773\n","Epoch 7 Running loss: 0.014287089387448831\n","Epoch 8 Running loss: 0.009966718693510793\n","Epoch 9 Running loss: 0.016429559491312924\n","Epoch 10 Running loss: 0.01837630203356758\n","Epoch 11 Running loss: 0.017665419525231797\n","Epoch 12 Running loss: 0.011820679369825905\n","Epoch 13 Running loss: 0.01853630413262608\n","Epoch 14 Running loss: 0.01156843489351364\n","Epoch 15 Running loss: 0.012338092619071182\n","Epoch 16 Running loss: 0.015800125682696748\n","Epoch 17 Running loss: 0.013807509463435164\n","Epoch 18 Running loss: 0.00832641648408323\n","Epoch 19 Running loss: 0.013646922934169586\n","Epoch 20 Running loss: 0.009214946065847865\n","Epoch 21 Running loss: 0.010266816082853859\n","Epoch 22 Running loss: 0.008365560703860304\n","Epoch 23 Running loss: 0.008806157607240036\n","Epoch 24 Running loss: 0.00988242211052404\n","Epoch 25 Running loss: 0.009060975009450516\n","Epoch 26 Running loss: 0.012955574562755255\n","Epoch 27 Running loss: 0.007700258740982689\n","Epoch 28 Running loss: 0.010842710066908083\n","Epoch 29 Running loss: 0.008925434880363294\n","Epoch 30 Running loss: 0.008561921481507273\n","Epoch 31 Running loss: 0.012170821713944213\n","Epoch 32 Running loss: 0.008174669247465774\n","Epoch 33 Running loss: 0.009681288141031235\n","Epoch 34 Running loss: 0.009994192626148748\n","Epoch 35 Running loss: 0.009085866113821157\n","Epoch 36 Running loss: 0.043636480459389976\n","Epoch 37 Running loss: 0.016016707728846006\n","Epoch 38 Running loss: 0.020471515366063713\n","Epoch 39 Running loss: 0.012665782111902207\n","Epoch 40 Running loss: 0.01731700981006074\n","Epoch 41 Running loss: 0.006855120959754189\n","Epoch 42 Running loss: 0.011299861505770455\n","Epoch 43 Running loss: 0.009072809554517459\n","Epoch 44 Running loss: 0.01268305298619377\n","Epoch 45 Running loss: 0.015295136089142139\n","Epoch 46 Running loss: 0.009916071836559917\n","Epoch 47 Running loss: 0.012073833150223801\n","Epoch 48 Running loss: 0.00788423428520227\n","Epoch 49 Running loss: 0.017846198127673456\n","Epoch 50 Running loss: 0.008632355378553891\n","Epoch 51 Running loss: 0.011431604338149293\n","Epoch 52 Running loss: 0.009899241379655588\n","Epoch 53 Running loss: 0.01025528763048946\n","Epoch 54 Running loss: 0.006066380693508794\n","Epoch 55 Running loss: 0.012264154399164949\n","Epoch 56 Running loss: 0.013255544935171596\n","Epoch 57 Running loss: 0.00777928564495172\n","Epoch 58 Running loss: 0.013641228500646524\n","Epoch 59 Running loss: 0.012398703601032781\n","Epoch 60 Running loss: 0.012432480772463278\n","Epoch 61 Running loss: 0.008109121086498418\n","Epoch 62 Running loss: 0.006457298994064331\n","Epoch 63 Running loss: 0.006807734457829509\n","Epoch 64 Running loss: 0.007403395141656406\n","Epoch 65 Running loss: 0.009406284021493344\n","Epoch 66 Running loss: 0.007085901384536451\n","Epoch 67 Running loss: 0.01197213562913596\n","Epoch 68 Running loss: 0.006884181270964991\n","Epoch 69 Running loss: 0.007776302675279185\n","Epoch 70 Running loss: 0.008458581024084609\n","Epoch 71 Running loss: 0.008257574166733617\n","Epoch 72 Running loss: 0.006706004800109597\n","Epoch 73 Running loss: 0.008171705011361705\n","Epoch 74 Running loss: 0.01067265934837512\n","Epoch 75 Running loss: 0.006213756795889273\n","Epoch 76 Running loss: 0.011561551318762782\n","Epoch 77 Running loss: 0.006614819597512389\n","Epoch 78 Running loss: 0.0050102657944963765\n","Epoch 79 Running loss: 0.012141944120486324\n","Epoch 80 Running loss: 0.005490169512292448\n","Epoch 81 Running loss: 0.0061756085140255695\n","Epoch 82 Running loss: 0.0077017844675447995\n","Epoch 83 Running loss: 0.00750959586030759\n","Epoch 84 Running loss: 0.007805641847677505\n","Epoch 85 Running loss: 0.008254600599550972\n","Epoch 86 Running loss: 0.015306217030595285\n","Epoch 87 Running loss: 0.006756647040668768\n","Epoch 88 Running loss: 0.011671811627884643\n","Epoch 89 Running loss: 0.00853507415936016\n","Epoch 90 Running loss: 0.0063898037797726764\n","Epoch 91 Running loss: 0.00785177993698242\n","Epoch 92 Running loss: 0.00985551565980759\n","Epoch 93 Running loss: 0.005942973176600596\n","Epoch 94 Running loss: 0.02459027496770548\n","Epoch 95 Running loss: 0.007053071698441673\n","Epoch 96 Running loss: 0.00866556776979099\n","Epoch 97 Running loss: 0.005779010306198757\n","Epoch 98 Running loss: 0.007843918836535737\n","Epoch 99 Running loss: 0.00566712956423291\n","Epoch 100 Running loss: 0.005408861719000454\n","0.025_False_mel_spectrograms\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f03ee3388fa448438496be87ba0f932d","version_major":2,"version_minor":0},"text/plain":["Training Progress:   0%|          | 0/100 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1 Running loss: 0.008306525576228912\n","Epoch 2 Running loss: 0.014958560276336182\n","Epoch 3 Running loss: 0.0071601625829459\n","Epoch 4 Running loss: 0.007383058627192586\n","Epoch 5 Running loss: 0.007829959590594989\n","Epoch 6 Running loss: 0.009259725911929584\n","Epoch 7 Running loss: 0.009241608004219616\n","Epoch 8 Running loss: 0.011772029696942899\n","Epoch 9 Running loss: 0.01706622945614897\n","Epoch 10 Running loss: 0.015968351889723027\n","Epoch 11 Running loss: 0.009152657691591654\n","Epoch 12 Running loss: 0.010720379245928682\n","Epoch 13 Running loss: 0.009997186569360118\n","Epoch 14 Running loss: 0.007627796215085557\n","Epoch 15 Running loss: 0.011707535566994177\n","Epoch 16 Running loss: 0.009266271330297183\n","Epoch 17 Running loss: 0.023973602075546312\n","Epoch 18 Running loss: 0.015092747303814933\n","Epoch 19 Running loss: 0.015516208764463187\n","Epoch 20 Running loss: 0.019049551921149793\n","Epoch 21 Running loss: 0.013036753089664082\n","Epoch 22 Running loss: 0.012534826256025332\n","Epoch 23 Running loss: 0.013213654676565347\n","Epoch 24 Running loss: 0.01161460797436321\n","Epoch 25 Running loss: 0.014472060691053494\n","Epoch 26 Running loss: 0.00761974788607119\n","Epoch 27 Running loss: 0.009574516703145573\n","Epoch 28 Running loss: 0.007649248073133417\n","Epoch 29 Running loss: 0.009641144603205185\n","Epoch 30 Running loss: 0.009834421899752876\n","Epoch 31 Running loss: 0.008518171172362927\n","Epoch 32 Running loss: 0.014107608757079981\n","Epoch 33 Running loss: 0.008759303214831855\n","Epoch 34 Running loss: 0.011313991234325372\n","Epoch 35 Running loss: 0.016474728576672343\n","Epoch 36 Running loss: 0.008765558084359946\n","Epoch 37 Running loss: 0.012630779141435226\n","Epoch 38 Running loss: 0.009833520276846882\n","Epoch 39 Running loss: 0.009895122279755223\n","Epoch 40 Running loss: 0.010783330510599544\n","Epoch 41 Running loss: 0.009162552630939423\n","Epoch 42 Running loss: 0.01612938916721283\n","Epoch 43 Running loss: 0.00884616203582325\n","Epoch 44 Running loss: 0.007000907827109193\n","Epoch 45 Running loss: 0.009925569398715473\n","Epoch 46 Running loss: 0.007694367878734113\n","Epoch 47 Running loss: 0.011991686523912814\n","Epoch 48 Running loss: 0.009416000911602959\n","Epoch 49 Running loss: 0.01039537737449518\n","Epoch 50 Running loss: 0.009380236410866149\n","Epoch 51 Running loss: 0.006745313172237561\n","Epoch 52 Running loss: 0.007583639301811925\n","Epoch 53 Running loss: 0.006850923402621723\n","Epoch 54 Running loss: 0.005812747014192537\n","Epoch 55 Running loss: 0.006856333047818072\n","Epoch 56 Running loss: 0.00652277422027466\n","Epoch 57 Running loss: 0.008936030700945626\n","Epoch 58 Running loss: 0.007866857722163582\n","Epoch 59 Running loss: 0.0064201952931218255\n","Epoch 60 Running loss: 0.011437423503436982\n","Epoch 61 Running loss: 0.006029440572086615\n","Epoch 62 Running loss: 0.007305956710451327\n","Epoch 63 Running loss: 0.010051349291024497\n","Epoch 64 Running loss: 0.004529722377110404\n","Epoch 65 Running loss: 0.007182699803727123\n","Epoch 66 Running loss: 0.008825136259341011\n","Epoch 67 Running loss: 0.007170653952577244\n","Epoch 68 Running loss: 0.006969855321045317\n","Epoch 69 Running loss: 0.007073466198428864\n","Epoch 70 Running loss: 0.007404019181339885\n","Epoch 71 Running loss: 0.005201272880688262\n","Epoch 72 Running loss: 0.005848349789127755\n","Epoch 73 Running loss: 0.005771939461223614\n","Epoch 74 Running loss: 0.005071758462217288\n","Epoch 75 Running loss: 0.007484755386559727\n","Epoch 76 Running loss: 0.004312541042923178\n","Epoch 77 Running loss: 0.005624385961233236\n","Epoch 78 Running loss: 0.005258682722481676\n","Epoch 79 Running loss: 0.010258343177862441\n","Epoch 80 Running loss: 0.006623659366235947\n","Epoch 81 Running loss: 0.011098170051940333\n","Epoch 82 Running loss: 0.005408496100712343\n","Epoch 83 Running loss: 0.0058188149326156595\n","Epoch 84 Running loss: 0.005212882123054407\n","Epoch 85 Running loss: 0.006764691668196608\n","Epoch 86 Running loss: 0.008226383989230512\n","Epoch 87 Running loss: 0.009673704925817423\n","Epoch 88 Running loss: 0.005167170597341494\n","Epoch 89 Running loss: 0.005837645012730607\n","Epoch 90 Running loss: 0.006696954417152527\n","Epoch 91 Running loss: 0.00495577458375559\n","Epoch 92 Running loss: 0.009427547073973634\n","Epoch 93 Running loss: 0.004949660787281518\n","Epoch 94 Running loss: 0.010509912960064679\n","Epoch 95 Running loss: 0.005938831228798571\n","Epoch 96 Running loss: 0.008383006143112914\n","Epoch 97 Running loss: 0.005607058969549478\n","Epoch 98 Running loss: 0.007617336302138746\n","Epoch 99 Running loss: 0.0057353789623553\n","Epoch 100 Running loss: 0.006140270838722254\n","0.05_True_mel_spectrograms\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1928e65dfe8e4b0791f560a218685425","version_major":2,"version_minor":0},"text/plain":["Training Progress:   0%|          | 0/100 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1 Running loss: 0.006317947238398056\n","Epoch 2 Running loss: 0.018195105056031443\n","Epoch 3 Running loss: 0.008839735779137657\n","Epoch 4 Running loss: 0.008003449668518651\n","Epoch 5 Running loss: 0.009305279475812334\n","Epoch 6 Running loss: 0.008543042329172738\n","Epoch 7 Running loss: 0.01984201395473541\n","Epoch 8 Running loss: 0.009984112204835057\n","Epoch 9 Running loss: 0.011590304846961658\n","Epoch 10 Running loss: 0.007580645739460905\n","Epoch 11 Running loss: 0.008407599438493625\n","Epoch 12 Running loss: 0.007855489612006532\n","Epoch 13 Running loss: 0.01159972199997582\n","Epoch 14 Running loss: 0.008599866502962935\n","Epoch 15 Running loss: 0.007585945220801016\n","Epoch 16 Running loss: 0.007752644163318359\n","Epoch 17 Running loss: 0.009267106319007021\n","Epoch 18 Running loss: 0.009910771641106651\n","Epoch 19 Running loss: 0.011054242380891746\n","Epoch 20 Running loss: 0.006358752901926603\n","Epoch 21 Running loss: 0.012175545144004943\n","Epoch 22 Running loss: 0.010608277762659822\n","Epoch 23 Running loss: 0.01497708108668891\n","Epoch 24 Running loss: 0.007047264982526676\n","Epoch 25 Running loss: 0.012971436253751809\n","Epoch 26 Running loss: 0.012249490609184241\n","Epoch 27 Running loss: 0.011527775765988773\n"]}],"source":["for spectrogram_type in SPECTROGRAMS:\n","    for threshold in THRESHOLDS:\n","        for off_spike in OFF_SPIKES:\n","            if not os.path.isfile(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{threshold}_{off_spike}/{spectrogram_type}/train.csv\") and os.path.isfile(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{threshold}_{off_spike}/{spectrogram_type}/train.pt\"):\n","                print(f\"{threshold}_{off_spike}_{spectrogram_type}\")\n","                train_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{threshold}_{off_spike}/{spectrogram_type}/train.pt\")\n","                test_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{threshold}_{off_spike}/{spectrogram_type}/test.pt\")\n","\n","                # Get the shape of the first sample (train_dataset[0]) of data (x) within the dataset\n","                x_shape = train_dataset[0][0].shape\n","\n","                # Assuming the shape is t x f\n","                features_shape = x_shape[1]\n","                POP_ENCODING = 10\n","                classes = len(label_encoder.classes_)\n","                output_shape = classes * POP_ENCODING\n","\n","\n","                model = Triangle_Network(features_shape, output_shape, beta=0.9, time_dependent=True).to(device)\n","                num_epochs = 100\n","\n","                criterion = PopulationCrossEntropyLoss(num_classes=classes)\n","\n","                optimizer = optim.Adam(model.parameters(), lr=0.005)\n","\n","                batch_size = 120\n","                train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=10, shuffle=True)\n","\n","                test_results = df()\n","                train_results = df()\n","\n","                epoch_progress_bar = tqdm(total=num_epochs, desc=\"Training Progress\", position=0)\n","\n","                for epoch in range(num_epochs):\n","                    running_loss = 0.0\n","                    total = 0\n","                    model.train()\n","                    for inputs, targets in train_loader:\n","                        # inputs in form of (time, batch, features)\n","                        inputs, targets = inputs.transpose(0, 1).to(device), targets.to(device)\n","\n","                        spikes, _ = model(inputs)\n","\n","                        loss = criterion(spikes, targets)\n","\n","                        loss.backward()\n","                        optimizer.step()\n","                        optimizer.zero_grad()\n","\n","                        running_loss += loss.item()\n","                        total += spikes.size(0)\n","\n","                    epoch_progress_bar.update(1)\n","\n","                    print(f\"Epoch {epoch+1} Running loss: {running_loss/total}\")\n","                    \n","                    # Print average loss for the epoch\n","                    if ((epoch+1) % 5 == 0):\n","                        test_results = test_spiking_network(model, test_dataset, criterion, test_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'test')\n","                        train_results = test_spiking_network(model, train_dataset, criterion, train_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'train')\n","\n","                del model\n","                del inputs\n","                del targets\n","                del optimizer\n","                del criterion\n","                del loss\n","                gc.collect()\n","                if device == 'cuda': torch.cuda.empty_cache()\n","                elif device == 'mps': torch.mps.empty_cache()\n","\n","                test_results.to_csv(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{threshold}_{off_spike}/{spectrogram_type}/test.csv\")\n","                train_results.to_csv(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{threshold}_{off_spike}/{spectrogram_type}/train.csv\")"]},{"cell_type":"markdown","metadata":{},"source":["## Cumulative Time Contrast (SF)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from delta import delta\n","\n","NON_ENCODED = \"direct_encoding\"\n","ENCODING_TYPE = \"step_forward\"\n","\n","THRESHOLDS = [0.01, 0.025, 0.05, 0.10, 0.20, 0.50]\n","OFF_SPIKES = [True, False]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for spectrogram_type in SPECTROGRAMS:\n","    for threshold in THRESHOLDS:\n","        for off_spike in OFF_SPIKES:\n","            original_test_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{NON_ENCODED}/{spectrogram_type}/test.pt\")\n","            original_train_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{NON_ENCODED}/{spectrogram_type}/train.pt\")\n","\n","            TC_test = delta(original_test_dataset, padding = True, threshold=threshold, off_spike=off_spike, threshold_as_percentage=True, cumulative=True)\n","            TC_train = delta(original_train_dataset, padding = True, threshold=threshold, off_spike=off_spike, threshold_as_percentage=True, cumulative=True)\n","\n","            os.makedirs(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{threshold}_{off_spike}/{spectrogram_type}\", exist_ok=True)\n","\n","            torch.save(TC_test, f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{threshold}_{off_spike}/{spectrogram_type}/test.pt\")\n","            torch.save(TC_train, f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{threshold}_{off_spike}/{spectrogram_type}/train.pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for spectrogram_type in SPECTROGRAMS:\n","    for threshold in THRESHOLDS:\n","        for off_spike in OFF_SPIKES:\n","            if not os.path.isfile(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{threshold}_{off_spike}/{spectrogram_type}/train.csv\") and os.path.isfile(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{threshold}_{off_spike}/{spectrogram_type}/train.pt\"):\n","                print(f\"{threshold}_{off_spike}_{spectrogram_type}\")\n","                train_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{threshold}_{off_spike}/{spectrogram_type}/train.pt\")\n","                test_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{threshold}_{off_spike}/{spectrogram_type}/test.pt\")\n","\n","                # Get the shape of the first sample (train_dataset[0]) of data (x) within the dataset\n","                x_shape = train_dataset[0][0].shape\n","\n","                # Assuming the shape is t x f\n","                features_shape = x_shape[1]\n","                POP_ENCODING = 10\n","                classes = len(label_encoder.classes_)\n","                output_shape = classes * POP_ENCODING\n","\n","\n","                model = Triangle_Network(features_shape, output_shape, beta=0.9, time_dependent=True).to(device)\n","                num_epochs = 100\n","\n","                criterion = PopulationCrossEntropyLoss(num_classes=classes)\n","\n","                optimizer = optim.Adam(model.parameters(), lr=0.005)\n","\n","                batch_size = 120\n","                train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=10, shuffle=True)\n","\n","                test_results = df()\n","                train_results = df()\n","\n","                epoch_progress_bar = tqdm(total=num_epochs, desc=\"Training Progress\", position=0)\n","\n","                for epoch in range(num_epochs):\n","                    running_loss = 0.0\n","                    total = 0\n","                    model.train()\n","                    for inputs, targets in train_loader:\n","                        # inputs in form of (time, batch, features)\n","                        inputs, targets = inputs.transpose(0, 1).to(device), targets.to(device)\n","\n","                        spikes, _ = model(inputs)\n","\n","                        loss = criterion(spikes, targets)\n","\n","                        loss.backward()\n","                        optimizer.step()\n","                        optimizer.zero_grad()\n","\n","                        running_loss += loss.item()\n","                        total += spikes.size(0)\n","\n","                    epoch_progress_bar.update(1)\n","\n","                    print(f\"Epoch {epoch+1} Running loss: {running_loss/total}\")\n","                    \n","                    # Print average loss for the epoch\n","                    if ((epoch+1) % 5 == 0):\n","                        test_results = test_spiking_network(model, test_dataset, criterion, test_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'test')\n","                        train_results = test_spiking_network(model, train_dataset, criterion, train_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'train')\n","\n","                del model\n","                del inputs\n","                del targets\n","                del optimizer\n","                del criterion\n","                del loss\n","                gc.collect()\n","                if device == 'cuda': torch.cuda.empty_cache()\n","                elif device == 'mps': torch.mps.empty_cache()\n","\n","                test_results.to_csv(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{threshold}_{off_spike}/{spectrogram_type}/test.csv\")\n","                train_results.to_csv(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{threshold}_{off_spike}/{spectrogram_type}/train.csv\")"]},{"cell_type":"markdown","metadata":{},"source":["## Rate Encoding Imports"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from rate import rate, count"]},{"cell_type":"markdown","metadata":{},"source":["## Count Encoding (Whole Spectrogram)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["NON_ENCODED = \"direct_encoding\"\n","ENCODING_TYPE = \"count_encoding\"\n","SUB = \"whole\"\n","\n","for spectrogram_type in SPECTROGRAMS:\n","    for n_count in [5,7,10,15]:\n","        original_test_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{NON_ENCODED}/{spectrogram_type}/test.pt\")\n","        original_train_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{NON_ENCODED}/{spectrogram_type}/train.pt\")\n","\n","        poisson_test = count(original_test_dataset, max_spikes=n_count)\n","        poisson_train = count(original_train_dataset, max_spikes=n_count)\n","\n","        os.makedirs(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{SUB}/{n_count}/{spectrogram_type}\", exist_ok=True)\n","\n","        torch.save(poisson_test, f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{SUB}/{n_count}/{spectrogram_type}/test.pt\")\n","        torch.save(poisson_train, f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{SUB}/{n_count}/{spectrogram_type}/train.pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for spectrogram_type in SPECTROGRAMS:\n","    for n_count in [5,7,10,15]:\n","        if not os.path.isfile(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{SUB}/{n_count}/{spectrogram_type}/train.csv\") and os.path.isfile(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{SUB}/{n_count}/{spectrogram_type}/train.pt\"):\n","            print(f\"{spectrogram_type}\")\n","            train_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{SUB}/{n_count}/{spectrogram_type}/train.pt\")\n","            test_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{SUB}/{n_count}/{spectrogram_type}/test.pt\")\n","\n","            x_shape = train_dataset[0][0].shape\n","            scale_factor = min(30000/(x_shape[0] * x_shape[1]), 1)\n","\n","            transform = transforms.Compose([\n","                transforms.ToTensor(),\n","                transforms.Resize(tuple(int(dim * scale_factor) for dim in x_shape), antialias=True)\n","            ])\n","\n","            train_dataset = [(transform(sample.numpy()), target) for sample, target in train_dataset]\n","            test_dataset = [(transform(sample.numpy()), target) for sample, target in test_dataset]\n","\n","            flattened_x_shape = int(x_shape[0]* scale_factor) * int(x_shape[1] * scale_factor)\n","\n","            features_shape = flattened_x_shape\n","            POP_ENCODING = 10\n","            classes = len(label_encoder.classes_)\n","            output_shape = classes * POP_ENCODING\n","\n","\n","            model = Triangle_Network(features_shape, output_shape, beta=0.9, time_dependent=True).to(device)\n","            num_epochs = 100\n","\n","            criterion = PopulationCrossEntropyLoss(num_classes=classes)\n","\n","            optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","            batch_size = 120\n","            train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=10, shuffle=True)\n","\n","            test_results = df()\n","            train_results = df()\n","\n","            epoch_progress_bar = tqdm(total=num_epochs, desc=\"Training Progress\", position=0)\n","\n","            for epoch in range(num_epochs):\n","                running_loss = 0.0\n","                total = 0\n","                model.train()\n","                for inputs, targets in train_loader:\n","                    # inputs in form of (time, batch, features)\n","                    inputs, targets = inputs.transpose(0, 1).to(device), targets.to(device)\n","\n","                    spikes, _ = model(inputs)\n","\n","                    loss = criterion(spikes, targets)\n","\n","                    loss.backward()\n","                    optimizer.step()\n","                    optimizer.zero_grad()\n","\n","                    running_loss += loss.item()\n","                    total += spikes.size(0)\n","\n","                epoch_progress_bar.update(1)\n","\n","                print(f\"Epoch {epoch+1} Running loss: {running_loss/total}\")\n","                \n","                # Print average loss for the epoch\n","                if ((epoch+1) % 5 == 0):\n","                    test_results = test_spiking_network(model, test_dataset, criterion, test_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'test')\n","                    train_results = test_spiking_network(model, train_dataset, criterion, train_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'train')\n","\n","            del model\n","            del inputs\n","            del targets\n","            del optimizer\n","            del criterion\n","            del loss\n","            gc.collect()\n","            if device == 'cuda': torch.cuda.empty_cache()\n","            elif device == 'mps': torch.mps.empty_cache()\n","\n","            test_results.to_csv(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{SUB}/{n_count}/{spectrogram_type}/test.csv\")\n","            train_results.to_csv(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{SUB}/{n_count}/{spectrogram_type}/train.csv\")"]},{"cell_type":"markdown","metadata":{},"source":["## Count Encoding (Extending Dims)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["NON_ENCODED = \"direct_encoding\"\n","ENCODING_TYPE = \"count_encoding\"\n","SUB = \"extend\"\n","\n","for spectrogram_type in SPECTROGRAMS:\n","    for n_count in [5,7,10,15]:\n","        original_test_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{NON_ENCODED}/{spectrogram_type}/test.pt\")\n","        original_train_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{NON_ENCODED}/{spectrogram_type}/train.pt\")\n","\n","        poisson_test = count(original_test_dataset, max_spikes=n_count, time_varying=True)\n","        poisson_train = count(original_train_dataset, max_spikes=n_count, time_varying=True)\n","\n","        os.makedirs(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{SUB}/{n_count}/{spectrogram_type}\", exist_ok=True)\n","\n","        torch.save(poisson_test, f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{SUB}/{n_count}/{spectrogram_type}/test.pt\")\n","        torch.save(poisson_train, f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{SUB}/{n_count}/{spectrogram_type}/train.pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for spectrogram_type in SPECTROGRAMS:\n","    for n_count in [5,7,10,15]:\n","        if not os.path.isfile(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{SUB}/{n_count}/{spectrogram_type}/train.csv\") and os.path.isfile(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{SUB}/{n_count}/{spectrogram_type}/train.pt\"):\n","            print(f\"{spectrogram_type}\")\n","            train_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{SUB}/{n_count}/{spectrogram_type}/train.pt\")\n","            test_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{SUB}/{n_count}/{spectrogram_type}/test.pt\")\n","\n","            # Get the shape of the first sample (train_dataset[0]) of data (x) within the dataset\n","            x_shape = train_dataset[0][0].shape\n","\n","            # Assuming the shape is t x f\n","            features_shape = x_shape[1]\n","            POP_ENCODING = 10\n","            classes = len(label_encoder.classes_)\n","            output_shape = classes * POP_ENCODING\n","\n","\n","            model = Triangle_Network(features_shape, output_shape, beta=0.9, time_dependent=True).to(device)\n","            num_epochs = 120\n","\n","            criterion = PopulationCrossEntropyLoss(num_classes=classes)\n","\n","            optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","            batch_size = 120\n","            train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=10, shuffle=True)\n","\n","            test_results = df()\n","            train_results = df()\n","\n","            epoch_progress_bar = tqdm(total=num_epochs, desc=\"Training Progress\", position=0)\n","\n","            for epoch in range(num_epochs):\n","                running_loss = 0.0\n","                total = 0\n","                model.train()\n","                for inputs, targets in train_loader:\n","                    # inputs in form of (time, batch, features)\n","                    inputs, targets = inputs.transpose(0, 1).to(device), targets.to(device)\n","\n","                    spikes, _ = model(inputs)\n","\n","                    loss = criterion(spikes, targets)\n","\n","                    loss.backward()\n","                    optimizer.step()\n","                    optimizer.zero_grad()\n","\n","                    running_loss += loss.item()\n","                    total += spikes.size(0)\n","\n","                epoch_progress_bar.update(1)\n","\n","                print(f\"Epoch {epoch+1} Running loss: {running_loss/total}\")\n","                \n","                # Print average loss for the epoch\n","                if ((epoch+1) % 5 == 0):\n","                    test_results = test_spiking_network(model, test_dataset, criterion, test_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'test')\n","                    train_results = test_spiking_network(model, train_dataset, criterion, train_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'train')\n","\n","            del model\n","            del inputs\n","            del targets\n","            del optimizer\n","            del criterion\n","            del loss\n","            gc.collect()\n","            if device == 'cuda': torch.cuda.empty_cache()\n","            elif device == 'mps': torch.mps.empty_cache()\n","\n","            test_results.to_csv(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{SUB}/{n_count}/{spectrogram_type}/test.csv\")\n","            train_results.to_csv(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{SUB}/{n_count}/{spectrogram_type}/train.csv\")"]},{"cell_type":"markdown","metadata":{},"source":["## Poisson Encoding (Whole Spectrogram)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["NON_ENCODED = \"direct_encoding\"\n","ENCODING_TYPE = \"poisson_count\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for spectrogram_type in SPECTROGRAMS:\n","    for n_count in [5,7,10,15]:\n","        original_test_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{NON_ENCODED}/{spectrogram_type}/test.pt\")\n","        original_train_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{NON_ENCODED}/{spectrogram_type}/train.pt\")\n","\n","        poisson_test = rate(original_test_dataset, extend=False, num_steps=n_count)\n","        poisson_train = rate(original_train_dataset, extend=False, num_steps=n_count)\n","\n","        os.makedirs(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{SUB}/{n_count}/{spectrogram_type}\", exist_ok=True)\n","\n","        torch.save(poisson_test, f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{SUB}/{n_count}/{spectrogram_type}/test.pt\")\n","        torch.save(poisson_train, f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{SUB}/{n_count}/{spectrogram_type}/train.pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for spectrogram_type in SPECTROGRAMS:\n","    for n_count in [5,7,10,15]:\n","        if not os.path.isfile(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{SUB}/{n_count}/{spectrogram_type}/train.csv\") and os.path.isfile(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{SUB}/{n_count}/{spectrogram_type}/train.pt\"):\n","            print(f\"{spectrogram_type}\")\n","            train_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{SUB}/{n_count}/{spectrogram_type}/train.pt\")\n","            test_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{SUB}/{n_count}/{spectrogram_type}/test.pt\")\n","\n","            x_shape = train_dataset[0][0].shape\n","            scale_factor = min(30000/(x_shape[0] * x_shape[1]), 1)\n","\n","            transform = transforms.Compose([\n","                transforms.ToTensor(),\n","                transforms.Resize(tuple(int(dim * scale_factor) for dim in x_shape), antialias=True)\n","            ])\n","\n","            train_dataset = [(transform(sample.numpy()), target) for sample, target in train_dataset]\n","            test_dataset = [(transform(sample.numpy()), target) for sample, target in test_dataset]\n","\n","            flattened_x_shape = int(x_shape[0]* scale_factor) * int(x_shape[1] * scale_factor)\n","\n","            features_shape = flattened_x_shape\n","            POP_ENCODING = 10\n","            classes = len(label_encoder.classes_)\n","            output_shape = classes * POP_ENCODING\n","\n","\n","            model = Triangle_Network(features_shape, output_shape, beta=0.9, time_dependent=True).to(device)\n","            num_epochs = 100\n","\n","            criterion = PopulationCrossEntropyLoss(num_classes=classes)\n","\n","            optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","            batch_size = 120\n","            train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=10, shuffle=True)\n","\n","            test_results = df()\n","            train_results = df()\n","\n","            epoch_progress_bar = tqdm(total=num_epochs, desc=\"Training Progress\", position=0)\n","\n","            for epoch in range(num_epochs):\n","                running_loss = 0.0\n","                total = 0\n","                model.train()\n","                for inputs, targets in train_loader:\n","                    # inputs in form of (time, batch, features)\n","                    inputs, targets = inputs.transpose(0, 1).to(device), targets.to(device)\n","\n","                    spikes, _ = model(inputs)\n","\n","                    loss = criterion(spikes, targets)\n","\n","                    loss.backward()\n","                    optimizer.step()\n","                    optimizer.zero_grad()\n","\n","                    running_loss += loss.item()\n","                    total += spikes.size(0)\n","\n","                epoch_progress_bar.update(1)\n","\n","                print(f\"Epoch {epoch+1} Running loss: {running_loss/total}\")\n","                \n","                # Print average loss for the epoch\n","                if ((epoch+1) % 5 == 0):\n","                    test_results = test_spiking_network(model, test_dataset, criterion, test_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'test')\n","                    train_results = test_spiking_network(model, train_dataset, criterion, train_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'train')\n","\n","            del model\n","            del inputs\n","            del targets\n","            del optimizer\n","            del criterion\n","            del loss\n","            gc.collect()\n","            if device == 'cuda': torch.cuda.empty_cache()\n","            elif device == 'mps': torch.mps.empty_cache()\n","\n","            test_results.to_csv(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{SUB}/{n_count}/{spectrogram_type}/test.csv\")\n","            train_results.to_csv(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{SUB}/{n_count}/{spectrogram_type}/train.csv\")"]},{"cell_type":"markdown","metadata":{},"source":["## Poisson Encoding (Keeping Dimensions)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["NON_ENCODED = \"direct_encoding\"\n","ENCODING_TYPE = \"poisson_dims\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for spectrogram_type in SPECTROGRAMS:\n","    original_test_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{NON_ENCODED}/{spectrogram_type}/test.pt\")\n","    original_train_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{NON_ENCODED}/{spectrogram_type}/train.pt\")\n","\n","    poisson_test = rate(original_test_dataset)\n","    poisson_train = rate(original_train_dataset)\n","\n","    os.makedirs(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}\", exist_ok=True)\n","\n","    torch.save(poisson_test, f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/test.pt\")\n","    torch.save(poisson_train, f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/train.pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for spectrogram_type in SPECTROGRAMS:\n","    if not os.path.isfile(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/train.csv\") and os.path.isfile(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/train.pt\"):\n","        print(f\"{spectrogram_type}\")\n","        train_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/train.pt\")\n","        test_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/test.pt\")\n","\n","        # Get the shape of the first sample (train_dataset[0]) of data (x) within the dataset\n","        x_shape = train_dataset[0][0].shape\n","\n","        # Assuming the shape is t x f\n","        features_shape = x_shape[1]\n","        POP_ENCODING = 10\n","        classes = len(label_encoder.classes_)\n","        output_shape = classes * POP_ENCODING\n","\n","\n","        model = Triangle_Network(features_shape, output_shape, beta=0.9, time_dependent=True).to(device)\n","        num_epochs = 100\n","\n","        criterion = PopulationCrossEntropyLoss(num_classes=classes)\n","\n","        optimizer = optim.Adam(model.parameters(), lr=0.005)\n","\n","        batch_size = 100\n","        train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=10, shuffle=True)\n","\n","        test_results = df()\n","        test_results = df()\n","\n","        epoch_progress_bar = tqdm(total=num_epochs, desc=\"Training Progress\", position=0)\n","\n","        for epoch in range(num_epochs):\n","            running_loss = 0.0\n","            total = 0\n","            model.train()\n","            for inputs, targets in train_loader:\n","                # inputs in form of (time, batch, features)\n","                inputs, targets = inputs.transpose(0, 1).to(device), targets.to(device)\n","\n","                spikes, _ = model(inputs)\n","\n","                loss = criterion(spikes, targets)\n","\n","                loss.backward()\n","                optimizer.step()\n","                optimizer.zero_grad()\n","\n","                running_loss += loss.item()\n","                total += spikes.size(0)\n","\n","            epoch_progress_bar.update(1)\n","\n","            print(f\"Epoch {epoch+1} Running loss: {running_loss/total}\")\n","            \n","            # Print average loss for the epoch\n","            if ((epoch+1) % 5 == 0):\n","                test_results = test_spiking_network(model, test_dataset, criterion, test_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'test')\n","                train_results = test_spiking_network(model, train_dataset, criterion, train_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'train')\n","\n","        del model\n","        del inputs\n","        del targets\n","        del optimizer\n","        del criterion\n","        del loss\n","        gc.collect()\n","        if device == 'cuda': torch.cuda.empty_cache()\n","        elif device == 'mps': torch.mps.empty_cache()\n","\n","        test_results.to_csv(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/test.csv\")\n","        train_results.to_csv(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/train.csv\")"]},{"cell_type":"markdown","metadata":{},"source":["## Poisson Encoding (Extending Dims)"]},{"cell_type":"markdown","metadata":{},"source":["### Note that this took too long for Count Encoding (Extending Dims) --- i.e. it takes upwards of 50hrs to train Count_n=15"]},{"cell_type":"markdown","metadata":{},"source":["## Autoencoder"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from snntorch import utils"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class AutoEncoder(nn.module):\n","    def __init__(self, features_shape, coding_size):\n","        super().__init__()\n","\n","        # Encoder\n","        self.encoder = Triangle_Network(features_shape, coding_size, beta=0.9, time_dependent=True)\n","\n","        # Decoder\n","        self.decoder = Triangle_Network(coding_size, features_shape, beta=0.9, time_dependent=True)\n","\n","    def forward(self, x):\n","        utils.reset(self.encoder)\n","        utils.reset(self.decoder)\n","\n","        # Assume the data is in the form [time x batch x features]\n","        num_steps = x.size(0)\n","\n","        spk_mem2=[]\n","        spk_rec=[]\n","        \n","        # Over the time dimension\n","        for step in range(num_steps):\n","            # Encode\n","            spk_x, _ = self.encode(x[step])\n","            spk_rec.append(spk_x)\n","            \n","            # Decode\n","            _, x_mem_recon = self.decode(spk_x)\n","            spk_mem2.append(x_mem_recon)\n","\n","\n","        # Same Dimensions as input: [time x batch x features]\n","        spk_rec = torch.stack(spk_rec,dim=0)\n","        spk_mem2 = torch.stack(spk_mem2,dim=0)\n","\n","        return spk_mem2\n","    \n","    def encode(self,x):\n","        spk_latent_x, mem_latent_x = self.encoder(x)\n","        return spk_latent_x,mem_latent_x\n","\n","    def decode(self,x):\n","        spk_x2, mem_x2 = self.decoder(x)\n","        return spk_x2,mem_x2\n"]},{"cell_type":"markdown","metadata":{},"source":["# Architectures & Action Potentials"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["FILEPATH = \"../\"\n","TEST_TYPE = \"IST non-JNB results/architectures\"\n","ENCODING = \"\"\n","SPECTROGRAMS = ['mel_spectrograms']"]},{"cell_type":"markdown","metadata":{},"source":["## MLP (Triangle)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Ignore beta = 0.90 as this has been worked out before depending on the input dataset\n","BETAS = [0.70, 0.80, 0.95]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for beta in BETAS:\n","    for spectrogram_type in SPECTROGRAMS:\n","        input_dir = f\"{FILEPATH}/IST non-JNB results/input_encoding/{ENCODING}/{spectrogram_type}\"\n","        output_dir = f\"{FILEPATH}/{TEST_TYPE}/{beta}/{spectrogram_type}\"\n","        if not os.path.isfile(f\"{output_dir}/train.csv\") and os.path.isfile(f\"{input_dir}/train.pt\"):\n","            print(f\"{spectrogram_type}\")\n","            train_dataset = torch.load(f\"{input_dir}/train.pt\")\n","            test_dataset = torch.load(f\"{input_dir}/test.pt\")\n","\n","            # Get the shape of the first sample (train_dataset[0]) of data (x) within the dataset\n","            x_shape = train_dataset[0][0].shape\n","\n","            # Assuming the shape is t x f\n","            features_shape = x_shape[1]\n","            POP_ENCODING = 10\n","            classes = len(label_encoder.classes_)\n","            output_shape = classes * POP_ENCODING\n","\n","\n","            model = Triangle_Network(features_shape, output_shape, beta=0.9, time_dependent=True).to(device)\n","            num_epochs = 100\n","\n","            criterion = PopulationCrossEntropyLoss(num_classes=classes)\n","\n","            optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","            batch_size = 120\n","            train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=10, shuffle=True)\n","\n","            test_results = df()\n","            train_results = df()\n","\n","            epoch_progress_bar = tqdm(total=num_epochs, desc=\"Training Progress\", position=0)\n","\n","            for epoch in range(num_epochs):\n","                running_loss = 0.0\n","                total = 0\n","                model.train()\n","                for inputs, targets in train_loader:\n","                    # inputs in form of (time, batch, features)\n","                    inputs, targets = inputs.transpose(0, 1).to(device), targets.to(device)\n","\n","                    spikes, _ = model(inputs)\n","\n","                    loss = criterion(spikes, targets)\n","\n","                    loss.backward()\n","                    optimizer.step()\n","                    optimizer.zero_grad()\n","\n","                    running_loss += loss.item()\n","                    total += spikes.size(0)\n","\n","                epoch_progress_bar.update(1)\n","\n","                print(f\"Epoch {epoch+1} Running loss: {running_loss/total}\")\n","                \n","                # Print average loss for the epoch\n","                if ((epoch+1) % 5 == 0):\n","                    test_results = test_spiking_network(model, test_dataset, criterion, test_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'test')\n","                    train_results = test_spiking_network(model, train_dataset, criterion, train_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'train')\n","\n","            del model\n","            del inputs\n","            del targets\n","            del optimizer\n","            del criterion\n","            del loss\n","            gc.collect()\n","            if device == 'cuda': torch.cuda.empty_cache()\n","            elif device == 'mps': torch.mps.empty_cache()\n","\n","            test_results.to_csv(f\"{output_dir}/test.csv\")\n","            train_results.to_csv(f\"{output_dir}/train.csv\")"]},{"cell_type":"markdown","metadata":{},"source":["## Convolutional Neural Network"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["QrnOeGaHh25K","43m8jiuhh25L","st4_dGj4h25N"],"gpuType":"A100","private_outputs":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":0}
