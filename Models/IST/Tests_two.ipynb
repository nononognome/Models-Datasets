{"cells":[{"cell_type":"markdown","metadata":{"id":"cHy2H4YVh25D"},"source":["# Basic Setup and Functions"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"rXuB5FHah25G"},"outputs":[{"name":"stdout","output_type":"stream","text":["Note: you may need to restart the kernel to use updated packages.\n","Using mps device\n"]}],"source":["%pip install snntorch --quiet\n","\n","import librosa, random\n","import numpy as np\n","import pandas as pd\n","import os\n","import soundfile as sf\n","\n","from pandas import DataFrame as df\n","import torch\n","\n","from sklearn.metrics import confusion_matrix, roc_auc_score, precision_score, recall_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","\n","import snntorch as snn\n","from snntorch.functional.acc import _population_code, _prediction_check\n","\n","import torch.nn as nn\n","from torch import Tensor\n","from torch.utils.data import TensorDataset, DataLoader\n","from torch import optim\n","from torchvision import transforms\n","\n","from tqdm.notebook import tqdm\n","\n","import gc\n","\n","device = (\n","    \"cuda\"\n","    if torch.cuda.is_available()\n","    else \"mps\"\n","    if torch.backends.mps.is_available()\n","    else \"cpu\"\n",")\n","\n","print(f\"Using {device} device\")"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"3ae_oxqGh25H"},"outputs":[],"source":["def Triangle_Network(num_inputs, num_outputs, beta=0.90, time_dependent = False):\n","    dy_dx = int(4/(num_outputs - num_inputs))\n","    hidden1 = num_inputs + (dy_dx * 1)\n","    hidden2 = num_inputs + (dy_dx * 2)\n","    hidden3 = num_inputs + (dy_dx * 3)\n","\n","    if beta and time_dependent:\n","        class Net(nn.Module):\n","        # Initialise network with 2 forward connections (linear connections) and 2 leaky integrated fire layers (hidden and output)\n","            def __init__(self, *args, **kwargs) -> None:\n","                super().__init__(*args, **kwargs)\n","                self.fc1 = nn.Linear(num_inputs, hidden1)\n","                self.lif1 = snn.Leaky(beta=beta)\n","                self.fc2 = nn.Linear(hidden1, hidden2)\n","                self.lif2 = snn.Leaky(beta=beta)\n","                self.fc3 = nn.Linear(hidden3, hidden3)\n","                self.lif3 = snn.Leaky(beta=beta)\n","                self.fc4 = nn.Linear(hidden3, num_outputs)\n","                self.lif4 = snn.Leaky(beta=beta)\n","\n","            # Define a forward pass assuming x is normalised data (i.e. all values in [0,1])\n","            def forward(self, x):\n","                mem1 = self.lif1.init_leaky()\n","                mem2 = self.lif2.init_leaky()\n","                mem3 = self.lif3.init_leaky()\n","                mem4 = self.lif4.init_leaky()\n","\n","                spk_rec = []\n","                mem_rec = []\n","\n","                # Insert data in shape (time x batch x features)\n","                for step in range(x.size(0)):\n","                    cur1 = self.fc1(x[step])\n","                    spk1, mem1 = self.lif1(cur1, mem1)\n","                    cur2 = self.fc2(spk1)\n","                    spk2, mem2 = self.lif2(cur2, mem2)\n","                    cur3 = self.fc3(spk2)\n","                    spk3, mem3 = self.lif3(cur3, mem3)\n","                    cur4 = self.fc4(spk3)\n","                    spk4, mem4 = self.lif4(cur4, mem4)\n","\n","                    spk_rec.append(spk4)\n","                    mem_rec.append(mem4)\n","\n","                return torch.stack(spk_rec, dim=0), torch.stack(mem_rec, dim=0)\n","            \n","        return Net()\n","\n","\n","    elif beta and not time_dependent: return nn.Sequential(nn.Flatten(),\n","                    nn.Linear(num_inputs, hidden1),\n","                    snn.Leaky(beta=beta, init_hidden=True),\n","                    nn.Linear(hidden1, hidden2),\n","                    snn.Leaky(beta=beta, init_hidden=True),\n","                    nn.Linear(hidden2, hidden3),\n","                    snn.Leaky(beta=beta, init_hidden=True),\n","                    nn.Linear(hidden3, num_outputs),\n","                    snn.Leaky(beta=beta, init_hidden=True, output=True))\n","\n","    else: return nn.Sequential(nn.Flatten(),\n","                    nn.Linear(num_inputs, hidden1),\n","                    nn.ReLU(),\n","                    nn.Linear(hidden1, hidden2),\n","                    nn.ReLU(),\n","                    nn.Linear(hidden2, hidden3),\n","                    nn.ReLU(),\n","                    nn.Linear(hidden3, num_outputs))"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"_6kx2Evvh25I"},"outputs":[],"source":["def test_network(model, dataset, loss_fn, results: df, epoch, device, printable=None, train_test = 'test'):\n","    dataloader = DataLoader(dataset, batch_size=100, shuffle=False)\n","    model.eval()\n","    with torch.no_grad():\n","        test_loss = 0.0\n","        correct = 0\n","        total = 0\n","        all_labels = []\n","        all_predicted = []\n","        all_probs = []\n","\n","        for data, labels in dataloader:\n","            x, labels = data.to(device), labels.to(device)\n","            outputs = model(x)\n","            test_loss += loss_fn(outputs, labels).item()\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","            all_labels.extend(labels.cpu().numpy())\n","            all_predicted.extend(predicted.cpu().numpy())\n","\n","\n","            softmax = torch.nn.Softmax(dim=1)\n","            probabilities = softmax(outputs)\n","            all_probs.extend(probabilities.cpu().numpy())\n","\n","    # Accuracy\n","    accuracy = 100 * correct / total\n","\n","    # Confusion Matrix\n","    cm = confusion_matrix(all_labels, all_predicted)\n","\n","    # Recall/Sensitivity -- avoiding div by 0\n","    recall = recall_score(all_labels, all_predicted, average='weighted', zero_division=0)\n","\n","    # Precision\n","    precision = precision_score(all_labels, all_predicted, average='weighted', zero_division=0)\n","\n","    # F1 Score\n","    f1_score = (2 * precision * recall) / (precision + recall)\n","\n","    # AUC-ROC\n","    auc_roc = 100 * roc_auc_score(all_labels, all_probs, multi_class='ovr')\n","    \n","    if printable: printable.set_description(\n","        f'Epoch [{epoch + 1}] {train_test} Loss: {test_loss / len(dataloader):.2f} '\n","        f'{train_test} Accuracy: {accuracy:.2f}% F1: {f1_score}% Recall: {recall:.2f}% Precision: {precision:.2f}% '\n","        f'AUC-ROC: {auc_roc:.4f}%'\n","    )\n","\n","    results = results._append({\n","            'Epoch': epoch + 1,\n","            'Accuracy': accuracy,\n","            'F1': f1_score,\n","            'Recall': recall,\n","            'Precision': precision,\n","            'Test Loss': test_loss / len(dataloader),\n","            'AUC-ROC': auc_roc,\n","            'Confusion Matrix': cm\n","        }, ignore_index=True)\n","\n","    del data\n","    del labels\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","\n","    return results\n","\n","\n","def test_spiking_network(model, dataset, loss_fn, results: df, epoch, device, num_classes=False, printable=None, train_test = 'test'):\n","    dataloader = DataLoader(dataset, batch_size=100, num_workers=3, shuffle=False)\n","    model.eval()\n","    with torch.no_grad():\n","        test_loss = 0.0\n","        correct = 0\n","        total = 0\n","        all_labels = []\n","        all_predicted = []\n","        all_probs = []\n","\n","        for data, labels in dataloader:\n","            x, labels = data.transpose(0, 1).to(device), labels.to(device)\n","            spikes, _ = model(x)\n","            test_loss += loss_fn(spikes, labels).item()\n","            \n","            if num_classes: _, predicted = _population_code(spikes, num_classes=num_classes, num_outputs=spikes.size(-1)).max(1)\n","            else: _, predicted = spikes.sum(dim=1).max(1)\n","\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","            all_labels.extend(labels.cpu().numpy())\n","            all_predicted.extend(predicted.cpu().numpy())\n","\n","            if num_classes: num_spikes = _population_code(spikes, num_classes=num_classes, num_outputs=spikes.size(-1))\n","            else: num_spikes = spikes.sum(dim=1)\n","            \n","            softmax = torch.nn.Softmax(dim=1)\n","            probabilities = softmax(num_spikes)\n","            all_probs.extend(probabilities.cpu().numpy())\n","\n","    # Accuracy\n","    accuracy = 100 * correct / total\n","\n","    # Confusion Matrix\n","    cm = confusion_matrix(all_labels, all_predicted)\n","\n","    # Recall/Sensitivity -- avoiding div by 0\n","    recall = recall_score(all_labels, all_predicted, average='weighted', zero_division=0)\n","\n","    # Precision\n","    precision = precision_score(all_labels, all_predicted, average='weighted', zero_division=0)\n","\n","    # F1 Score\n","    f1_score = (2 * precision * recall) / (precision + recall)\n","\n","    # AUC-ROC\n","    auc_roc = 100 * roc_auc_score(all_labels, all_probs, multi_class='ovr')\n","    \n","    if printable: printable.set_description(\n","        f'Epoch [{epoch + 1}] {train_test} Loss: {test_loss / len(dataloader):.2f} '\n","        f'{train_test} Accuracy: {accuracy:.2f}% F1: {f1_score}% Recall: {recall:.2f}% Precision: {precision:.2f}% '\n","        f'AUC-ROC: {auc_roc:.4f}%'\n","    )\n","\n","    results = results._append({\n","            'Epoch': epoch + 1,\n","            'Accuracy': accuracy,\n","            'F1': f1_score,\n","            'Recall': recall,\n","            'Precision': precision,\n","            'Test Loss': test_loss / len(dataloader),\n","            'AUC-ROC': auc_roc,\n","            'Confusion Matrix': cm\n","        }, ignore_index=True)\n","\n","    del data\n","    del labels\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","\n","    return results"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["class PopulationCrossEntropyLoss():\n","    def __init__(self, num_classes=2):\n","        self.num_classes = num_classes\n","        self.__name__ = \"PopulationCrossEntropyLoss\"\n","\n","    def __call__(self, spk_out, targets):\n","        loss_fn = nn.CrossEntropyLoss()\n","        \n","        _, _, num_outputs = _prediction_check(spk_out)\n","\n","        spike_count = _population_code(\n","                spk_out, self.num_classes, num_outputs\n","            )\n","\n","        loss = loss_fn(spike_count, targets)\n","\n","        return loss\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"q93J30hEh25J"},"outputs":[],"source":["LABEL_MAPPINGS = {\n","    'westernart/classical': 'Classical',\n","    'indierock/pop': 'Rock',\n","    'pop/soul/electronica': 'Electronic',\n","    'electronica': 'Electronic',\n","    'jazz': 'Jazz',\n","    'pop/hiphop/rock': 'Pop',\n","    'rap/hiphop': 'Hiphop',\n","    'rock': 'Rock',\n","    'rock/folk': 'Rock',\n","    'westernart/baroque': 'Classical',\n","    'electronica/dance': 'Electronic',\n","    'westernart/romantic': 'Classical',\n","    'blues': 'Jazz',\n","    'pop/folk': 'Pop',\n","    'westernart/romantic/classical': 'Classical',\n","    'pop/electronica': 'Electronic',\n","    'latin': 'Jazz',\n","    'country/folk': 'Country',\n","    'indierock/folk/pop': 'Rock',\n","    'jazz/blues': 'Jazz',\n","    'pop/rap/rock/hiphop': 'Pop',\n","    'pop/experimental': 'Pop',\n","    'blues/rock/jazz': 'Jazz',\n","    'jazz/adventure': 'Jazz',\n","    'blues/electronica': 'Jazz',\n","    'jazz/pop/soul': 'Jazz',\n","    'funk/electronica': 'Electronic',\n","    'folk/pop': 'Folk',\n","    'indierock/rock': 'Rock',\n","    'jazz/electronica': 'Electronic',\n","    'hiphop': 'Hiphop',\n","    'funk/rnb/adventure': 'Soul',\n","    'pop': 'Pop',\n","    'hiphop/rap': 'Hiphop',\n","    'pop/gospel': 'Soul',\n","    'rap/metal/electronica': 'Electronic',\n","    'pop/rock/folk': 'Rock',\n","    'pop/electronica/hiphop': 'Pop',\n","    'metal/rap': 'Hiphop',\n","    'country': 'Country',\n","    'rap/metal': 'Hiphop',\n","    'country/pop': 'Country',\n","    'folk': 'Folk',\n","    'pop/rock/dance': 'Pop',\n","    'dance': 'Electronic',\n","    'pop/jazz/latin': 'Jazz',\n","    'pop/jazz': 'Jazz',\n","    'funk/rnb/electronica': 'Electronic',\n","    'funk/blues/jazz': 'Jazz',\n","    'pop/rock/soul': 'Pop',\n","    'pop/hiphop': 'Pop',\n","    'blues/funk': 'Jazz',\n","    'rap/metal/hiphop': 'Hiphop',\n","    'blues/jazz/adventure': 'Jazz',\n","    'folk/indierock': 'Folk',\n","    'adventure': 'Classical',\n","    'metal/rock': 'Rock',\n","    'blues/rock/country': 'Jazz',\n","    'pop/soul/rnb': 'Soul',\n","    'blues/rock': 'Jazz',\n","    'blues/rock/indierock': 'Jazz',\n","    'country/pop/folk': 'Country',\n","    'country/blues/rock': 'Country',\n","    'rock/funk/country': 'Rock',\n","    'pop/rock': 'Rock',\n","    'pop/blues': 'Rock',\n","    'blues/indierock': 'Rock',\n","    'blues/rock/rnb': 'Rock',\n","    'blues/pop/folk': 'Jazz',\n","    'pop/funk/adventure': 'Pop',\n","    'blues/rock/pop': 'Rock',\n","    'folk/pop/funk': 'Folk'\n","}\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"y5-_se-YiO7P"},"outputs":[{"name":"stdout","output_type":"stream","text":["{0: 'Classical', 1: 'Country', 2: 'Electronic', 3: 'Folk', 4: 'Hiphop', 5: 'Jazz', 6: 'Pop', 7: 'Rock', 8: 'Soul'}\n"]}],"source":["try:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    !rsync -av --exclude='mel_spectrograms' --exclude='cqt_spectrograms' /content/drive/MyDrive/spectrogram_tensors/ /content/spectrogram_tensors/ --quiet\n","    FILEPATH = '/content'\n","    CSV = 'sample_ISD.csv'\n","\n","    dataset = pd.read_csv(f'/content/drive/MyDrive/{CSV}', index_col=0)\n","\n","    \n","except:\n","    FILEPATH = \"../../Datasets/SmallDataset\"\n","    ORIGINAL_DIR = \"audio\"\n","    SAMPLE_DIR = \"audio uncompressed samples\"\n","    COMPRESSED_DIR = \"audio compressed\"\n","    CSV = 'sample_ISD.csv'\n","\n","    dataset = pd.read_csv(f'{FILEPATH}/{CSV}', index_col=0)\n","\n","X = dataset['filename'].tolist()\n","Y = dataset[dataset['supercategory']=='music']['category'].map(lambda x: LABEL_MAPPINGS[x]).tolist()\n","label_encoder = LabelEncoder()\n","Y_encoded = label_encoder.fit_transform(Y)\n","\n","label_mappings = {encoded_label: original_label for original_label, encoded_label in zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))}\n","print(label_mappings)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Garbage collection special commands\n","\n","gc.collect()\n","if device == \"cuda\":\n","    torch.cuda.empty_cache()\n","    torch.cuda.memory_summary(device=None, abbreviated=False)\n","elif device == \"mps\":\n","    torch.mps.empty_cache()\n","    print(f\"MPS occupied memory: {torch.mps.driver_allocated_memory()}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Very special command -- remove all variables\n","%reset"]},{"cell_type":"markdown","metadata":{"id":"JjzopoGZh25J"},"source":["# Audio Representation"]},{"cell_type":"markdown","metadata":{"id":"QrnOeGaHh25K"},"source":["## Sampling"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5qroeHpJh25L"},"outputs":[],"source":["def sample(audio_path, duration=5.0, sr=44100):\n","    original_path = audio_path\n","    for ext in [\".m4a\", \".wav\", \".ogg\", \".flac\", \".mp3\"]:\n","        if os.path.exists(audio_path + ext):\n","            audio_path += ext\n","\n","            total_duration = librosa.get_duration(path=audio_path)\n","            y, _ = librosa.load(audio_path, sr=sr, duration=total_duration)\n","\n","            if total_duration < duration:\n","                pad_length = int((duration - total_duration) * sr)\n","                y = np.pad(y, (0, pad_length), mode='constant')\n","\n","            start = random.uniform(0, max(0, total_duration - duration))\n","            y = y[int(start * sr):int((start + duration) * sr)]\n","\n","            sf.write(f\"{FILEPATH}/{SAMPLE_DIR}/{original_path.split('/')[-1]}.wav\", y, sr)\n","\n","            return y"]},{"cell_type":"markdown","metadata":{"id":"43m8jiuhh25L"},"source":["## Bitrate and Compression"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"74ui8zpqh25M"},"outputs":[],"source":["import os\n","from tqdm.notebook import tqdm\n","from concurrent.futures import ThreadPoolExecutor\n","\n","def convert_to_mp3(input_file, output_file, sample_rate=16000, bit_rate=\"8k\", channels=1):\n","    !ffmpeg -i \"$input_file\" -ar \"$sample_rate\" -b:a \"$bitrate\" -ac \"$channels\" \"$output_file\" -hide_banner -loglevel error\n","\n","def convert_directory_to_mp3(input_dir, output_dir, sample_rate=16000, bit_rate=\"8k\"):\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    audio_files = [file for file in os.listdir(input_dir) if file.endswith((\".m4a\", \".wav\", \".ogg\", \".flac\", \".mp3\"))]\n","\n","    for file in tqdm(audio_files, desc=\"Converting\"):\n","            input_file_path = os.path.join(input_dir, file)\n","            output_file_path = os.path.join(output_dir, os.path.splitext(file)[0] + \".mp3\")\n","            convert_to_mp3(input_file_path, output_file_path, sample_rate, bit_rate)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IAUf5u8Yh25M"},"outputs":[],"source":["bitdepths = np.array([2,4,8,16,24])\n","samplerates = np.int32(np.array([8,16,22.05,32,44.1])*1000)\n","\n","with ThreadPoolExecutor() as executor:\n","    for bitdepth in bitdepths:\n","        for samplerate in samplerates:\n","            bitrate = (bitdepth * samplerate) / 1000\n","            print(f\"bitdepth: {bitdepth}, samplerate: {samplerate}\")\n","            print(f\"effective bitrate: {bitrate} kbps\")\n","\n","            executor.submit(convert_directory_to_mp3(f\"{FILEPATH}/{SAMPLE_DIR}\", f\"{FILEPATH}/{COMPRESSED_DIR}/{bitdepth}-{samplerate}\", sample_rate=samplerate, bit_rate=f\"{bitrate}k\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mEmydtY2h25M"},"outputs":[],"source":["# Assuming the directory contains all compressed files\n","!find . -mindepth 1 -maxdepth 1 -type d -exec sh -c 'find \"$1\" -type f -exec ls -l {} \\; | awk \"{sum += \\$5} END {print \\\"$1\\\", sum}\"' _ {} \\"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0K_lIJiLh25N"},"outputs":[],"source":["from mutagen.mp3 import MP3\n","\n","def get_unpacked_size(mp3_file):\n","    audio = MP3(mp3_file)\n","    duration = audio.info.length  # Duration of the audio in seconds\n","    bitrate = audio.info.bitrate  # Bitrate of the audio in bits per second\n","    # Calculate the unpacked size based on bitrate and duration\n","    unpacked_size = (duration * bitrate) / 8\n","    return unpacked_size\n","\n","\n","file_dirs = [d for d in os.listdir(f\"{FILEPATH}/{COMPRESSED_DIR}\") if os.path.isdir(f\"{FILEPATH}/{COMPRESSED_DIR}/{d}\")]\n","for bitrate in file_dirs:\n","    audio_files = [file for file in os.listdir(f\"{FILEPATH}/{COMPRESSED_DIR}/{bitrate}\") if file.endswith((\".mp3\"))]\n","    size = 0\n","    for file in audio_files:\n","        if os.path.exists(f\"{FILEPATH}/{COMPRESSED_DIR}/{bitrate}/{file}\"):\n","            size += get_unpacked_size(f\"{FILEPATH}/{COMPRESSED_DIR}/{bitrate}/{file}\")\n","    print(f\"{bitrate.split('/')[-1]}: {size} bytes\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BW6hyuwDh25N"},"outputs":[],"source":["from matplotlib import pyplot as plt\n","import tikzplotlib\n","\n","bit_two = np.array([[16,32,44.1,64,88.2],[1,3,4,5,5]]).T\n","bit_four = np.array([[32,64,88.2,128,176.4],[2,4,5,5,5]]).T\n","bit_eight = np.array([[64,128,176.4,256,352.8],[2,4,5,5,5]]).T\n","bit_sixteen = np.array([[128,256,352.8,512,705.6],[2,3,4,4,5]]).T\n","bit_twentyfour = np.array([[192,384,529.2,768,1058.4],[2,4,5,5,5]]).T\n","\n","plt.plot(bit_two[:,0], bit_two[:,1], label=\"2-bit\")\n","plt.plot(bit_four[:,0], bit_four[:,1], label=\"4-bit\")\n","plt.plot(bit_eight[:,0], bit_eight[:,1], label=\"8-bit\")\n","plt.plot(bit_sixteen[:,0], bit_sixteen[:,1], label=\"16-bit\")\n","plt.plot(bit_twentyfour[:,0], bit_twentyfour[:,1], label=\"24-bit\")\n","\n","plt.ylabel(\"Perceived Quality\")\n","plt.xlabel(\"Bitrate (kbps)\")\n","plt.xscale(\"log\")\n","plt.xlim(10,1100)\n","plt.ylim(0, 6)\n","plt.grid(True, which='both', axis='y')\n","#plt.legend()\n","\n","tikzplotlib.save(\"AudioRep/CompressionReception.tex\")"]},{"cell_type":"markdown","metadata":{"id":"st4_dGj4h25N"},"source":["## Spectrograms"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yE7h8re8h25O"},"outputs":[],"source":["import spectrograms\n","\n","AUDIO_DIR = \"compressed_audio\"\n","\n","X = dataset[dataset['supercategory']=='music']['filename'].tolist()\n","Y = dataset[dataset['supercategory']=='music']['category'].map(lambda x: LABEL_MAPPINGS[x]).tolist()\n","\n","label_encoder = LabelEncoder()\n","Y_encoded = label_encoder.fit_transform(Y)\n","\n","label_mappings = {encoded_label: original_label for original_label, encoded_label in zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))}\n","print(label_mappings)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, Y_encoded, test_size=0.2)\n","\n","waveforms_train = [spectrograms.load_from_path(f\"{FILEPATH}/{AUDIO_DIR}/{file}.mp3\") for file in X_train]\n","waveforms_test = [spectrograms.load_from_path(f\"{FILEPATH}/{AUDIO_DIR}/{file}.mp3\") for file in X_test]"]},{"cell_type":"markdown","metadata":{"id":"K_N2kwfnh25O"},"source":["### Standard Spectrogram"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vQQmRuouh25O"},"outputs":[],"source":["DIR = \"spectrogram_tensors\"\n","\n","\n","for n_fft in [512, 1024, 2048, 4096]:\n","    for win_length in [512, 1024, 2048, 4096]:\n","        if n_fft < win_length:\n","            continue\n","        else:\n","            os.makedirs(f\"{FILEPATH}/{DIR}/spectrograms/{n_fft}-{512}-{win_length}\", exist_ok=True)\n","            spectrogram_X_train = Tensor(np.array([x for x, _ in [spectrograms.spectrogram(sample, sr, hop=512, fft=n_fft, win=win_length) for sample, sr in waveforms_train]]))\n","            spectrogram_X_test = Tensor(np.array([x for x, _ in [spectrograms.spectrogram(sample, sr, hop=512, fft=n_fft, win=win_length) for sample, sr in waveforms_test]]))\n","            spectrogram_train = TensorDataset(spectrogram_X_train, torch.LongTensor(y_train))\n","            spectrogram_test = TensorDataset(spectrogram_X_test, torch.LongTensor(y_test))\n","            torch.save(spectrogram_train, f\"{FILEPATH}/{DIR}/spectrograms/{n_fft}-{512}-{win_length}/train.pt\")\n","            torch.save(spectrogram_test, f\"{FILEPATH}/{DIR}/spectrograms/{n_fft}-{512}-{win_length}/test.pt\")\n","\n","\n","for hop_length in [256, 1024, 2048]:\n","    os.makedirs(f\"{FILEPATH}/{DIR}/spectrograms/{2048}-{hop_length}-{2048}\", exist_ok=True)\n","    spectrogram_X_train = Tensor(np.array([x for x, _ in [spectrograms.spectrogram(sample, sr, hop=hop_length, fft=2048, win=2048) for sample, sr in waveforms_train]]))\n","    spectrogram_X_test = Tensor(np.array([x for x, _ in [spectrograms.spectrogram(sample, sr, hop=hop_length, fft=2048, win=2048) for sample, sr in waveforms_test]]))\n","    spectrogram_train = TensorDataset(spectrogram_X_train, torch.LongTensor(y_train))\n","    spectrogram_test = TensorDataset(spectrogram_X_test, torch.LongTensor(y_test))\n","    torch.save(spectrogram_train, f\"{FILEPATH}/{DIR}/spectrograms/{2048}-{hop_length}-{2048}/train.pt\")\n","    torch.save(spectrogram_test, f\"{FILEPATH}/{DIR}/spectrograms/{2048}-{hop_length}-{2048}/test.pt\")\n"]},{"cell_type":"markdown","metadata":{"id":"bgYyIxHJh25O"},"source":["### Mel Spectrogram"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ejZ5v5tBh25O"},"outputs":[],"source":["DIR = \"spectrogram_tensors\"\n","\n","\n","for n_fft in [512, 1024, 2048, 4096]:\n","    for win_length in [512, 1024, 2048, 4096]:\n","        if n_fft < win_length:\n","            continue\n","        else:\n","            os.makedirs(f\"{FILEPATH}/{DIR}/mel_spectrograms/{n_fft}-{512}-{win_length}-{128}\", exist_ok=True)\n","            spectrogram_X_train = Tensor(np.array([x for x, _ in [spectrograms.mel_spectrogram(sample, sr, fft=n_fft, win=win_length) for sample, sr in waveforms_train]]))\n","            spectrogram_X_test = Tensor(np.array([x for x, _ in [spectrograms.mel_spectrogram(sample, sr, fft=n_fft, win=win_length) for sample, sr in waveforms_test]]))\n","            spectrogram_train = TensorDataset(spectrogram_X_train, torch.LongTensor(y_train))\n","            spectrogram_test = TensorDataset(spectrogram_X_test, torch.LongTensor(y_test))\n","            torch.save(spectrogram_train, f\"{FILEPATH}/{DIR}/mel_spectrograms/{n_fft}-{512}-{win_length}-{128}/train.pt\")\n","            torch.save(spectrogram_test, f\"{FILEPATH}/{DIR}/mel_spectrograms/{n_fft}-{512}-{win_length}-{128}/test.pt\")\n","\n","\n","for hop_length in [256, 1024, 2048]:\n","    os.makedirs(f\"{FILEPATH}/{DIR}/mel_spectrograms/{2048}-{hop_length}-{2048}-{128}\", exist_ok=True)\n","    spectrogram_X_train = Tensor(np.array([x for x, _ in [spectrograms.mel_spectrogram(sample, sr, hop=hop_length, fft=2048, win=2048) for sample, sr in waveforms_train]]))\n","    spectrogram_X_test = Tensor(np.array([x for x, _ in [spectrograms.mel_spectrogram(sample, sr, hop=hop_length, fft=2048, win=2048) for sample, sr in waveforms_test]]))\n","    spectrogram_train = TensorDataset(spectrogram_X_train, torch.LongTensor(y_train))\n","    spectrogram_test = TensorDataset(spectrogram_X_test, torch.LongTensor(y_test))\n","    torch.save(spectrogram_train, f\"{FILEPATH}/{DIR}/mel_spectrograms/{2048}-{hop_length}-{2048}-{128}/train.pt\")\n","    torch.save(spectrogram_test, f\"{FILEPATH}/{DIR}/mel_spectrograms/{2048}-{hop_length}-{2048}-{128}/test.pt\")\n","\n","\n","for mel_features in [64, 128, 192, 256]:\n","    os.makedirs(f\"{FILEPATH}/{DIR}/mel_spectrograms/{2048}-{512}-{2048}-{mel_features}\", exist_ok=True)\n","    spectrogram_X_train = Tensor(np.array([x for x, _ in [spectrograms.mel_spectrogram(sample, sr, mel=mel_features) for sample, sr in waveforms_train]]))\n","    spectrogram_X_test = Tensor(np.array([x for x, _ in [spectrograms.mel_spectrogram(sample, sr, mel=mel_features) for sample, sr in waveforms_test]]))\n","    spectrogram_train = TensorDataset(spectrogram_X_train, torch.LongTensor(y_train))\n","    spectrogram_test = TensorDataset(spectrogram_X_test, torch.LongTensor(y_test))\n","    torch.save(spectrogram_train, f\"{FILEPATH}/{DIR}/mel_spectrograms/{2048}-{512}-{2048}-{mel_features}/train.pt\")\n","    torch.save(spectrogram_test, f\"{FILEPATH}/{DIR}/mel_spectrograms/{2048}-{512}-{2048}-{mel_features}/test.pt\")"]},{"cell_type":"markdown","metadata":{"id":"_VOfBuf6h25P"},"source":["### MFCCs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d1WeX2vLh25P"},"outputs":[],"source":["DIR = \"spectrogram_tensors\"\n","\n","for n_fft in [512, 1024, 2048, 4096]:\n","    for win_length in [512, 1024, 2048, 4096]:\n","        if n_fft < win_length:\n","            continue\n","        else:\n","            os.makedirs(f\"{FILEPATH}/{DIR}/mfcc_spectrograms/{n_fft}-{512}-{win_length}-{128}-{13}\", exist_ok=True)\n","            spectrogram_X_train = Tensor(np.array([x for x, _ in [spectrograms.mfcc_spectrogram(sample, sr, fft=n_fft, win=win_length) for sample, sr in waveforms_train]]))\n","            spectrogram_X_test = Tensor(np.array([x for x, _ in [spectrograms.mfcc_spectrogram(sample, sr, fft=n_fft, win=win_length) for sample, sr in waveforms_test]]))\n","            spectrogram_train = TensorDataset(spectrogram_X_train, torch.LongTensor(y_train))\n","            spectrogram_test = TensorDataset(spectrogram_X_test, torch.LongTensor(y_test))\n","            torch.save(spectrogram_train, f\"{FILEPATH}/{DIR}/mfcc_spectrograms/{n_fft}-{512}-{win_length}-{128}-{13}/train.pt\")\n","            torch.save(spectrogram_test, f\"{FILEPATH}/{DIR}/mfcc_spectrograms/{n_fft}-{512}-{win_length}-{128}-{13}/test.pt\")\n","\n","\n","for hop_length in [256, 1024, 2048]:\n","    os.makedirs(f\"{FILEPATH}/{DIR}/mfcc_spectrograms/{2048}-{hop_length}-{2048}-{128}-{13}\", exist_ok=True)\n","    spectrogram_X_train = Tensor(np.array([x for x, _ in [spectrograms.mfcc_spectrogram(sample, sr, hop=hop_length, fft=2048, win=2048) for sample, sr in waveforms_train]]))\n","    spectrogram_X_test = Tensor(np.array([x for x, _ in [spectrograms.mfcc_spectrogram(sample, sr, hop=hop_length, fft=2048, win=2048) for sample, sr in waveforms_test]]))\n","    spectrogram_train = TensorDataset(spectrogram_X_train, torch.LongTensor(y_train))\n","    spectrogram_test = TensorDataset(spectrogram_X_test, torch.LongTensor(y_test))\n","    torch.save(spectrogram_train, f\"{FILEPATH}/{DIR}/mfcc_spectrograms/{2048}-{hop_length}-{2048}-{128}-{13}/train.pt\")\n","    torch.save(spectrogram_test, f\"{FILEPATH}/{DIR}/mfcc_spectrograms/{2048}-{hop_length}-{2048}-{128}-{13}/test.pt\")\n","\n","\n","for mel_features in [64, 128, 192, 256]:\n","    os.makedirs(f\"{FILEPATH}/{DIR}/mfcc_spectrograms/{2048}-{512}-{2048}-{mel_features}-{13}\", exist_ok=True)\n","    spectrogram_X_train = Tensor(np.array([x for x, _ in [spectrograms.mfcc_spectrogram(sample, sr, mel=mel_features) for sample, sr in waveforms_train]]))\n","    spectrogram_X_test = Tensor(np.array([x for x, _ in [spectrograms.mfcc_spectrogram(sample, sr, mel=mel_features) for sample, sr in waveforms_test]]))\n","    spectrogram_train = TensorDataset(spectrogram_X_train, torch.LongTensor(y_train))\n","    spectrogram_test = TensorDataset(spectrogram_X_test, torch.LongTensor(y_test))\n","    torch.save(spectrogram_train, f\"{FILEPATH}/{DIR}/mfcc_spectrograms/{2048}-{512}-{2048}-{mel_features}-{13}/train.pt\")\n","    torch.save(spectrogram_test, f\"{FILEPATH}/{DIR}/mfcc_spectrograms/{2048}-{512}-{2048}-{mel_features}-{13}/test.pt\")\n","\n","for mfcc_components in [5, 9, 13, 20]:\n","    os.makedirs(f\"{FILEPATH}/{DIR}/mfcc_spectrograms/{2048}-{512}-{2048}-{128}-{mfcc_components}\", exist_ok=True)\n","    spectrogram_X_train = Tensor(np.array([x for x, _ in [spectrograms.mfcc_spectrogram(sample, sr, mfcc_bins=mfcc_components) for sample, sr in waveforms_train]]))\n","    spectrogram_X_test = Tensor(np.array([x for x, _ in [spectrograms.mfcc_spectrogram(sample, sr, mfcc_bins=mfcc_components) for sample, sr in waveforms_test]]))\n","    spectrogram_train = TensorDataset(spectrogram_X_train, torch.LongTensor(y_train))\n","    spectrogram_test = TensorDataset(spectrogram_X_test, torch.LongTensor(y_test))\n","    torch.save(spectrogram_train, f\"{FILEPATH}/{DIR}/mfcc_spectrograms/{2048}-{512}-{2048}-{128}-{mfcc_components}/train.pt\")\n","    torch.save(spectrogram_test, f\"{FILEPATH}/{DIR}/mfcc_spectrograms/{2048}-{512}-{2048}-{128}-{mfcc_components}/test.pt\")"]},{"cell_type":"markdown","metadata":{"id":"quC-qqvvh25P"},"source":["### CQT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dYLOq4ruh25P"},"outputs":[],"source":["for hop_length in [256, 512, 1024, 2048]:\n","    os.makedirs(f\"{FILEPATH}/{DIR}/cqt_spectrograms/{hop_length}\", exist_ok=True)\n","    spectrogram_X_train = Tensor(np.array([x for x, _ in [spectrograms.cqt_spectrogram(sample, sr, hop=hop_length) for sample, sr in waveforms_train]]))\n","    spectrogram_X_test = Tensor(np.array([x for x, _ in [spectrograms.cqt_spectrogram(sample, sr, hop=hop_length) for sample, sr in waveforms_test]]))\n","    spectrogram_train = TensorDataset(spectrogram_X_train, torch.LongTensor(y_train))\n","    spectrogram_test = TensorDataset(spectrogram_X_test, torch.LongTensor(y_test))\n","    torch.save(spectrogram_train, f\"{FILEPATH}/{DIR}/cqt_spectrograms/{hop_length}/train.pt\")\n","    torch.save(spectrogram_test, f\"{FILEPATH}/{DIR}/cqt_spectrograms/{hop_length}/test.pt\")"]},{"cell_type":"markdown","metadata":{"id":"v-ac1vMrh25P"},"source":["# ANN Baseline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xEiy6I9ph25P"},"outputs":[],"source":["def train(model, train_dataset, test_dataset, num_epochs, device):\n","    criterion = nn.CrossEntropyLoss()\n","    #optimizer = optim.SGD(model.parameters(), lr=0.01)\n","    optimizer = optim.Adam(model.parameters(), lr=0.0005)\n","\n","    batch_size = 32\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","    test_results = df()\n","    train_results = df()\n","\n","    epoch_progress_bar = tqdm(total=num_epochs, desc=\"Training Progress\", position=0)\n","\n","    for epoch in range(num_epochs):\n","        running_loss = 0.0\n","        model.train()\n","        for inputs, targets in train_loader:\n","            inputs, targets = inputs.to(device), targets.to(device)\n","\n","            outputs = model(inputs)\n","            loss = criterion(outputs, targets)\n","\n","            loss.backward()\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","            running_loss += loss.item()\n","\n","        epoch_progress_bar.update(1)\n","\n","        # Print average loss for the epoch\n","        test_results = test_network(model, test_dataset, criterion, test_results, epoch, device, printable=(epoch_progress_bar if ((epoch+1) % 15 == 0) else None), test_train = 'test')\n","        train_results = test_network(model, train_dataset, criterion, test_results, epoch, device, printable=(epoch_progress_bar if ((epoch+1) % 15 == 0) else None), test_train = 'train')\n","\n","    del model\n","    del inputs\n","    del targets\n","    del optimizer\n","    del criterion\n","    del loss\n","    gc.collect()\n","    if device == 'cuda': torch.cuda.empty_cache()\n","    elif device == 'mps': torch.mps.empty_cache()\n","\n","    print(\"Training finished!\")\n","    return test_results, train_results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ha95p49VjS-I"},"outputs":[],"source":["DIR = \"spectrogram_tensors\"\n","FILEPATH = \"/content\"\n","\n","X = dataset[dataset['supercategory']=='music']['filename'].tolist()\n","Y = dataset[dataset['supercategory']=='music']['category'].map(lambda x: LABEL_MAPPINGS[x]).tolist()\n","\n","label_encoder = LabelEncoder()\n","Y_encoded = label_encoder.fit_transform(Y)\n","\n","label_mappings = {encoded_label: original_label for original_label, encoded_label in zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))}\n","print(label_mappings)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0JoO1V9rh25P"},"outputs":[],"source":["for spectrogram_type in ['mfcc_spectrograms', 'cqt_spectrograms', 'mel_spectrograms', 'spectrograms']:\n","  for spectrogram_files in os.listdir(f\"{FILEPATH}/{DIR}/{spectrogram_type}\"):\n","    if not os.path.isfile(f\"{FILEPATH}/{DIR}/{spectrogram_type}/{spectrogram_files}/train.csv\") and os.path.isfile(f\"{FILEPATH}/{DIR}/{spectrogram_type}/{spectrogram_files}/train.pt\"):\n","      print(f\"{spectrogram_type}/{spectrogram_files}\")\n","      train_dataset = torch.load(f\"{FILEPATH}/{DIR}/{spectrogram_type}/{spectrogram_files}/train.pt\")\n","      test_dataset = torch.load(f\"{FILEPATH}/{DIR}/{spectrogram_type}/{spectrogram_files}/test.pt\")\n","\n","      x_shape = train_dataset[0][0].shape\n","      scale_factor = min(30000/(x_shape[0] * x_shape[1]), 1)\n","\n","      transform = transforms.Compose([\n","          transforms.ToTensor(),\n","          transforms.Resize(tuple(int(dim * scale_factor) for dim in x_shape), antialias=True)\n","      ])\n","\n","      train_dataset = [(transform(sample.numpy()), target) for sample, target in train_dataset]\n","      test_dataset = [(transform(sample.numpy()), target) for sample, target in test_dataset]\n","\n","      flattened_x_shape = int(x_shape[0]* scale_factor) * int(x_shape[1] * scale_factor)\n","\n","\n","      model = Triangle_Network(flattened_x_shape, len(label_encoder.classes_), beta=False).to(device)\n","      num_epochs = 120\n","\n","      criterion = nn.CrossEntropyLoss()\n","      #optimizer = optim.SGD(model.parameters(), lr=0.01)\n","      optimizer = optim.Adam(model.parameters(), lr=0.0005)\n","\n","      batch_size = 32\n","      train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","      test_results = df()\n","      train_results = df()\n","\n","      epoch_progress_bar = tqdm(total=num_epochs, desc=\"Training Progress\", position=0)\n","\n","      for epoch in range(num_epochs):\n","          running_loss = 0.0\n","          model.train()\n","          for inputs, targets in train_loader:\n","              inputs, targets = inputs.to(device), targets.to(device)\n","\n","              outputs = model(inputs)\n","              loss = criterion(outputs, targets)\n","\n","              loss.backward()\n","              optimizer.step()\n","              optimizer.zero_grad()\n","\n","              running_loss += loss.item()\n","\n","          epoch_progress_bar.update(1)\n","\n","          # Print average loss for the epoch\n","          test_results = test_network(model, test_dataset, criterion, test_results, epoch, device, printable=(epoch_progress_bar if ((epoch+1) % 15 == 0) else None), test_train = 'test')\n","          train_results = test_network(model, train_dataset, criterion, test_results, epoch, device, printable=(epoch_progress_bar if ((epoch+1) % 15 == 0) else None), test_train = 'train')\n","\n","      del model\n","      del inputs\n","      del targets\n","      del optimizer\n","      del criterion\n","      del loss\n","      gc.collect()\n","      if device == 'cuda': torch.cuda.empty_cache()\n","      elif device == 'mps': torch.mps.empty_cache()\n","\n","      test_results.to_csv(f\"/content/drive/MyDrive/spectrogram_tensors/{spectrogram_type}/{spectrogram_files}/test.csv\")\n","      train_results.to_csv(f\"/content/drive/MyDrive/spectrogram_tensors/{spectrogram_type}/{spectrogram_files}/train.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eLIP4saookhS"},"outputs":[],"source":["%reset"]},{"cell_type":"markdown","metadata":{},"source":["# Input Encodings"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/var/folders/mq/y1mzq23j39104lm0kgrz14180000gn/T/ipykernel_83930/705755807.py:2: DeprecationWarning: The module snntorch.backprop will be deprecated in  a future release. Writing out your own training loop will lead to substantially faster performance.\n","  from snntorch import backprop\n"]}],"source":["from snntorch import functional as SF\n","\n","FILEPATH = \"../../\"\n","TEST_TYPE = \"Models/IST non-JNB results/input_encoding\"\n","SPECTROGRAMS = ['mfcc_spectrograms', 'mel_spectrograms']"]},{"cell_type":"markdown","metadata":{},"source":["## Direct Encoding"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ENCODING_TYPE = \"direct_encoding\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for spectrogram_type in SPECTROGRAMS:\n","    if not os.path.isfile(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/train.csv\") and os.path.isfile(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/train.pt\"):\n","        print(f\"{spectrogram_type}\")\n","        train_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/train.pt\")\n","        test_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/test.pt\")\n","\n","        # Get the shape of the first sample (train_dataset[0]) of data (x) within the dataset\n","        x_shape = train_dataset[0][0].shape\n","\n","        # Assuming the shape is t x f\n","        features_shape = x_shape[1]\n","        POP_ENCODING = 10\n","        classes = len(label_encoder.classes_)\n","        output_shape = classes * POP_ENCODING\n","\n","\n","        model = Triangle_Network(features_shape, output_shape, beta=0.9, time_dependent=True).to(device)\n","        num_epochs = 120\n","\n","        criterion = SF.mse_count_loss(correct_rate=1.0, incorrect_rate=0.0, population_code=True, num_classes=classes)\n","\n","        optimizer = optim.Adam(model.parameters(), lr=0.05)\n","\n","        batch_size = 125\n","        train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=10, shuffle=True)\n","\n","        test_results = df()\n","        train_results = df()\n","\n","        epoch_progress_bar = tqdm(total=num_epochs, desc=\"Training Progress\", position=0)\n","    \n","        for epoch in range(num_epochs):\n","            running_loss = 0.0\n","            acc = 0\n","            total = 0\n","            model.train()\n","            for inputs, targets in train_loader:\n","                inputs, targets = inputs.transpose(0, 1).to(device), targets.to(device)\n","\n","                spikes, _ = model(inputs)\n","\n","                loss = criterion(spikes, targets)\n","\n","                loss.backward()\n","                optimizer.step()\n","                optimizer.zero_grad()\n","\n","                running_loss += loss.item()\n","                total += spikes.size(1)\n","\n","            epoch_progress_bar.update(1)\n","\n","            print(f\"Epoch {epoch+1} Running loss: {running_loss/total}\")\n","            \n","            # Print average loss for the epoch\n","            if ((epoch+1) % 5 == 0):\n","                to_print = (epoch_progress_bar if ((epoch+1) % 15 == 0) else None)\n","                test_results = test_spiking_network(model, test_dataset, criterion, test_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'test')\n","                train_results = test_spiking_network(model, train_dataset, criterion, test_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'train')\n","\n","        del model\n","        del inputs\n","        del targets\n","        del optimizer\n","        del criterion\n","        del loss\n","        gc.collect()\n","        if device == 'cuda': torch.cuda.empty_cache()\n","        elif device == 'mps': torch.mps.empty_cache()\n","\n","        test_results.to_csv(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/test.csv\")\n","        train_results.to_csv(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/train.csv\")"]},{"cell_type":"markdown","metadata":{},"source":["## Direct Time Contrast"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from delta import delta\n","\n","NON_ENCODED = \"direct_encoding\"\n","ENCODING_TYPE = \"direct_TC_encoding\"\n","\n","for spectrogram_type in ['mfcc_spectrograms', 'mel_spectrograms']:\n","    original_test_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{NON_ENCODED}/{spectrogram_type}/test.pt\")\n","    original_train_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{NON_ENCODED}/{spectrogram_type}/train.pt\")\n","\n","    direct_TC_test = delta(original_test_dataset, padding = True)\n","    direct_TC_train = delta(original_train_dataset, padding = True)\n","\n","    torch.save(direct_TC_test, f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/test.pt\")\n","    torch.save(direct_TC_train, f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/train.pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for spectrogram_type in SPECTROGRAMS:\n","    if not os.path.isfile(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/train.csv\") and os.path.isfile(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/train.pt\"):\n","        print(f\"{spectrogram_type}\")\n","        train_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/train.pt\")\n","        test_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/test.pt\")\n","\n","        # Get the shape of the first sample (train_dataset[0]) of data (x) within the dataset\n","        x_shape = train_dataset[0][0].shape\n","\n","        # Assuming the shape is t x f\n","        features_shape = x_shape[1]\n","        POP_ENCODING = 10\n","        classes = len(label_encoder.classes_)\n","        output_shape = classes * POP_ENCODING\n","\n","\n","        model = Triangle_Network(features_shape, output_shape, beta=0.9, time_dependent=True).to(device)\n","        num_epochs = 120\n","\n","        criterion = PopulationCrossEntropyLoss(num_classes=classes)\n","\n","        optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","        batch_size = 125\n","        train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=10, shuffle=True)\n","\n","        test_results = df()\n","        train_results = df()\n","\n","        epoch_progress_bar = tqdm(total=num_epochs, desc=\"Training Progress\", position=0)\n","    \n","        for epoch in range(num_epochs):\n","            running_loss = 0.0\n","            acc = 0\n","            total = 0\n","            model.train()\n","            for inputs, targets in train_loader:\n","                # inputs in form of (time, batch, features)\n","                inputs, targets = inputs.transpose(0, 1).to(device), targets.to(device)\n","\n","                spikes, _ = model(inputs)\n","\n","                loss = criterion(spikes, targets)\n","\n","                loss.backward()\n","                optimizer.step()\n","                optimizer.zero_grad()\n","\n","                running_loss += loss.item()\n","                total += spikes.size(0)\n","\n","            epoch_progress_bar.update(1)\n","\n","            print(f\"Epoch {epoch+1} Running loss: {running_loss/total}\")\n","            \n","            # Print average loss for the epoch\n","            if ((epoch+1) % 5 == 0):\n","                to_print = (epoch_progress_bar if ((epoch+1) % 15 == 0) else None)\n","                test_results = test_spiking_network(model, test_dataset, criterion, test_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'test')\n","                train_results = test_spiking_network(model, train_dataset, criterion, test_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'train')\n","\n","        del model\n","        del inputs\n","        del targets\n","        del optimizer\n","        del criterion\n","        del loss\n","        gc.collect()\n","        if device == 'cuda': torch.cuda.empty_cache()\n","        elif device == 'mps': torch.mps.empty_cache()\n","\n","        test_results.to_csv(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/test.csv\")\n","        train_results.to_csv(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{spectrogram_type}/train.csv\")"]},{"cell_type":"markdown","metadata":{},"source":["## Time Contrast or Threshold Based"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["from delta import delta\n","\n","NON_ENCODED = \"direct_encoding\"\n","ENCODING_TYPE = \"time_contrast\"\n","\n","THRESHOLDS = [0.01, 0.025, 0.05, 0.10, 0.20, 0.50]\n","OFF_SPIKES = [True, False]\n","\n","for spectrogram_type in SPECTROGRAMS:\n","    for threshold in THRESHOLDS:\n","        for off_spike in OFF_SPIKES:\n","            original_test_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{NON_ENCODED}/{spectrogram_type}/test.pt\")\n","            original_train_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{NON_ENCODED}/{spectrogram_type}/train.pt\")\n","\n","            TC_test = delta(original_test_dataset, padding = True, threshold=threshold, off_spike=off_spike, threshold_as_percentage=True)\n","            TC_train = delta(original_train_dataset, padding = True, threshold=threshold, off_spike=off_spike, threshold_as_percentage=True)\n","\n","            os.makedirs(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{threshold}_{off_spike}/{spectrogram_type}\", exist_ok=True)\n","\n","            torch.save(TC_test, f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{threshold}_{off_spike}/{spectrogram_type}/test.pt\")\n","            torch.save(TC_train, f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{threshold}_{off_spike}/{spectrogram_type}/train.pt\")"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.01_True_mfcc_spectrograms\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"227117b509a7468e9527874b8448dedc","version_major":2,"version_minor":0},"text/plain":["Training Progress:   0%|          | 0/120 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1 Running loss: 0.35442625295620755\n","Epoch 2 Running loss: 0.26819463735952165\n","Epoch 3 Running loss: 0.1882083282683985\n","Epoch 4 Running loss: 0.16401675829110435\n","Epoch 5 Running loss: 0.14367981208637118\n","Epoch 6 Running loss: 0.13952355948499978\n","Epoch 7 Running loss: 0.17333261654399834\n","Epoch 8 Running loss: 0.08689660233811448\n","Epoch 9 Running loss: 0.1391909769929636\n","Epoch 10 Running loss: 0.06948035826888709\n","Epoch 11 Running loss: 0.05840403079605712\n","Epoch 12 Running loss: 0.06437429604819789\n","Epoch 13 Running loss: 0.04588500036599156\n","Epoch 14 Running loss: 0.03363625005411264\n","Epoch 15 Running loss: 0.03506985868508823\n","Epoch 16 Running loss: 0.028461989884178477\n","Epoch 17 Running loss: 0.02195574719304094\n","Epoch 18 Running loss: 0.02221214199980227\n","Epoch 19 Running loss: 0.016474429553690047\n","Epoch 20 Running loss: 0.01601898870148217\n","Epoch 21 Running loss: 0.01342568234704173\n","Epoch 22 Running loss: 0.01797505042042595\n","Epoch 23 Running loss: 0.012295082925607602\n","Epoch 24 Running loss: 0.02142034551967828\n","Epoch 25 Running loss: 0.01884281863800634\n","Epoch 26 Running loss: 0.018264194266102946\n","Epoch 27 Running loss: 0.018879128340334176\n","Epoch 28 Running loss: 0.009347677468872679\n","Epoch 29 Running loss: 0.014228602567800699\n","Epoch 30 Running loss: 0.011276505244806551\n","Epoch 31 Running loss: 0.01394558086181982\n","Epoch 32 Running loss: 0.013402838105210861\n","Epoch 33 Running loss: 0.011357459016501332\n","Epoch 34 Running loss: 0.014127005022554732\n","Epoch 35 Running loss: 0.009314583132442194\n","Epoch 36 Running loss: 0.009115722917091732\n","Epoch 37 Running loss: 0.010646871865366975\n","Epoch 38 Running loss: 0.01648619704353162\n","Epoch 39 Running loss: 0.011145301329822967\n","Epoch 40 Running loss: 0.00993728999512645\n","Epoch 41 Running loss: 0.010311493667931602\n","Epoch 42 Running loss: 0.009377446608802381\n","Epoch 43 Running loss: 0.011587301001381188\n","Epoch 44 Running loss: 0.010742032108977199\n","Epoch 45 Running loss: 0.014046844011678482\n","Epoch 46 Running loss: 0.012497942097270832\n","Epoch 47 Running loss: 0.010573116354287242\n","Epoch 48 Running loss: 0.00976303105537122\n","Epoch 49 Running loss: 0.010432779027250247\n","Epoch 50 Running loss: 0.012318958489658733\n","Epoch 51 Running loss: 0.011360937794938256\n","Epoch 52 Running loss: 0.01216286782639476\n","Epoch 53 Running loss: 0.010368734883805053\n","Epoch 54 Running loss: 0.009465730180755591\n","Epoch 55 Running loss: 0.00941829997510575\n","Epoch 56 Running loss: 0.009309410858458985\n","Epoch 57 Running loss: 0.010760458323140494\n","Epoch 58 Running loss: 0.013783989813381109\n","Epoch 59 Running loss: 0.008011991366410788\n","Epoch 60 Running loss: 0.013481954416147055\n","Epoch 61 Running loss: 0.008667429986472328\n","Epoch 62 Running loss: 0.01078877110069933\n","Epoch 63 Running loss: 0.014917278251708887\n","Epoch 64 Running loss: 0.010380250767777903\n","Epoch 65 Running loss: 0.010553788072384966\n","Epoch 66 Running loss: 0.014301525708585502\n","Epoch 67 Running loss: 0.010904311752928712\n","Epoch 68 Running loss: 0.013074045744947731\n","Epoch 69 Running loss: 0.008121025448028271\n","Epoch 70 Running loss: 0.016234360183008945\n","Epoch 71 Running loss: 0.008647432152074747\n","Epoch 72 Running loss: 0.01477050438475685\n","Epoch 73 Running loss: 0.009245422189704146\n","Epoch 74 Running loss: 0.01105340791586489\n","Epoch 75 Running loss: 0.010180272995092617\n","Epoch 76 Running loss: 0.016130944029591716\n","Epoch 77 Running loss: 0.007843938831704112\n","Epoch 78 Running loss: 0.00631998472225171\n","Epoch 79 Running loss: 0.008958804150358938\n","Epoch 80 Running loss: 0.008601559998509221\n","Epoch 81 Running loss: 0.008149946269135887\n","Epoch 82 Running loss: 0.007124164424384364\n"]}],"source":["for spectrogram_type in SPECTROGRAMS:\n","    for threshold in THRESHOLDS:\n","        for off_spike in OFF_SPIKES:\n","            if not os.path.isfile(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{threshold}_{off_spike}/{spectrogram_type}/train.csv\") and os.path.isfile(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{threshold}_{off_spike}/{spectrogram_type}/train.pt\"):\n","                print(f\"{threshold}_{off_spike}_{spectrogram_type}\")\n","                train_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{threshold}_{off_spike}/{spectrogram_type}/train.pt\")\n","                test_dataset = torch.load(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{threshold}_{off_spike}/{spectrogram_type}/test.pt\")\n","\n","                # Get the shape of the first sample (train_dataset[0]) of data (x) within the dataset\n","                x_shape = train_dataset[0][0].shape\n","\n","                # Assuming the shape is t x f\n","                features_shape = x_shape[1]\n","                POP_ENCODING = 10\n","                classes = len(label_encoder.classes_)\n","                output_shape = classes * POP_ENCODING\n","\n","\n","                model = Triangle_Network(features_shape, output_shape, beta=0.9, time_dependent=True).to(device)\n","                num_epochs = 120\n","\n","                criterion = PopulationCrossEntropyLoss(num_classes=classes)\n","\n","                optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","                batch_size = 120\n","                train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=10, shuffle=True)\n","\n","                test_results = df()\n","                train_results = df()\n","\n","                epoch_progress_bar = tqdm(total=num_epochs, desc=\"Training Progress\", position=0)\n","            \n","                for epoch in range(num_epochs):\n","                    running_loss = 0.0\n","                    acc = 0\n","                    total = 0\n","                    model.train()\n","                    for inputs, targets in train_loader:\n","                        # inputs in form of (time, batch, features)\n","                        inputs, targets = inputs.transpose(0, 1).to(device), targets.to(device)\n","\n","                        spikes, _ = model(inputs)\n","\n","                        loss = criterion(spikes, targets)\n","\n","                        loss.backward()\n","                        optimizer.step()\n","                        optimizer.zero_grad()\n","\n","                        running_loss += loss.item()\n","                        total += spikes.size(0)\n","\n","                    epoch_progress_bar.update(1)\n","\n","                    print(f\"Epoch {epoch+1} Running loss: {running_loss/total}\")\n","                    \n","                    # Print average loss for the epoch\n","                    if ((epoch+1) % 5 == 0):\n","                        to_print = (epoch_progress_bar if ((epoch+1) % 15 == 0) else None)\n","                        test_results = test_spiking_network(model, test_dataset, criterion, test_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'test')\n","                        train_results = test_spiking_network(model, train_dataset, criterion, test_results, epoch, device, num_classes = classes, printable = epoch_progress_bar, train_test = 'train')\n","\n","                del model\n","                del inputs\n","                del targets\n","                del optimizer\n","                del criterion\n","                del loss\n","                gc.collect()\n","                if device == 'cuda': torch.cuda.empty_cache()\n","                elif device == 'mps': torch.mps.empty_cache()\n","\n","                test_results.to_csv(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{threshold}_{off_spike}/{spectrogram_type}/test.csv\")\n","                train_results.to_csv(f\"{FILEPATH}/{TEST_TYPE}/{ENCODING_TYPE}/{threshold}_{off_spike}/{spectrogram_type}/train.csv\")"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["QrnOeGaHh25K","43m8jiuhh25L","st4_dGj4h25N"],"gpuType":"A100","private_outputs":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":0}
